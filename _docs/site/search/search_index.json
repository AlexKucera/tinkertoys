{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Tinkertoys Documentation","text":"<p>Welcome to the comprehensive documentation for the Tinkertoys utility scripts collection. This repository contains a carefully curated set of automation tools, development utilities, and system administration scripts designed to streamline workflows and improve productivity.</p>"},{"location":"index.html#overview","title":"Overview","text":"<p>Tinkertoys is a collection of utility scripts and automation tools organized by programming language and purpose. The repository includes:</p> <ul> <li>Bash Scripts: System administration, media processing, development tools, and rendering automation</li> <li>Python Scripts: Data processing, media conversion, system utilities, and macOS integration</li> <li>Configuration Files: Centralized settings for various tools and services</li> </ul>"},{"location":"index.html#quick-start","title":"Quick Start","text":""},{"location":"index.html#prerequisites","title":"Prerequisites","text":"<ul> <li>macOS: Most scripts are designed for macOS (some may work on Linux)</li> <li>Bash 4.0+: Modern bash shell for script execution</li> <li>FFmpeg: Required for media processing scripts</li> <li>Python 3.11+: For Python utilities (modernized from Python 2.7)</li> </ul>"},{"location":"index.html#installation","title":"Installation","text":"<ol> <li>Clone or download the repository</li> <li>Set up configuration files in the <code>config/</code> directory</li> <li>Install required dependencies based on the scripts you plan to use</li> <li>Make scripts executable: <code>chmod +x script_name.sh</code></li> </ol>"},{"location":"index.html#key-features","title":"Key Features","text":""},{"location":"index.html#development-tools","title":"\ud83d\udd27 Development Tools","text":"<ul> <li>App Builder (Bash): Convert shell scripts to macOS applications</li> <li>Version Management (Bash): Automated version number incrementing</li> <li>Folder Comparison (Bash/Python): Compare directories for differences</li> <li>Image Extension Fixing (Bash): Automatically correct file extensions</li> <li>Timer Utility (Python): Advanced timing and stopwatch functionality</li> <li>Git Empty Folder Marker (Python): Manage .gitkeep files in repositories</li> </ul>"},{"location":"index.html#media-processing","title":"\ud83c\udfa5 Media Processing","text":"<ul> <li>Video Transcoding (Bash): Convert videos to H.264, ProRes, and web formats</li> <li>Image Sequence Processing (Bash): Convert image sequences to video</li> <li>Audio Processing (Bash): Split stereo audio to mono channels</li> <li>PSD to EXR Converter (Python): Convert Photoshop files to EXR format</li> <li>Render Statistics (Python): Analyze render times and frame sequences</li> </ul>"},{"location":"index.html#system-administration","title":"\u2699\ufe0f System Administration","text":"<ul> <li>Application Management (Bash): Track installed applications for backup</li> <li>Log Monitoring (Bash): Automated log size checking and collection</li> <li>Memory Management (Bash): Intelligent memory purging for macOS</li> <li>Disk Management (Bash): Find disk devices by label</li> <li>File Size Comparison (Python): Compare file sizes and detect corruption</li> <li>Symlink Repair (Python): Fix broken symbolic links</li> <li>Duplicate File Manager (Python): Remove duplicate files keeping larger versions</li> <li>Path Replacement (Python): Bulk path updates with JSON configuration</li> </ul>"},{"location":"index.html#rendering-tools","title":"\ud83c\udfac Rendering Tools","text":"<ul> <li>Email Notifications (Bash): Automated notifications for completed renders</li> <li>Nuke Integration (Bash): Streamlined Nuke rendering with progress tracking</li> </ul>"},{"location":"index.html#data-processing","title":"\ud83d\udcca Data Processing","text":"<ul> <li>DayOne Journal Splitter (Python): Split DayOne exports into individual files</li> <li>Pinboard Export (Python): Backup Pinboard bookmarks</li> </ul>"},{"location":"index.html#shared-libraries","title":"\ud83d\udcda Shared Libraries","text":"<ul> <li>Common Functions (Bash): Reusable validation and utility functions</li> <li>Media Functions (Bash): Specialized video/audio processing utilities</li> <li>System Functions (Bash): Cross-platform system information and management</li> <li>AppleScript Integration (Python): Modern macOS automation with error handling</li> <li>File Copying Utilities (Python): High-performance file operations with progress tracking</li> <li>Hash Calculation (Python): Optimized file hashing with multiple algorithms</li> <li>Interactive Prompts (Python): Enhanced user interaction utilities</li> </ul>"},{"location":"index.html#architecture","title":"Architecture","text":""},{"location":"index.html#security-best-practices","title":"Security &amp; Best Practices","text":"<ul> <li>No Hardcoded Credentials: All sensitive data uses environment variables</li> <li>Input Validation: Comprehensive validation of all user inputs</li> <li>Error Handling: Proper error handling with <code>set -euo pipefail</code></li> <li>Path Safety: Protection against path traversal attacks</li> </ul>"},{"location":"index.html#code-organization","title":"Code Organization","text":"<ul> <li>Modular Design: Scripts organized by functional category</li> <li>Shared Libraries: Common functionality extracted to reusable modules</li> <li>Consistent Interface: Standardized help system across all scripts</li> <li>Configuration Management: Centralized configuration files</li> </ul>"},{"location":"index.html#quality-assurance","title":"Quality Assurance","text":"<ul> <li>Comprehensive Testing: Automated test suite for all scripts</li> <li>Syntax Validation: All scripts validated for proper bash syntax</li> <li>Functionality Testing: Safe functional testing of key operations</li> <li>Integration Testing: Validation of shared library integration</li> </ul>"},{"location":"index.html#getting-help","title":"Getting Help","text":"<p>Each script includes comprehensive help documentation accessible via:</p> <pre><code>script_name.sh --help\n# or\nscript_name.sh -h\n</code></pre> <p>For detailed documentation on specific scripts, see the navigation menu or browse the individual script documentation pages.</p>"},{"location":"index.html#contributing","title":"Contributing","text":"<p>When contributing to this repository:</p> <ol> <li>Follow existing code style and organization patterns</li> <li>Include comprehensive help documentation in all scripts</li> <li>Add appropriate error handling and input validation</li> <li>Update documentation for any new features or changes</li> <li>Test scripts thoroughly before submission</li> </ol>"},{"location":"index.html#license","title":"License","text":"<p>This project is maintained by Alexander Kucera / babylondreams.de. Individual scripts may have specific licensing terms - please check script headers for details.</p>"},{"location":"index.html#support","title":"Support","text":"<p>For issues, questions, or contributions, please refer to the individual script documentation or contact the maintainer.</p> <p>Last updated: July 2025</p>"},{"location":"bash/overview.html","title":"Bash Scripts Overview","text":"<p>The bash scripts collection provides comprehensive automation tools for development, media processing, system administration, and rendering workflows. All scripts have been modernized with proper error handling, security best practices, and shared library integration.</p>"},{"location":"bash/overview.html#script-categories","title":"Script Categories","text":""},{"location":"bash/overview.html#development-tools","title":"\ud83d\udd27 Development Tools","text":"<p>Development utilities for app creation, version management, and project maintenance.</p> Script Purpose Key Features appifiy.sh Convert shell scripts to macOS apps Creates .app bundles, custom naming comparefolders.sh Compare two directories Recursive comparison, difference reporting fixImgExt.sh Fix image file extensions Content-based detection, batch processing version_up.sh Increment version numbers Semantic versioning, history tracking"},{"location":"bash/overview.html#media-processing","title":"\ud83c\udfa5 Media Processing","text":"<p>Professional-grade media conversion and processing tools with optimized settings.</p> Script Purpose Key Features convert_images_to_h264.sh Convert image sequences to H.264 Configurable quality, bitrate guidelines convert_images_to_prores.sh Convert image sequences to ProRes Multiple ProRes formats, high quality convert_movie_to_h264.sh Convert movies to H.264 Optimized compression, format flexibility convert_movie_to_prores.sh Convert movies to ProRes Professional codecs, configurable quality movie_to_web.sh Convert movies for web MP4 + WebM output, web optimization split_stereo_to_mono.sh Split stereo audio to mono Apple Lossless output, channel separation"},{"location":"bash/overview.html#system-administration","title":"\u2699\ufe0f System Administration","text":"<p>Tools for system monitoring, application management, and maintenance automation.</p> Script Purpose Key Features application_list_updater.sh Track installed applications Homebrew integration, backup lists checkLogSize.sh Monitor log file sizes Configurable limits, automation-ready getDiskDevice.sh Find disk devices by label Label-based lookup, device identification purgeLoop.sh Automated memory purging Intelligent thresholds, continuous monitoring log_collector.sh Advanced log collection Category filtering, time-based queries"},{"location":"bash/overview.html#rendering-tools","title":"\ud83c\udfac Rendering Tools","text":"<p>Automation and notification tools for rendering workflows.</p> Script Purpose Key Features mail_send.sh Email notifications for renders Timing tracking, completion alerts nukerender_bash.sh Automated Nuke rendering Interactive setup, email integration"},{"location":"bash/overview.html#shared-libraries","title":"\ud83d\udcda Shared Libraries","text":"<p>Reusable function libraries that provide common functionality across all scripts.</p> Library Purpose Key Functions common.sh Core utility functions Validation, timestamps, logging media_functions.sh Media processing utilities Codec setup, format validation system_functions.sh System information functions Memory info, platform detection writeToLogAndEcho.sh Logging utilities Console + file output, message handling"},{"location":"bash/overview.html#common-features","title":"Common Features","text":""},{"location":"bash/overview.html#security-safety","title":"Security &amp; Safety","text":"<ul> <li>Input Validation: All user inputs are validated and sanitized</li> <li>Path Protection: Protection against path traversal attacks</li> <li>No Hardcoded Secrets: All credentials use environment variables</li> <li>Error Handling: Comprehensive error handling with <code>set -euo pipefail</code></li> </ul>"},{"location":"bash/overview.html#user-experience","title":"User Experience","text":"<ul> <li>Standardized Help: All scripts support <code>-h</code> and <code>--help</code> flags</li> <li>Consistent Interface: Unified argument and option patterns</li> <li>Progress Feedback: Clear status messages and progress indicators</li> <li>Error Messages: Helpful error messages with troubleshooting guidance</li> </ul>"},{"location":"bash/overview.html#quality-assurance","title":"Quality Assurance","text":"<ul> <li>Syntax Validation: All scripts validated for correct bash syntax</li> <li>Shared Libraries: Common functionality extracted to reusable modules</li> <li>Testing: Comprehensive test suite validates all functionality</li> <li>Documentation: Complete documentation following MkDocs standards</li> </ul>"},{"location":"bash/overview.html#usage-patterns","title":"Usage Patterns","text":""},{"location":"bash/overview.html#getting-help","title":"Getting Help","text":"<p>Every script provides comprehensive help: <pre><code>script_name.sh --help\n</code></pre></p>"},{"location":"bash/overview.html#common-options","title":"Common Options","text":"<p>Most scripts support these standard patterns: - <code>-h, --help</code>: Show help information - Input validation with clear error messages - Configuration via environment variables where appropriate - Progress feedback and status reporting</p>"},{"location":"bash/overview.html#environment-variables","title":"Environment Variables","text":"<p>Scripts use environment variables for configuration: - <code>MAIL_PASSWORD</code>: Email notification password - <code>NUKEPATH</code>: Path to Nuke executable - <code>LOG_FILE</code>: Custom log file location (for logging utilities)</p>"},{"location":"bash/overview.html#integration","title":"Integration","text":""},{"location":"bash/overview.html#shared-libraries_1","title":"Shared Libraries","text":"<p>Scripts automatically source required shared libraries: <pre><code>source \"${SCRIPT_DIR}/../lib/common.sh\"\nsource \"${SCRIPT_DIR}/../lib/media_functions.sh\"  # Media scripts\nsource \"${SCRIPT_DIR}/../lib/system_functions.sh\" # System scripts\n</code></pre></p>"},{"location":"bash/overview.html#configuration-files","title":"Configuration Files","text":"<p>Centralized configuration in <code>config/</code> directory: - <code>mail_send.conf</code>: Email notification settings - <code>log_sources.conf</code>: Log collection source definitions</p>"},{"location":"bash/overview.html#testing","title":"Testing","text":"<p>Comprehensive test suite available: <pre><code># Run all tests\n./test_all_scripts.sh\n\n# Quick validation\n./quick_test.sh\n\n# Full validation with logging\n./final_validation.sh\n</code></pre></p>"},{"location":"bash/overview.html#architecture","title":"Architecture","text":"<p>The bash scripts follow a consistent architecture pattern:</p> <ol> <li>Header &amp; Metadata: Script purpose, author, requirements</li> <li>Library Integration: Source shared libraries as needed</li> <li>Help System: Standardized help function and argument parsing</li> <li>Input Validation: Validate all arguments and file paths</li> <li>Main Logic: Core functionality with error handling</li> <li>Output &amp; Cleanup: Status reporting and temporary file cleanup</li> </ol> <p>This organization ensures maintainability, security, and consistent user experience across all scripts.</p>"},{"location":"bash/development/appifiy.html","title":"App Builder (appifiy.sh)","text":"<p>Convert shell scripts into native macOS .app bundles for easier distribution and execution.</p>"},{"location":"bash/development/appifiy.html#overview","title":"Overview","text":"<p>The <code>appifiy.sh</code> script transforms any shell script into a macOS application bundle (.app), making it possible to run command-line tools through the Finder or Dock. This is particularly useful for creating user-friendly interfaces for automation scripts.</p>"},{"location":"bash/development/appifiy.html#usage","title":"Usage","text":"<pre><code>appifiy.sh script_file.sh [app_name]\n</code></pre>"},{"location":"bash/development/appifiy.html#arguments","title":"Arguments","text":"Argument Type Description <code>script_file</code> Required Path to the shell script to convert <code>app_name</code> Optional Custom name for the app (defaults to script filename)"},{"location":"bash/development/appifiy.html#options","title":"Options","text":"Option Description <code>-h, --help</code> Show help message and exit"},{"location":"bash/development/appifiy.html#examples","title":"Examples","text":""},{"location":"bash/development/appifiy.html#basic-usage","title":"Basic Usage","text":"<pre><code># Convert script using default name\n./appifiy.sh my-script.sh\n\n# This creates: my-script.app\n</code></pre>"},{"location":"bash/development/appifiy.html#custom-app-name","title":"Custom App Name","text":"<pre><code># Convert with custom name\n./appifiy.sh backup-script.sh \"Backup Tool\"\n\n# This creates: Backup Tool.app\n</code></pre>"},{"location":"bash/development/appifiy.html#convert-utility-scripts","title":"Convert Utility Scripts","text":"<pre><code># Convert a log monitor into an app\n./appifiy.sh checkLogSize.sh \"Log Monitor\"\n\n# Convert a media processor\n./appifiy.sh convert_movie_to_h264.sh \"Video Converter\"\n</code></pre>"},{"location":"bash/development/appifiy.html#features","title":"Features","text":""},{"location":"bash/development/appifiy.html#core-functionality","title":"\ud83d\udd27 Core Functionality","text":"<ul> <li>Native App Bundle Creation: Generates proper macOS .app structure</li> <li>Automatic Naming: Uses script filename if no app name provided</li> <li>Executable Setup: Sets proper permissions for the contained script</li> <li>Error Prevention: Checks for existing apps to prevent overwrites</li> </ul>"},{"location":"bash/development/appifiy.html#safety-features","title":"\ud83d\udee1\ufe0f Safety Features","text":"<ul> <li>Input Validation: Verifies script file exists before processing</li> <li>Collision Detection: Prevents overwriting existing .app bundles</li> <li>Path Validation: Ensures safe file operations</li> </ul>"},{"location":"bash/development/appifiy.html#user-experience","title":"\ud83d\udca1 User Experience","text":"<ul> <li>Simple Interface: Single command converts any script</li> <li>Clear Feedback: Reports success and final app location</li> <li>Help System: Comprehensive help with examples</li> </ul>"},{"location":"bash/development/appifiy.html#how-it-works","title":"How It Works","text":"<p>The script creates a standard macOS application bundle structure:</p> <pre><code>MyApp.app/\n\u251c\u2500\u2500 Contents/\n    \u2514\u2500\u2500 MacOS/\n        \u2514\u2500\u2500 MyApp          # Your original script\n</code></pre> <ol> <li>Validation: Checks that the source script exists</li> <li>Structure Creation: Creates the .app bundle directory structure  </li> <li>Script Installation: Copies your script to the MacOS directory</li> <li>Permission Setup: Makes the script executable within the bundle</li> <li>Verification: Reports successful creation with full path</li> </ol>"},{"location":"bash/development/appifiy.html#requirements","title":"Requirements","text":""},{"location":"bash/development/appifiy.html#system-requirements","title":"System Requirements","text":"<ul> <li>macOS: Required for .app bundle creation</li> <li>Bash: Standard bash shell</li> <li>File System Access: Write permissions in current directory</li> </ul>"},{"location":"bash/development/appifiy.html#input-requirements","title":"Input Requirements","text":"<ul> <li>Valid Script File: Source script must exist and be readable</li> <li>Unique Name: App name must not conflict with existing .app bundles</li> </ul>"},{"location":"bash/development/appifiy.html#configuration","title":"Configuration","text":"<p>No configuration files required. The script operates entirely from command-line arguments.</p>"},{"location":"bash/development/appifiy.html#output","title":"Output","text":""},{"location":"bash/development/appifiy.html#success-output","title":"Success Output","text":"<pre><code>Creating app bundle: MyScript.app\nSuccessfully created: /full/path/to/MyScript.app\n</code></pre>"},{"location":"bash/development/appifiy.html#error-scenarios","title":"Error Scenarios","text":"<ul> <li>Missing Script: \"Error: Script file 'filename.sh' does not exist\"</li> <li>Existing App: \"Error: /path/MyScript.app already exists\"</li> <li>Missing Arguments: Shows usage information</li> </ul>"},{"location":"bash/development/appifiy.html#integration","title":"Integration","text":""},{"location":"bash/development/appifiy.html#with-other-scripts","title":"With Other Scripts","text":"<pre><code># Create apps for multiple scripts\nfor script in *.sh; do\n    ./appifiy.sh \"$script\"\ndone\n\n# Create themed app names\n./appifiy.sh video_converter.sh \"\ud83c\udfac Video Converter\"\n./appifiy.sh log_monitor.sh \"\ud83d\udcca Log Monitor\"\n</code></pre>"},{"location":"bash/development/appifiy.html#automation-examples","title":"Automation Examples","text":"<pre><code># Build distribution package\n./appifiy.sh main_tool.sh \"Production Tool\"\n./appifiy.sh setup_helper.sh \"Setup Assistant\"\n./appifiy.sh maintenance.sh \"Maintenance Utility\"\n</code></pre>"},{"location":"bash/development/appifiy.html#best-practices","title":"Best Practices","text":""},{"location":"bash/development/appifiy.html#script-preparation","title":"Script Preparation","text":"<ol> <li>Test Scripts Thoroughly: Ensure scripts work correctly before conversion</li> <li>Add Help Systems: Include <code>--help</code> functionality in your scripts</li> <li>Handle Paths Properly: Use absolute paths or relative to script location</li> <li>Error Handling: Implement proper error handling in source scripts</li> </ol>"},{"location":"bash/development/appifiy.html#app-naming","title":"App Naming","text":"<ol> <li>Descriptive Names: Use clear, descriptive app names</li> <li>Avoid Conflicts: Check for existing apps before conversion</li> <li>Consistent Naming: Use consistent naming patterns for related tools</li> </ol>"},{"location":"bash/development/appifiy.html#distribution","title":"Distribution","text":"<ol> <li>Test App Bundles: Test created apps on clean systems</li> <li>Include Documentation: Provide README files with your apps</li> <li>Version Control: Track both scripts and app bundles appropriately</li> </ol>"},{"location":"bash/development/appifiy.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"bash/development/appifiy.html#common-issues","title":"Common Issues","text":"<p>App Won't Launch - Check original script permissions and syntax - Verify script doesn't require specific working directory - Test original script independently first</p> <p>Permission Denied - Ensure write permissions in target directory - Check that original script is readable</p> <p>App Already Exists - Remove existing .app bundle or choose different name - Use <code>rm -rf \"AppName.app\"</code> to remove existing bundle</p>"},{"location":"bash/development/appifiy.html#technical-details","title":"Technical Details","text":""},{"location":"bash/development/appifiy.html#based-on","title":"Based On","text":"<ul> <li>Reference implementation: https://mathiasbynens.be/notes/shell-script-mac-apps</li> <li>Enhanced with modern error handling and validation</li> </ul>"},{"location":"bash/development/appifiy.html#security-considerations","title":"Security Considerations","text":"<ul> <li>Input Validation: All file paths validated before use</li> <li>Safe Operations: Prevents overwriting existing files</li> <li>Path Safety: No arbitrary path construction or traversal</li> </ul>"},{"location":"bash/development/appifiy.html#limitations","title":"Limitations","text":"<ul> <li>macOS Only: App bundles only work on macOS systems</li> <li>Simple Bundle: Creates basic app structure without advanced features</li> <li>No Icon Support: Generated apps use default system icon</li> </ul>"},{"location":"bash/development/appifiy.html#see-also","title":"See Also","text":"<ul> <li>Version Incrementer - For managing app versions</li> <li>Shared Libraries - Common validation functions used</li> <li>Development Tools Overview - Other development utilities</li> </ul> <p>Script Location: <code>bash/development/appifiy.sh</code> Author: Alexander Kucera / babylondreams.de</p>"},{"location":"bash/development/comparefolders.html","title":"Folder Comparison (comparefolders.sh)","text":"<p>Compare two directories for file differences with detailed reporting and automated output generation.</p>"},{"location":"bash/development/comparefolders.html#overview","title":"Overview","text":"<p>The <code>comparefolders.sh</code> script performs comprehensive recursive comparison between two directories, identifying differences in files and generating detailed reports. It's designed for backup verification, synchronization validation, and content auditing.</p>"},{"location":"bash/development/comparefolders.html#usage","title":"Usage","text":"<pre><code>comparefolders.sh &lt;path1&gt; &lt;path2&gt;\n</code></pre>"},{"location":"bash/development/comparefolders.html#arguments","title":"Arguments","text":"Argument Type Description <code>path1</code> Required Path to first directory to compare <code>path2</code> Required Path to second directory to compare"},{"location":"bash/development/comparefolders.html#options","title":"Options","text":"Option Description <code>-h, --help</code> Show help message and exit"},{"location":"bash/development/comparefolders.html#examples","title":"Examples","text":""},{"location":"bash/development/comparefolders.html#basic-directory-comparison","title":"Basic Directory Comparison","text":"<pre><code># Compare two backup directories\n./comparefolders.sh /Users/alex/Documents/backup1 /Users/alex/Documents/backup2\n\n# Compare project versions\n./comparefolders.sh ~/Projects/v1.0 ~/Projects/v2.0\n</code></pre>"},{"location":"bash/development/comparefolders.html#backup-verification","title":"Backup Verification","text":"<pre><code># Verify backup integrity\n./comparefolders.sh /original/data /backup/location\n\n# Compare local vs network storage\n./comparefolders.sh ~/Documents /Volumes/NetworkDrive/Documents\n</code></pre>"},{"location":"bash/development/comparefolders.html#development-workflow","title":"Development Workflow","text":"<pre><code># Compare development branches (if using file-based projects)\n./comparefolders.sh ~/Projects/main-branch ~/Projects/feature-branch\n\n# Verify deployment\n./comparefolders.sh ~/local-build ~/staging-deployment\n</code></pre>"},{"location":"bash/development/comparefolders.html#features","title":"Features","text":""},{"location":"bash/development/comparefolders.html#comprehensive-comparison","title":"\ud83d\udd0d Comprehensive Comparison","text":"<ul> <li>Recursive Analysis: Compares all files in subdirectories</li> <li>File Content Comparison: Detects differences in file contents, not just names</li> <li>Metadata Awareness: Identifies files with different timestamps or sizes</li> <li>Missing File Detection: Reports files present in one directory but not the other</li> </ul>"},{"location":"bash/development/comparefolders.html#smart-filtering","title":"\ud83d\udee1\ufe0f Smart Filtering","text":"<ul> <li>System File Exclusion: Automatically excludes <code>.DS_Store</code> files</li> <li>Thumbnail Filtering: Ignores <code>Thumbs</code> files for cleaner results</li> <li>Hidden File Handling: Processes hidden files but filters out system artifacts</li> </ul>"},{"location":"bash/development/comparefolders.html#detailed-reporting","title":"\ud83d\udcca Detailed Reporting","text":"<ul> <li>Output File Generation: Creates <code>~/compare.txt</code> with detailed results</li> <li>Difference Counting: Reports total number of differences found</li> <li>Clear Status Messages: Provides immediate feedback on comparison results</li> <li>Success Indicators: Clear indication when directories are identical</li> </ul>"},{"location":"bash/development/comparefolders.html#how-it-works","title":"How It Works","text":"<p>The script uses the <code>diff</code> command with recursive comparison:</p> <ol> <li>Input Validation: Verifies both directories exist and are accessible</li> <li>Recursive Comparison: Uses <code>diff -qr</code> for comprehensive file comparison</li> <li>Smart Filtering: Excludes system files that shouldn't affect comparison</li> <li>Result Processing: Generates report file and provides summary statistics</li> <li>Status Reporting: Clear feedback on comparison results</li> </ol>"},{"location":"bash/development/comparefolders.html#output-format","title":"Output Format","text":""},{"location":"bash/development/comparefolders.html#console-output","title":"Console Output","text":"<pre><code>Comparing directories...\nPath 1: /Users/alex/Documents/old\nPath 2: /Users/alex/Documents/new\nOutput: /Users/alex/compare.txt\n\u2713 Differences found and written to /Users/alex/compare.txt\nNumber of differences: 5\n</code></pre>"},{"location":"bash/development/comparefolders.html#report-file-format","title":"Report File Format","text":"<p>The generated <code>~/compare.txt</code> contains detailed difference information: <pre><code>Only in /path1: unique_file.txt\nOnly in /path2: new_file.txt\nFiles /path1/modified.txt and /path2/modified.txt differ\n</code></pre></p>"},{"location":"bash/development/comparefolders.html#configuration","title":"Configuration","text":""},{"location":"bash/development/comparefolders.html#output-location","title":"Output Location","text":"<ul> <li>Default: Results saved to <code>~/compare.txt</code></li> <li>Automatic: Output file location reported in console</li> <li>Overwrite: Each run overwrites previous comparison results</li> </ul>"},{"location":"bash/development/comparefolders.html#environment-variables","title":"Environment Variables","text":"<p>No environment variables required. All configuration through command-line arguments.</p>"},{"location":"bash/development/comparefolders.html#integration","title":"Integration","text":""},{"location":"bash/development/comparefolders.html#with-backup-scripts","title":"With Backup Scripts","text":"<pre><code>#!/bin/bash\n# Backup verification script\nBACKUP_DATE=$(date +%Y%m%d)\n./comparefolders.sh ~/Documents ~/Backups/$BACKUP_DATE\n\nif [[ -s ~/compare.txt ]]; then\n    echo \"Backup verification failed - differences found\"\n    exit 1\nelse\n    echo \"Backup verification successful\"\nfi\n</code></pre>"},{"location":"bash/development/comparefolders.html#with-deployment-workflows","title":"With Deployment Workflows","text":"<pre><code># Pre-deployment verification\n./comparefolders.sh ~/build ~/staging\nif [[ ! -s ~/compare.txt ]]; then\n    echo \"Staging matches build - safe to deploy\"\nelse\n    echo \"Staging differences detected - review required\"\n    cat ~/compare.txt\nfi\n</code></pre>"},{"location":"bash/development/comparefolders.html#automated-monitoring","title":"Automated Monitoring","text":"<pre><code># Daily sync verification\n#!/bin/bash\nLOG_FILE=\"/var/log/sync_verification.log\"\n./comparefolders.sh /local/data /remote/sync\n\nif [[ -s ~/compare.txt ]]; then\n    echo \"$(date): Sync differences detected\" &gt;&gt; \"$LOG_FILE\"\n    cat ~/compare.txt &gt;&gt; \"$LOG_FILE\"\nelse\n    echo \"$(date): Sync verification passed\" &gt;&gt; \"$LOG_FILE\"\nfi\n</code></pre>"},{"location":"bash/development/comparefolders.html#best-practices","title":"Best Practices","text":""},{"location":"bash/development/comparefolders.html#directory-preparation","title":"Directory Preparation","text":"<ol> <li>Clean Paths: Ensure directory paths don't contain special characters</li> <li>Proper Permissions: Verify read access to both directories</li> <li>Network Considerations: Allow extra time for network-mounted directories</li> <li>Large Directories: Be patient with very large directory trees</li> </ol>"},{"location":"bash/development/comparefolders.html#result-interpretation","title":"Result Interpretation","text":"<ol> <li>Review Output File: Always check the generated comparison file</li> <li>Understand Differences: Distinguish between content and metadata differences</li> <li>Filter Expectations: Remember that system files are automatically filtered</li> <li>Context Matters: Consider whether detected differences are expected</li> </ol>"},{"location":"bash/development/comparefolders.html#performance-optimization","title":"Performance Optimization","text":"<ol> <li>Local Comparisons: Faster when both directories are local</li> <li>Network Mounts: Mount network drives before comparison for better performance</li> <li>Large Files: Comparison time increases with file count and size</li> <li>Parallel Runs: Avoid running multiple comparisons simultaneously</li> </ol>"},{"location":"bash/development/comparefolders.html#error-handling","title":"Error Handling","text":""},{"location":"bash/development/comparefolders.html#common-scenarios","title":"Common Scenarios","text":"<ul> <li>Missing Directories: Clear error message if either directory doesn't exist</li> <li>Permission Issues: Graceful handling of inaccessible files</li> <li>Network Timeouts: Proper error reporting for network-related issues</li> <li>Disk Space: Verification that output file can be written</li> </ul>"},{"location":"bash/development/comparefolders.html#exit-codes","title":"Exit Codes","text":"<ul> <li>0: Successful comparison (regardless of whether differences found)</li> <li>1: Error in execution (missing directories, permission issues, etc.)</li> </ul>"},{"location":"bash/development/comparefolders.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"bash/development/comparefolders.html#no-output-file-generated","title":"No Output File Generated","text":"<ul> <li>Check write permissions to home directory</li> <li>Verify both input directories exist</li> <li>Ensure sufficient disk space for output file</li> </ul>"},{"location":"bash/development/comparefolders.html#missing-differences","title":"Missing Differences","text":"<ul> <li>System files (.DS_Store, Thumbs) are intentionally filtered</li> <li>Hidden files may not be compared depending on directory permissions</li> <li>Symbolic links handled differently than regular files</li> </ul>"},{"location":"bash/development/comparefolders.html#performance-issues","title":"Performance Issues","text":"<ul> <li>Large directory trees take significant time</li> <li>Network mounted directories slower than local</li> <li>Consider using <code>nice</code> command for large comparisons</li> </ul>"},{"location":"bash/development/comparefolders.html#technical-details","title":"Technical Details","text":""},{"location":"bash/development/comparefolders.html#dependencies","title":"Dependencies","text":"<ul> <li>diff: Standard Unix diff command with recursive support</li> <li>grep: For filtering unwanted files from results</li> <li>Shared Libraries: Uses common.sh for directory validation</li> </ul>"},{"location":"bash/development/comparefolders.html#filtering-logic","title":"Filtering Logic","text":"<pre><code>diff -qr \"$path1\" \"$path2\" | grep -v -e 'DS_Store' -e 'Thumbs'\n</code></pre>"},{"location":"bash/development/comparefolders.html#security-considerations","title":"Security Considerations","text":"<ul> <li>Path Validation: All paths validated before use</li> <li>No Arbitrary Execution: No dynamic command execution</li> <li>Safe File Operations: Read-only operations on input directories</li> </ul>"},{"location":"bash/development/comparefolders.html#see-also","title":"See Also","text":"<ul> <li>Common Functions - Shared validation functions used</li> <li>Development Tools Overview - Related development utilities</li> <li>System Administration - Monitoring and maintenance tools</li> </ul> <p>Script Location: <code>bash/development/comparefolders.sh</code> Author: Alexander Kucera / babylondreams.de Copyright: 2012 BabylonDreams. All rights reserved.</p>"},{"location":"bash/development/fixImgExt.html","title":"Image Extension Fixer (fixImgExt.sh)","text":"<p>Automatically correct image file extensions based on actual file content rather than current extension.</p>"},{"location":"bash/development/fixImgExt.html#overview","title":"Overview","text":"<p>The <code>fixImgExt.sh</code> script analyzes image files to determine their true format and corrects file extensions accordingly. This is particularly useful for fixing incorrectly named files, batch processing image collections, and ensuring accurate file type identification.</p>"},{"location":"bash/development/fixImgExt.html#usage","title":"Usage","text":"<pre><code>fixImgExt.sh [OPTIONS]\n</code></pre>"},{"location":"bash/development/fixImgExt.html#options","title":"Options","text":"Option Parameter Description <code>-f</code> FILE Process a single file with file path <code>-d</code> DIRECTORY Process all files in the specified directory <code>-r</code> Use with <code>-d</code> to process directories recursively <code>-s</code> Show detailed information for each file processed <code>-v</code> Log corrected files to <code>fixImgExt_info.txt</code> <code>-h</code> Show help message and exit"},{"location":"bash/development/fixImgExt.html#examples","title":"Examples","text":""},{"location":"bash/development/fixImgExt.html#single-file-processing","title":"Single File Processing","text":"<pre><code># Fix extension for a single image\n./fixImgExt.sh -f /path/to/image.wrong\n\n# Fix with detailed output\n./fixImgExt.sh -f -s /path/to/image.jpg\n</code></pre>"},{"location":"bash/development/fixImgExt.html#directory-processing","title":"Directory Processing","text":"<pre><code># Fix all images in a directory\n./fixImgExt.sh -d /path/to/images/\n\n# Process recursively with logging\n./fixImgExt.sh -d -r -v /path/to/image_collection/\n\n# Detailed processing with verbose output\n./fixImgExt.sh -d -s -v /Users/alex/Pictures/\n</code></pre>"},{"location":"bash/development/fixImgExt.html#batch-operations","title":"Batch Operations","text":"<pre><code># Process camera imports (often have generic extensions)\n./fixImgExt.sh -d -r -v ~/Pictures/Camera_Import/\n\n# Fix web downloads (may have incorrect extensions)\n./fixImgExt.sh -d -s ~/Downloads/images/\n\n# Process design project files\n./fixImgExt.sh -d -r -v ~/Projects/design_assets/\n</code></pre>"},{"location":"bash/development/fixImgExt.html#features","title":"Features","text":""},{"location":"bash/development/fixImgExt.html#content-based-detection","title":"\ud83d\udd0d Content-Based Detection","text":"<ul> <li>True Format Recognition: Uses <code>file</code> command to detect actual image format</li> <li>Extension Correction: Matches file extension to actual content</li> <li>Format Support: Supports major image formats (JPEG, PNG, GIF, TIFF, BMP, etc.)</li> <li>Professional Formats: Handles PSD, XCF, SVG, and WebM files</li> </ul>"},{"location":"bash/development/fixImgExt.html#safety-features","title":"\ud83d\udee1\ufe0f Safety Features","text":"<ul> <li>Collision Prevention: Avoids overwriting existing files</li> <li>Incremental Naming: Uses <code>filename_0.ext</code>, <code>filename_1.ext</code> for conflicts</li> <li>Path Validation: Prevents path traversal attacks</li> <li>Backup Logging: Optional logging of all changes made</li> </ul>"},{"location":"bash/development/fixImgExt.html#detailed-reporting","title":"\ud83d\udcca Detailed Reporting","text":"<ul> <li>Progress Feedback: Shows what files are being processed</li> <li>Change Logging: Optional logging to <code>fixImgExt_info.txt</code></li> <li>Detailed View: Optional verbose output showing file analysis</li> <li>Statistics: Reports successful corrections and any issues</li> </ul>"},{"location":"bash/development/fixImgExt.html#supported-formats","title":"Supported Formats","text":"Format Extensions Description JPEG <code>.jpeg</code>, <code>.jpg</code> Standard photo format PNG <code>.png</code> Lossless web format GIF <code>.gif</code> Animated/web graphics TIFF <code>.tif</code>, <code>.tiff</code> Professional/print format BMP <code>.bmp</code> Windows bitmap PSD <code>.psd</code> Adobe Photoshop XCF <code>.xcf</code> GIMP native format SVG <code>.svg</code> Vector graphics WebM <code>.webm</code> Web video/animation"},{"location":"bash/development/fixImgExt.html#how-it-works","title":"How It Works","text":""},{"location":"bash/development/fixImgExt.html#file-analysis-process","title":"File Analysis Process","text":"<ol> <li>Input Validation: Verifies file/directory exists and is accessible</li> <li>Content Detection: Uses <code>file</code> command to determine actual format</li> <li>Extension Matching: Compares current extension with detected format</li> <li>Conflict Resolution: Handles naming conflicts with incremental naming</li> <li>Safe Renaming: Performs the file rename operation</li> <li>Logging: Records changes if verbose logging enabled</li> </ol>"},{"location":"bash/development/fixImgExt.html#directory-processing_1","title":"Directory Processing","text":"<ol> <li>Path Traversal: Walks through directory structure (recursive if <code>-r</code> specified)</li> <li>File Filtering: Processes all files, not just those with image extensions</li> <li>Batch Processing: Handles multiple files efficiently</li> <li>Progress Reporting: Provides feedback on processing status</li> </ol>"},{"location":"bash/development/fixImgExt.html#configuration","title":"Configuration","text":""},{"location":"bash/development/fixImgExt.html#logging-configuration","title":"Logging Configuration","text":"<ul> <li>Log File: <code>fixImgExt_info.txt</code> in current directory</li> <li>Log Format: Lists all successfully corrected files</li> <li>Append Mode: Each run appends to existing log file</li> </ul>"},{"location":"bash/development/fixImgExt.html#processing-options","title":"Processing Options","text":"<ul> <li>Recursive Mode: Process subdirectories when using <code>-d</code> option</li> <li>Verbose Mode: Show detailed file information during processing</li> <li>Logging Mode: Record all successful corrections to log file</li> </ul>"},{"location":"bash/development/fixImgExt.html#output-examples","title":"Output Examples","text":""},{"location":"bash/development/fixImgExt.html#standard-output","title":"Standard Output","text":"<pre><code>Corrected!    /path/to/file.wrong    /path/to/file.jpg\nInfo!         No change needed       file.png\nWarning!      Currently supported formats: JPEG, GIF, PNG, TIFF, BMP, GIMP XCF, PSD, SVG, WebM\n</code></pre>"},{"location":"bash/development/fixImgExt.html#detailed-output-with-s","title":"Detailed Output (with <code>-s</code>)","text":"<pre><code>---------------------------------------------------------------------------------------\n  file path:-               /Users/alex/image.wrong\n  dir:-                     /Users/alex\n  file name with ext:-      image.wrong\n  file name:-               image\n---------------------------------------------------------------------------------------\nCorrected!    /Users/alex/image.wrong    /Users/alex/image.jpg\n</code></pre>"},{"location":"bash/development/fixImgExt.html#log-file-content-with-v","title":"Log File Content (with <code>-v</code>)","text":"<pre><code>--------------------------------NEW RUN--------------------------------\n/Users/alex/Pictures/photo.jpg\n/Users/alex/Pictures/graphic.png\n/Users/alex/Pictures/design.psd\n</code></pre>"},{"location":"bash/development/fixImgExt.html#integration","title":"Integration","text":""},{"location":"bash/development/fixImgExt.html#with-media-workflows","title":"With Media Workflows","text":"<pre><code># Process camera imports\n./fixImgExt.sh -d -r -v ~/Pictures/$(date +%Y-%m)/\n\n# Clean up download directory\n./fixImgExt.sh -d -v ~/Downloads/\n</code></pre>"},{"location":"bash/development/fixImgExt.html#automated-processing","title":"Automated Processing","text":"<pre><code>#!/bin/bash\n# Daily image cleanup script\nIMPORT_DIR=\"~/Pictures/Daily_Import\"\nLOG_FILE=\"/var/log/image_fixes.log\"\n\n./fixImgExt.sh -d -r -v \"$IMPORT_DIR\"\necho \"$(date): Processed $IMPORT_DIR\" &gt;&gt; \"$LOG_FILE\"\n</code></pre>"},{"location":"bash/development/fixImgExt.html#project-workflows","title":"Project Workflows","text":"<pre><code># Fix extensions in design project\n./fixImgExt.sh -d -r -s ~/Projects/client_work/assets/\n\n# Process web asset directory\n./fixImgExt.sh -d -v ~/Web_Projects/images/\n</code></pre>"},{"location":"bash/development/fixImgExt.html#best-practices","title":"Best Practices","text":""},{"location":"bash/development/fixImgExt.html#before-processing","title":"Before Processing","text":"<ol> <li>Backup Important Files: Make backups before batch processing</li> <li>Test on Small Set: Try on a few files before large batch operations</li> <li>Check Permissions: Ensure write access to target directories</li> <li>Review File Types: Understand what formats you're working with</li> </ol>"},{"location":"bash/development/fixImgExt.html#during-processing","title":"During Processing","text":"<ol> <li>Use Verbose Mode: Enable <code>-v</code> for logging important changes</li> <li>Monitor Output: Watch for warnings about unsupported formats</li> <li>Check Progress: Use <code>-s</code> for detailed view on complex operations</li> <li>Handle Conflicts: Be aware of incremental naming for duplicates</li> </ol>"},{"location":"bash/development/fixImgExt.html#after-processing","title":"After Processing","text":"<ol> <li>Review Log File: Check <code>fixImgExt_info.txt</code> for list of changes</li> <li>Verify Results: Spot-check corrected files</li> <li>Clean Up: Remove log file if no longer needed</li> <li>Document Changes: Keep record of batch operations performed</li> </ol>"},{"location":"bash/development/fixImgExt.html#error-handling","title":"Error Handling","text":""},{"location":"bash/development/fixImgExt.html#input-validation","title":"Input Validation","text":"<ul> <li>File Existence: Verifies files exist before processing</li> <li>Directory Access: Checks directory permissions</li> <li>Path Safety: Prevents directory traversal attacks</li> </ul>"},{"location":"bash/development/fixImgExt.html#processing-errors","title":"Processing Errors","text":"<ul> <li>Unsupported Formats: Clear warnings for unrecognized file types</li> <li>Permission Issues: Graceful handling of read-only files</li> <li>Naming Conflicts: Automatic resolution with incremental naming</li> </ul>"},{"location":"bash/development/fixImgExt.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"bash/development/fixImgExt.html#no-changes-made","title":"No Changes Made","text":"<ul> <li>Check that files actually have incorrect extensions</li> <li>Verify file formats are supported</li> <li>Ensure write permissions in target directory</li> </ul>"},{"location":"bash/development/fixImgExt.html#permission-denied-errors","title":"Permission Denied Errors","text":"<ul> <li>Run with appropriate file system permissions</li> <li>Check that files are not locked by other applications</li> <li>Verify directory write access</li> </ul>"},{"location":"bash/development/fixImgExt.html#unexpected-results","title":"Unexpected Results","text":"<ul> <li>Some files may have ambiguous formats</li> <li>Hidden files or system files may be processed</li> <li>Network drives may have slower performance</li> </ul>"},{"location":"bash/development/fixImgExt.html#technical-details","title":"Technical Details","text":""},{"location":"bash/development/fixImgExt.html#dependencies","title":"Dependencies","text":"<ul> <li>file: Unix file type detection command</li> <li>bash: Modern bash shell with getopts support</li> <li>Shared Libraries: Uses common.sh for validation functions</li> </ul>"},{"location":"bash/development/fixImgExt.html#security-considerations","title":"Security Considerations","text":"<ul> <li>Path Validation: All file paths validated for safety</li> <li>No Arbitrary Execution: No dynamic command construction</li> <li>Safe Renaming: Atomic file operations where possible</li> </ul>"},{"location":"bash/development/fixImgExt.html#original-attribution","title":"Original Attribution","text":"<ul> <li>Original script by \"Ten Elite Brains\" atqueensu@gmail.com</li> <li>Enhanced by Alexander Kucera / babylondreams.de</li> </ul>"},{"location":"bash/development/fixImgExt.html#see-also","title":"See Also","text":"<ul> <li>Media Processing Tools - Related media utilities</li> <li>Common Functions - Shared validation functions</li> <li>Development Tools Overview - Other development utilities</li> </ul> <p>Script Location: <code>bash/development/fixImgExt.sh</code> Original Author: Ten Elite Brains Enhanced by: Alexander Kucera / babylondreams.de</p>"},{"location":"bash/development/version_up.html","title":"Version Incrementer (version_up.sh)","text":"<p>Automatically increment version numbers in version files with timestamp tracking and history maintenance.</p>"},{"location":"bash/development/version_up.html#overview","title":"Overview","text":"<p>The <code>version_up.sh</code> script provides automated version number management for projects. It intelligently increments semantic version numbers, maintains version history with timestamps, and creates new version files when needed. Perfect for release automation and project version tracking.</p>"},{"location":"bash/development/version_up.html#usage","title":"Usage","text":"<pre><code>version_up.sh [version_file]\n</code></pre>"},{"location":"bash/development/version_up.html#arguments","title":"Arguments","text":"Argument Type Description <code>version_file</code> Optional Path to version file (default: <code>version.txt</code>)"},{"location":"bash/development/version_up.html#options","title":"Options","text":"Option Description <code>-h, --help</code> Show help message and exit"},{"location":"bash/development/version_up.html#examples","title":"Examples","text":""},{"location":"bash/development/version_up.html#basic-usage","title":"Basic Usage","text":"<pre><code># Increment version in default version.txt file\n./version_up.sh\n\n# Increment version in custom file\n./version_up.sh my_version.txt\n\n# Increment project-specific version\n./version_up.sh ~/Projects/myapp/VERSION\n</code></pre>"},{"location":"bash/development/version_up.html#development-workflow","title":"Development Workflow","text":"<pre><code># Pre-release version bump\n./version_up.sh src/version.txt\n\n# Build automation integration\n./version_up.sh &amp;&amp; make build\n\n# Multiple project management\n./version_up.sh frontend/version.txt\n./version_up.sh backend/version.txt\n./version_up.sh api/version.txt\n</code></pre>"},{"location":"bash/development/version_up.html#automation-scripts","title":"Automation Scripts","text":"<pre><code>#!/bin/bash\n# Release preparation script\n./version_up.sh\nNEW_VERSION=$(head -n 1 version.txt | cut -d' ' -f1)\necho \"Building release $NEW_VERSION\"\ngit add version.txt\ngit commit -m \"Bump version to $NEW_VERSION\"\ngit tag \"v$NEW_VERSION\"\n</code></pre>"},{"location":"bash/development/version_up.html#features","title":"Features","text":""},{"location":"bash/development/version_up.html#smart-version-management","title":"\ud83d\udd22 Smart Version Management","text":"<ul> <li>Semantic Versioning: Supports standard major.minor.patch format</li> <li>Intelligent Incrementing: Automatically increments the patch number</li> <li>Flexible Formats: Handles various version number formats</li> <li>History Preservation: Maintains complete version history</li> </ul>"},{"location":"bash/development/version_up.html#timestamp-tracking","title":"\ud83d\udcc5 Timestamp Tracking","text":"<ul> <li>Automatic Dating: Adds timestamp to each version entry</li> <li>ISO Format: Uses standard YYYY-MM-DD date format</li> <li>History Maintenance: Keeps chronological record of all versions</li> <li>Audit Trail: Complete history of when versions were created</li> </ul>"},{"location":"bash/development/version_up.html#safety-features","title":"\ud83d\udee1\ufe0f Safety Features","text":"<ul> <li>Format Validation: Validates version format before processing</li> <li>File Creation: Creates new version file if none exists</li> <li>Backup Preservation: Maintains existing version history</li> <li>Input Validation: Comprehensive validation of version formats</li> </ul>"},{"location":"bash/development/version_up.html#version-format-support","title":"Version Format Support","text":""},{"location":"bash/development/version_up.html#supported-formats","title":"Supported Formats","text":"<ul> <li><code>1.0.0</code> - Standard semantic versioning</li> <li><code>2.15.3</code> - Major.minor.patch</li> <li><code>0.1.0</code> - Pre-release versions</li> <li><code>10.20.30</code> - Large version numbers</li> </ul>"},{"location":"bash/development/version_up.html#version-increment-logic","title":"Version Increment Logic","text":"<pre><code>1.0.0 \u2192 1.0.1\n1.2.9 \u2192 1.2.10\n9.9.9 \u2192 9.9.10\n</code></pre> <p>The script automatically handles: - Carry Logic: Proper handling of digit overflow - Leading Zeros: Maintains consistent formatting - Patch Increment: Always increments the rightmost number</p>"},{"location":"bash/development/version_up.html#how-it-works","title":"How It Works","text":""},{"location":"bash/development/version_up.html#version-processing","title":"Version Processing","text":"<ol> <li>File Validation: Checks if version file exists, creates if needed</li> <li>Format Parsing: Reads and validates current version format</li> <li>Increment Calculation: Applies smart increment logic</li> <li>Timestamp Addition: Adds current date to new version</li> <li>History Update: Prepends new version to history</li> <li>File Writing: Saves updated version file</li> </ol>"},{"location":"bash/development/version_up.html#default-initialization","title":"Default Initialization","text":"<p>If no version file exists, creates one with: <pre><code>1.0.0 - 2025-07-05\n</code></pre></p>"},{"location":"bash/development/version_up.html#file-format","title":"File Format","text":""},{"location":"bash/development/version_up.html#version-file-structure","title":"Version File Structure","text":"<pre><code>1.2.1 - 2025-07-05\n1.2.0 - 2025-07-01\n1.1.9 - 2025-06-28\n1.1.8 - 2025-06-25\n</code></pre> <p>Each line contains: - Version Number: Semantic version in major.minor.patch format - Separator: <code>-</code> (space-dash-space) - Date: ISO format date (YYYY-MM-DD)</p>"},{"location":"bash/development/version_up.html#output-examples","title":"Output Examples","text":""},{"location":"bash/development/version_up.html#successful-execution","title":"Successful Execution","text":"<pre><code>Version incrementer working in: /Users/alex/Projects/myapp\nCurrent version: 1.2.0\nNew version: 1.2.1\nDate stamp: - 2025-07-05\n\u2713 Version updated successfully!\nVersion file updated: version.txt\n\nUpdated version history:\n  1.2.1 - 2025-07-05\n  1.2.0 - 2025-07-01\n  1.1.9 - 2025-06-28\n  1.1.8 - 2025-06-25\n  1.1.7 - 2025-06-20\n</code></pre>"},{"location":"bash/development/version_up.html#new-file-creation","title":"New File Creation","text":"<pre><code>Version incrementer working in: /Users/alex/Projects/newapp\nCreating new version file with initial version 1.0.0\nCurrent version: 1.0.0\nNew version: 1.0.1\n\u2713 Version updated successfully!\n</code></pre>"},{"location":"bash/development/version_up.html#configuration","title":"Configuration","text":""},{"location":"bash/development/version_up.html#environment-variables","title":"Environment Variables","text":"<p>No environment variables required. All configuration through file paths.</p>"},{"location":"bash/development/version_up.html#working-directory","title":"Working Directory","text":"<ul> <li>Script operates in the directory where it's executed</li> <li>Version files created/updated relative to current directory</li> <li>Reports working directory for confirmation</li> </ul>"},{"location":"bash/development/version_up.html#integration","title":"Integration","text":""},{"location":"bash/development/version_up.html#build-automation","title":"Build Automation","text":"<pre><code># Makefile integration\nversion:\n    ./version_up.sh\n    @echo \"New version: $$(head -n 1 version.txt | cut -d' ' -f1)\"\n\nrelease: version\n    @echo \"Building release...\"\n    # Build commands here\n</code></pre>"},{"location":"bash/development/version_up.html#git-workflows","title":"Git Workflows","text":"<pre><code>#!/bin/bash\n# Git release workflow\n./version_up.sh\nVERSION=$(head -n 1 version.txt | cut -d' ' -f1)\n\ngit add version.txt\ngit commit -m \"Bump version to $VERSION\"\ngit tag \"v$VERSION\"\ngit push origin main --tags\n</code></pre>"},{"location":"bash/development/version_up.html#cicd-integration","title":"CI/CD Integration","text":"<pre><code># GitHub Actions / CI integration\n- name: Increment Version\n  run: |\n    ./version_up.sh\n    echo \"NEW_VERSION=$(head -n 1 version.txt | cut -d' ' -f1)\" &gt;&gt; $GITHUB_ENV\n\n- name: Create Release\n  run: |\n    echo \"Creating release for version $NEW_VERSION\"\n</code></pre>"},{"location":"bash/development/version_up.html#multi-project-management","title":"Multi-Project Management","text":"<pre><code>#!/bin/bash\n# Update versions across multiple projects\nPROJECTS=(\"frontend\" \"backend\" \"api\" \"docs\")\n\nfor project in \"${PROJECTS[@]}\"; do\n    echo \"Updating $project version...\"\n    ./version_up.sh \"$project/version.txt\"\ndone\n</code></pre>"},{"location":"bash/development/version_up.html#best-practices","title":"Best Practices","text":""},{"location":"bash/development/version_up.html#version-file-management","title":"Version File Management","text":"<ol> <li>Consistent Location: Keep version files in predictable locations</li> <li>Version Control: Always commit version file changes</li> <li>Backup Strategy: Ensure version files are backed up</li> <li>Documentation: Document version increment policies</li> </ol>"},{"location":"bash/development/version_up.html#release-workflows","title":"Release Workflows","text":"<ol> <li>Pre-Release Testing: Test thoroughly before version increment</li> <li>Atomic Operations: Combine version increment with related tasks</li> <li>Tag Creation: Create git tags for version milestones</li> <li>Changelog Updates: Update changelogs alongside version increments</li> </ol>"},{"location":"bash/development/version_up.html#automation-guidelines","title":"Automation Guidelines","text":"<ol> <li>Script Integration: Integrate with build and release scripts</li> <li>Error Handling: Handle version increment failures gracefully</li> <li>Validation: Verify version format before automated increments</li> <li>Logging: Log version changes for audit purposes</li> </ol>"},{"location":"bash/development/version_up.html#error-handling","title":"Error Handling","text":""},{"location":"bash/development/version_up.html#input-validation","title":"Input Validation","text":"<ul> <li>File Format: Validates version file format before processing</li> <li>Version Format: Ensures version follows expected pattern</li> <li>File Permissions: Checks write access to version file</li> <li>Directory Access: Validates working directory access</li> </ul>"},{"location":"bash/development/version_up.html#error-scenarios","title":"Error Scenarios","text":"<ul> <li>Invalid Format: \"Invalid version format in version.txt: 'bad-format'\"</li> <li>Permission Denied: \"Failed to update version file\"</li> <li>Missing Directory: Script reports working directory and creates files appropriately</li> </ul>"},{"location":"bash/development/version_up.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"bash/development/version_up.html#version-format-issues","title":"Version Format Issues","text":"<ul> <li>Ensure version follows major.minor.patch format</li> <li>Check for extra characters or spaces in version file</li> <li>Verify file encoding (should be plain text)</li> </ul>"},{"location":"bash/development/version_up.html#file-permission-problems","title":"File Permission Problems","text":"<ul> <li>Check write permissions on version file and directory</li> <li>Ensure version file is not locked by other applications</li> <li>Verify disk space for file updates</li> </ul>"},{"location":"bash/development/version_up.html#integration-issues","title":"Integration Issues","text":"<ul> <li>Test version increment manually before automation</li> <li>Verify file paths in automated scripts</li> <li>Check that working directory is correct</li> </ul>"},{"location":"bash/development/version_up.html#technical-details","title":"Technical Details","text":""},{"location":"bash/development/version_up.html#dependencies","title":"Dependencies","text":"<ul> <li>bash: Modern bash shell</li> <li>date: Standard Unix date command</li> <li>Shared Libraries: Uses common.sh for utility functions</li> </ul>"},{"location":"bash/development/version_up.html#algorithm-details","title":"Algorithm Details","text":"<pre><code># Version increment logic (simplified)\ndeclare -a part=( ${version//\\./ } )  # Split by dots\ndeclare -i carry=1\n\nfor (( CNTR=${#part[@]}-1; CNTR&gt;=0; CNTR-=1 )); do\n    new=$((part[CNTR]+carry))\n    # Handle overflow and carry logic\ndone\n</code></pre>"},{"location":"bash/development/version_up.html#security-considerations","title":"Security Considerations","text":"<ul> <li>Path Validation: All file paths validated before use</li> <li>Safe File Operations: Atomic file operations where possible</li> <li>Input Sanitization: Version format strictly validated</li> </ul>"},{"location":"bash/development/version_up.html#see-also","title":"See Also","text":"<ul> <li>App Builder - Create apps with version management</li> <li>Common Functions - Shared utility functions</li> <li>Development Tools Overview - Related development utilities</li> </ul> <p>Script Location: <code>bash/development/version_up.sh</code> Author: Alexander Kucera / babylondreams.de</p>"},{"location":"bash/lib/common.html","title":"Common Functions Library (common.sh)","text":"<p>Core utility functions providing validation, timestamps, logging, and cross-platform compatibility for all bash scripts.</p>"},{"location":"bash/lib/common.html#overview","title":"Overview","text":"<p>The common functions library provides essential utilities used across all bash scripts, including input validation, timestamp generation, logging capabilities, and platform detection. This library ensures consistent behavior and reduces code duplication.</p>"},{"location":"bash/lib/common.html#key-functions","title":"Key Functions","text":""},{"location":"bash/lib/common.html#validation-functions","title":"Validation Functions","text":""},{"location":"bash/lib/common.html#validate_file","title":"<code>validate_file()</code>","text":"<p><pre><code>validate_file \"path/to/file\" \"description\"\n</code></pre> Validates that a file exists and is readable.</p> <ul> <li>Parameters: file_path, description</li> <li>Returns: 0 if valid, 1 if invalid</li> <li>Features: Comprehensive error reporting, path safety checks</li> </ul>"},{"location":"bash/lib/common.html#validate_directory","title":"<code>validate_directory()</code>","text":"<p><pre><code>validate_directory \"path/to/dir\" \"description\"\n</code></pre> Validates that a directory exists and is accessible.</p> <ul> <li>Parameters: directory_path, description</li> <li>Returns: 0 if valid, 1 if invalid</li> <li>Features: Permission checking, clear error messages</li> </ul>"},{"location":"bash/lib/common.html#validate_command","title":"<code>validate_command()</code>","text":"<p><pre><code>validate_command \"ffmpeg\" \"FFmpeg\"\n</code></pre> Validates that a command is available in the system PATH.</p> <ul> <li>Parameters: command_name, display_name</li> <li>Returns: 0 if available, 1 if missing</li> <li>Features: Installation guidance, dependency checking</li> </ul>"},{"location":"bash/lib/common.html#timestamp-functions","title":"Timestamp Functions","text":""},{"location":"bash/lib/common.html#get_timestamp","title":"<code>get_timestamp()</code>","text":"<p><pre><code>timestamp=$(get_timestamp)\n</code></pre> Generates formatted timestamps for logging and reporting.</p> <ul> <li>Returns: Formatted timestamp string</li> <li>Format: \"Monday, 05.07.2025 13:45:30\"</li> <li>Cross-platform: Works on macOS and Linux</li> </ul>"},{"location":"bash/lib/common.html#calculate_duration","title":"<code>calculate_duration()</code>","text":"<p><pre><code>duration=$(calculate_duration \"$start_time\" \"$end_time\")\n</code></pre> Calculates formatted duration between two timestamps.</p> <ul> <li>Parameters: start_epoch, end_epoch</li> <li>Returns: Formatted duration (e.g., \"2h:35m:42s\")</li> <li>Features: Human-readable format, zero-padding</li> </ul>"},{"location":"bash/lib/common.html#logging-functions","title":"Logging Functions","text":""},{"location":"bash/lib/common.html#log_message","title":"<code>log_message()</code>","text":"<p><pre><code>log_message \"Important event occurred\" \"app.log\"\n</code></pre> Writes timestamped messages to log files.</p> <ul> <li>Parameters: message, log_filename</li> <li>Features: Automatic timestamping, safe file operations</li> <li>Location: Logs written to current directory</li> </ul>"},{"location":"bash/lib/common.html#utility-functions","title":"Utility Functions","text":""},{"location":"bash/lib/common.html#get_script_dir","title":"<code>get_script_dir()</code>","text":"<p><pre><code>script_directory=$(get_script_dir)\n</code></pre> Returns the directory containing the calling script.</p> <ul> <li>Returns: Absolute path to script directory</li> <li>Use Cases: Relative path resolution, resource location</li> </ul>"},{"location":"bash/lib/common.html#parse_filename","title":"<code>parse_filename()</code>","text":"<p><pre><code>parse_filename \"/path/to/file.ext\" basename extension\n</code></pre> Safely parses filename components.</p> <ul> <li>Parameters: filepath, basename_var, extension_var</li> <li>Features: Extension extraction, path handling</li> </ul>"},{"location":"bash/lib/common.html#platform-detection","title":"Platform Detection","text":""},{"location":"bash/lib/common.html#is_macos","title":"<code>is_macos()</code>","text":"<p><pre><code>if is_macos; then\n    echo \"Running on macOS\"\nfi\n</code></pre> Detects macOS platform for platform-specific operations.</p> <ul> <li>Returns: 0 if macOS, 1 if other platform</li> <li>Use Cases: Platform-specific command selection</li> </ul>"},{"location":"bash/lib/common.html#is_linux","title":"<code>is_linux()</code>","text":"<p><pre><code>if is_linux; then\n    echo \"Running on Linux\"\nfi\n</code></pre> Detects Linux platform.</p> <ul> <li>Returns: 0 if Linux, 1 if other platform</li> </ul>"},{"location":"bash/lib/common.html#usage-examples","title":"Usage Examples","text":""},{"location":"bash/lib/common.html#basic-validation","title":"Basic Validation","text":"<pre><code>#!/bin/bash\nsource \"lib/common.sh\"\n\n# Validate input file\nif ! validate_file \"$1\" \"input video\"; then\n    exit 1\nfi\n\n# Validate output directory\nif ! validate_directory \"$OUTPUT_DIR\" \"output directory\"; then\n    exit 1\nfi\n</code></pre>"},{"location":"bash/lib/common.html#logging-with-timestamps","title":"Logging with Timestamps","text":"<pre><code>#!/bin/bash\nsource \"lib/common.sh\"\n\nLOG_FILE=\"processing.log\"\n\nlog_message \"Processing started\" \"$LOG_FILE\"\n# ... processing work ...\nlog_message \"Processing completed successfully\" \"$LOG_FILE\"\n</code></pre>"},{"location":"bash/lib/common.html#duration-tracking","title":"Duration Tracking","text":"<pre><code>#!/bin/bash\nsource \"lib/common.sh\"\n\nSTART_TIME=\"$(date +%s)\"\necho \"Started at: $(get_timestamp)\"\n\n# ... long running process ...\n\nEND_TIME=\"$(date +%s)\"\nDURATION=\"$(calculate_duration \"$START_TIME\" \"$END_TIME\")\"\necho \"Completed in: $DURATION\"\n</code></pre>"},{"location":"bash/lib/common.html#cross-platform-operations","title":"Cross-Platform Operations","text":"<pre><code>#!/bin/bash\nsource \"lib/common.sh\"\n\nif is_macos; then\n    OPEN_CMD=\"open\"\n    DATE_CMD=\"date -j\"\nelif is_linux; then\n    OPEN_CMD=\"xdg-open\"\n    DATE_CMD=\"date\"\nelse\n    echo \"Unsupported platform\"\n    exit 1\nfi\n</code></pre>"},{"location":"bash/lib/common.html#error-handling","title":"Error Handling","text":"<p>All functions provide comprehensive error handling:</p> <ul> <li>Input Validation: Parameters checked before use</li> <li>Error Reporting: Clear, descriptive error messages</li> <li>Safe Defaults: Graceful handling of missing parameters</li> <li>Return Codes: Consistent 0/1 return codes for scripting</li> </ul>"},{"location":"bash/lib/common.html#security-features","title":"Security Features","text":"<ul> <li>Path Validation: All file paths validated for safety</li> <li>No Arbitrary Execution: No dynamic command construction</li> <li>Input Sanitization: All inputs sanitized before use</li> <li>Safe File Operations: Atomic file operations where possible</li> </ul>"},{"location":"bash/lib/common.html#integration","title":"Integration","text":""},{"location":"bash/lib/common.html#library-loading","title":"Library Loading","text":"<pre><code># Standard library loading pattern\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" &amp;&amp; pwd)\"\nsource \"${SCRIPT_DIR}/../lib/common.sh\"\n</code></pre>"},{"location":"bash/lib/common.html#function-dependencies","title":"Function Dependencies","text":"<p>Some functions depend on others: - <code>log_message()</code> uses <code>get_timestamp()</code> - <code>calculate_duration()</code> uses cross-platform date handling - All validation functions use consistent error reporting</p>"},{"location":"bash/lib/common.html#best-practices","title":"Best Practices","text":""},{"location":"bash/lib/common.html#function-usage","title":"Function Usage","text":"<ol> <li>Always Check Return Codes: Use return codes for error handling</li> <li>Provide Descriptions: Use descriptive names in validation calls</li> <li>Log Important Events: Use logging for audit trails</li> <li>Handle Platform Differences: Use platform detection appropriately</li> </ol>"},{"location":"bash/lib/common.html#error-handling_1","title":"Error Handling","text":"<ol> <li>Validate Early: Check inputs before processing</li> <li>Fail Fast: Exit on validation errors</li> <li>Clear Messages: Provide helpful error descriptions</li> <li>Consistent Patterns: Use similar error handling across scripts</li> </ol>"},{"location":"bash/lib/common.html#see-also","title":"See Also","text":"<ul> <li>Media Functions - Media-specific utilities</li> <li>System Functions - System information functions</li> <li>Bash Scripts Overview - Integration patterns</li> </ul> <p>Script Location: <code>bash/lib/common.sh</code> Author: Alexander Kucera / babylondreams.de</p>"},{"location":"bash/lib/media_functions.html","title":"Media Functions Library (media_functions.sh)","text":"<p>Specialized functions for media processing, codec configuration, and format validation used by all media conversion scripts.</p>"},{"location":"bash/lib/media_functions.html#overview","title":"Overview","text":"<p>Provides optimized codec configurations, media file validation, and format-specific utilities for professional video and audio processing workflows. Used by all media conversion scripts to ensure consistent quality and compatibility.</p>"},{"location":"bash/lib/media_functions.html#key-functions","title":"Key Functions","text":""},{"location":"bash/lib/media_functions.html#codec-configuration","title":"Codec Configuration","text":""},{"location":"bash/lib/media_functions.html#setup_h264_codec","title":"<code>setup_h264_codec()</code>","text":"<p><pre><code>setup_h264_codec quality max_bitrate resolution\n</code></pre> Configures optimized H.264 encoding parameters.</p> <ul> <li>Parameters: quality (CRF), max_bitrate (kbps), resolution</li> <li>Returns: Sets global codec variables</li> <li>Features: Professional presets, bitrate limiting, quality optimization</li> </ul>"},{"location":"bash/lib/media_functions.html#setup_prores_codec","title":"<code>setup_prores_codec()</code>","text":"<p><pre><code>setup_prores_codec format quality resolution\n</code></pre> Configures Apple ProRes encoding parameters.</p> <ul> <li>Parameters: format (0-4), quality, resolution</li> <li>Returns: Sets ProRes-specific variables</li> <li>Formats: Proxy, LT, Standard, HQ, 4444</li> </ul>"},{"location":"bash/lib/media_functions.html#validation-functions","title":"Validation Functions","text":""},{"location":"bash/lib/media_functions.html#validate_media_file","title":"<code>validate_media_file()</code>","text":"<p><pre><code>validate_media_file \"path/to/video.mov\"\n</code></pre> Validates media files and checks format compatibility.</p> <ul> <li>Parameters: file_path</li> <li>Returns: 0 if valid, 1 if invalid</li> <li>Features: Format detection, codec verification</li> </ul>"},{"location":"bash/lib/media_functions.html#validate_sequence_pattern","title":"<code>validate_sequence_pattern()</code>","text":"<p><pre><code>validate_sequence_pattern \"frames_%04d.jpg\"\n</code></pre> Validates image sequence naming patterns.</p> <ul> <li>Parameters: sequence_pattern</li> <li>Returns: 0 if valid pattern, 1 if invalid</li> <li>Features: FFmpeg pattern validation</li> </ul>"},{"location":"bash/lib/media_functions.html#format-utilities","title":"Format Utilities","text":""},{"location":"bash/lib/media_functions.html#parse_sequence_filename","title":"<code>parse_sequence_filename()</code>","text":"<p><pre><code>parse_sequence_filename \"render_001.exr\" base_name frame_number\n</code></pre> Extracts components from sequence filenames.</p> <ul> <li>Parameters: filename, basename_var, frame_var</li> <li>Features: Frame number extraction, format identification</li> </ul>"},{"location":"bash/lib/media_functions.html#get_media_info","title":"<code>get_media_info()</code>","text":"<p><pre><code>get_media_info \"video.mov\" info_array\n</code></pre> Retrieves comprehensive media file information.</p> <ul> <li>Parameters: file_path, associative_array</li> <li>Returns: Populates array with metadata</li> <li>Information: Duration, resolution, codec, bitrate</li> </ul>"},{"location":"bash/lib/media_functions.html#codec-configurations","title":"Codec Configurations","text":""},{"location":"bash/lib/media_functions.html#h264-settings","title":"H.264 Settings","text":"<pre><code># Professional H.264 configuration\nCODEC=\"libx264\"\nPRESET=\"medium\"\nPROFILE=\"high\"\nLEVEL=\"4.0\"\nPIXEL_FORMAT=\"yuv420p\"\n</code></pre>"},{"location":"bash/lib/media_functions.html#prores-settings","title":"ProRes Settings","text":"Format Profile Quality Use Case 0 Proxy Lower quality Offline editing 1 LT Good quality Standard editing 2 Standard High quality General production 3 HQ Higher quality Professional delivery 4 4444 Highest quality VFX, alpha channel"},{"location":"bash/lib/media_functions.html#usage-examples","title":"Usage Examples","text":""},{"location":"bash/lib/media_functions.html#h264-encoding-setup","title":"H.264 Encoding Setup","text":"<pre><code>#!/bin/bash\nsource \"lib/media_functions.sh\"\n\n# Configure H.264 for web delivery\nsetup_h264_codec 22 8000 \"1280x720\"\n\n# Use configured settings\nffmpeg -i input.mov \\\n       -c:v \"$H264_CODEC\" \\\n       -crf \"$H264_QUALITY\" \\\n       -maxrate \"$H264_MAXRATE\" \\\n       -s \"$H264_RESOLUTION\" \\\n       output.mp4\n</code></pre>"},{"location":"bash/lib/media_functions.html#prores-workflow","title":"ProRes Workflow","text":"<pre><code>#!/bin/bash\nsource \"lib/media_functions.sh\"\n\n# Configure ProRes 4444 for VFX\nsetup_prores_codec 4 18 \"2048x1556\"\n\n# Validate input sequence\nif validate_sequence_pattern \"vfx_%05d.exr\"; then\n    # Process with ProRes settings\n    ffmpeg -i \"vfx_%05d.exr\" \\\n           -c:v \"$PRORES_CODEC\" \\\n           -profile:v \"$PRORES_PROFILE\" \\\n           master.mov\nfi\n</code></pre>"},{"location":"bash/lib/media_functions.html#media-validation","title":"Media Validation","text":"<pre><code>#!/bin/bash\nsource \"lib/media_functions.sh\"\n\n# Validate input media\nif validate_media_file \"$INPUT_FILE\"; then\n    echo \"\u2713 Input file validated\"\n\n    # Get media information\n    declare -A media_info\n    get_media_info \"$INPUT_FILE\" media_info\n\n    echo \"Duration: ${media_info[duration]}\"\n    echo \"Resolution: ${media_info[width]}x${media_info[height]}\"\n    echo \"Codec: ${media_info[codec]}\"\nelse\n    echo \"\u2717 Invalid input file\"\n    exit 1\nfi\n</code></pre>"},{"location":"bash/lib/media_functions.html#quality-presets","title":"Quality Presets","text":""},{"location":"bash/lib/media_functions.html#web-delivery","title":"Web Delivery","text":"<pre><code># Optimized for web streaming\nsetup_h264_codec 23 8000 \"1920x1080\"  # HD web\nsetup_h264_codec 25 5000 \"1280x720\"   # HD mobile\nsetup_h264_codec 28 2000 \"854x480\"    # SD mobile\n</code></pre>"},{"location":"bash/lib/media_functions.html#professional-delivery","title":"Professional Delivery","text":"<pre><code># Broadcast/professional quality\nsetup_h264_codec 18 15000 \"1920x1080\"  # HD broadcast\nsetup_h264_codec 16 50000 \"3840x2160\"  # 4K professional\nsetup_prores_codec 3 18 \"1920x1080\"    # ProRes HQ\n</code></pre>"},{"location":"bash/lib/media_functions.html#archivemaster","title":"Archive/Master","text":"<pre><code># Highest quality for archival\nsetup_prores_codec 4 16 \"4096x2160\"    # ProRes 4444 4K\nsetup_h264_codec 16 60000 \"3840x2160\"  # H.264 4K master\n</code></pre>"},{"location":"bash/lib/media_functions.html#format-support","title":"Format Support","text":""},{"location":"bash/lib/media_functions.html#input-formats","title":"Input Formats","text":"<ul> <li>Video: MOV, MP4, AVI, MKV, M4V</li> <li>Images: JPEG, PNG, TIFF, EXR, DPX, BMP</li> <li>Audio: WAV, AIFF, MP3, M4A, FLAC</li> </ul>"},{"location":"bash/lib/media_functions.html#output-formats","title":"Output Formats","text":"<ul> <li>H.264: MP4, MOV containers</li> <li>ProRes: MOV containers (macOS/professional)</li> <li>WebM: VP8/VP9 for web delivery</li> </ul>"},{"location":"bash/lib/media_functions.html#error-handling","title":"Error Handling","text":""},{"location":"bash/lib/media_functions.html#validation-errors","title":"Validation Errors","text":"<pre><code># File validation with error reporting\nif ! validate_media_file \"$input\"; then\n    echo \"Error: Invalid media file: $input\"\n    echo \"Supported formats: MOV, MP4, AVI, MKV\"\n    exit 1\nfi\n</code></pre>"},{"location":"bash/lib/media_functions.html#codec-errors","title":"Codec Errors","text":"<pre><code># Codec availability checking\nif ! command -v ffmpeg &gt;/dev/null 2&gt;&amp;1; then\n    echo \"Error: FFmpeg not found\"\n    echo \"Install FFmpeg to use media processing functions\"\n    exit 1\nfi\n</code></pre>"},{"location":"bash/lib/media_functions.html#performance-optimization","title":"Performance Optimization","text":""},{"location":"bash/lib/media_functions.html#multi-threading","title":"Multi-threading","text":"<pre><code># Optimize for available CPU cores\nTHREAD_COUNT=\"$(nproc 2&gt;/dev/null || sysctl -n hw.ncpu 2&gt;/dev/null || echo 4)\"\nffmpeg -threads \"$THREAD_COUNT\" ...\n</code></pre>"},{"location":"bash/lib/media_functions.html#hardware-acceleration","title":"Hardware Acceleration","text":"<pre><code># macOS VideoToolbox acceleration\nif is_macos &amp;&amp; check_videotoolbox_support; then\n    CODEC=\"h264_videotoolbox\"\nelse\n    CODEC=\"libx264\"\nfi\n</code></pre>"},{"location":"bash/lib/media_functions.html#integration","title":"Integration","text":""},{"location":"bash/lib/media_functions.html#library-dependencies","title":"Library Dependencies","text":"<pre><code># Required libraries\nsource \"${SCRIPT_DIR}/../lib/common.sh\"      # Core functions\nsource \"${SCRIPT_DIR}/../lib/media_functions.sh\"  # Media-specific\n</code></pre>"},{"location":"bash/lib/media_functions.html#cross-platform-support","title":"Cross-Platform Support","text":"<ul> <li>macOS: Native ProRes support, VideoToolbox acceleration</li> <li>Linux: Standard FFmpeg codecs, software encoding</li> <li>Windows: Compatible via WSL or native FFmpeg</li> </ul>"},{"location":"bash/lib/media_functions.html#see-also","title":"See Also","text":"<ul> <li>Common Functions - Core utility functions</li> <li>Media Processing Scripts - Scripts using these functions</li> <li>System Functions - System information utilities</li> </ul> <p>Script Location: <code>bash/lib/media_functions.sh</code> Author: Alexander Kucera / babylondreams.de</p>"},{"location":"bash/lib/system_functions.html","title":"System Functions Library (system_functions.sh)","text":"<p>System information, memory management, and platform-specific utilities for system administration and monitoring scripts.</p>"},{"location":"bash/lib/system_functions.html#overview","title":"Overview","text":"<p>Provides comprehensive system information gathering, memory management utilities, and cross-platform system operations. Used by system administration scripts for monitoring, maintenance, and automation tasks.</p>"},{"location":"bash/lib/system_functions.html#key-functions","title":"Key Functions","text":""},{"location":"bash/lib/system_functions.html#system-information","title":"System Information","text":""},{"location":"bash/lib/system_functions.html#get_system_info","title":"<code>get_system_info()</code>","text":"<p><pre><code>declare -A sys_info\nget_system_info sys_info\necho \"Hostname: ${sys_info[hostname]}\"\necho \"OS: ${sys_info[os]}\"\necho \"Architecture: ${sys_info[arch]}\"\n</code></pre> Retrieves comprehensive system information.</p> <ul> <li>Parameters: associative_array (passed by reference)</li> <li>Returns: Populates array with system details</li> <li>Information: hostname, OS version, architecture, kernel</li> </ul>"},{"location":"bash/lib/system_functions.html#get_memory_info","title":"<code>get_memory_info()</code>","text":"<p><pre><code>declare -A memory_info\nget_memory_info memory_info\necho \"Total RAM: ${memory_info[total_mb]}MB\"\necho \"Free RAM: ${memory_info[free_mb]}MB\"\necho \"Used RAM: ${memory_info[used_mb]}MB\"\n</code></pre> Retrieves detailed memory usage statistics.</p> <ul> <li>Parameters: associative_array (passed by reference)</li> <li>Returns: Memory statistics in MB</li> <li>Cross-platform: Works on macOS and Linux</li> </ul>"},{"location":"bash/lib/system_functions.html#memory-management","title":"Memory Management","text":""},{"location":"bash/lib/system_functions.html#purge_memory","title":"<code>purge_memory()</code>","text":"<p><pre><code>if purge_memory 5 15; then\n    echo \"Memory purged successfully\"\nelse\n    echo \"Memory purge not beneficial\"\nfi\n</code></pre> Intelligently purges inactive memory when beneficial.</p> <ul> <li>Parameters: min_ram_percent, min_inactive_percent</li> <li>Returns: 0 if purged, 1 if not needed</li> <li>Safety: Only purges when thresholds met</li> </ul>"},{"location":"bash/lib/system_functions.html#check_memory_pressure","title":"<code>check_memory_pressure()</code>","text":"<p><pre><code>if check_memory_pressure; then\n    echo \"System under memory pressure\"\n    # Take action\nfi\n</code></pre> Detects system memory pressure conditions.</p> <ul> <li>Returns: 0 if pressure detected, 1 if normal</li> <li>Use Cases: Proactive memory management</li> </ul>"},{"location":"bash/lib/system_functions.html#disk-management","title":"Disk Management","text":""},{"location":"bash/lib/system_functions.html#find_disk_by_label","title":"<code>find_disk_by_label()</code>","text":"<p><pre><code>device=$(find_disk_by_label \"Time Machine\")\nif [[ -n \"$device\" ]]; then\n    echo \"Found disk: $device\"\nfi\n</code></pre> Locates disk devices by volume label.</p> <ul> <li>Parameters: volume_label</li> <li>Returns: Device path (e.g., /dev/disk2s1)</li> <li>Platform: macOS-specific using diskutil</li> </ul>"},{"location":"bash/lib/system_functions.html#get_disk_usage","title":"<code>get_disk_usage()</code>","text":"<p><pre><code>declare -A disk_info\nget_disk_usage \"/\" disk_info\necho \"Available: ${disk_info[available]}GB\"\necho \"Used: ${disk_info[used_percent]}%\"\n</code></pre> Retrieves disk usage statistics.</p> <ul> <li>Parameters: mount_point, associative_array</li> <li>Returns: Usage statistics in human-readable format</li> </ul>"},{"location":"bash/lib/system_functions.html#process-management","title":"Process Management","text":""},{"location":"bash/lib/system_functions.html#check_process_running","title":"<code>check_process_running()</code>","text":"<p><pre><code>if check_process_running \"ffmpeg\"; then\n    echo \"FFmpeg is currently running\"\nfi\n</code></pre> Checks if a process is currently running.</p> <ul> <li>Parameters: process_name</li> <li>Returns: 0 if running, 1 if not</li> <li>Use Cases: Prevent concurrent operations</li> </ul>"},{"location":"bash/lib/system_functions.html#get_cpu_usage","title":"<code>get_cpu_usage()</code>","text":"<p><pre><code>cpu_percent=$(get_cpu_usage)\necho \"CPU Usage: ${cpu_percent}%\"\n</code></pre> Retrieves current CPU usage percentage.</p> <ul> <li>Returns: CPU usage as percentage</li> <li>Cross-platform: Adapted for different OS</li> </ul>"},{"location":"bash/lib/system_functions.html#application-management","title":"Application Management","text":""},{"location":"bash/lib/system_functions.html#list_applications","title":"<code>list_applications()</code>","text":"<p><pre><code>declare -a apps\nlist_applications apps\nfor app in \"${apps[@]}\"; do\n    echo \"Installed: $app\"\ndone\n</code></pre> Lists installed applications by category.</p> <ul> <li>Parameters: array (passed by reference)</li> <li>Returns: Array of application names</li> <li>Sources: /Applications, ~/Applications, Homebrew</li> </ul>"},{"location":"bash/lib/system_functions.html#check_homebrew_packages","title":"<code>check_homebrew_packages()</code>","text":"<p><pre><code>declare -a packages\ncheck_homebrew_packages packages\necho \"Homebrew packages: ${#packages[@]}\"\n</code></pre> Lists Homebrew packages and casks.</p> <ul> <li>Parameters: array (passed by reference)</li> <li>Returns: Array of package names</li> <li>Types: Both packages and casks</li> </ul>"},{"location":"bash/lib/system_functions.html#usage-examples","title":"Usage Examples","text":""},{"location":"bash/lib/system_functions.html#system-monitoring","title":"System Monitoring","text":"<pre><code>#!/bin/bash\nsource \"lib/system_functions.sh\"\n\n# Get system information\ndeclare -A sys_info\nget_system_info sys_info\n\necho \"System Report\"\necho \"=============\"\necho \"Host: ${sys_info[hostname]}\"\necho \"OS: ${sys_info[os_version]}\"\necho \"Uptime: ${sys_info[uptime]}\"\n\n# Memory status\ndeclare -A mem_info\nget_memory_info mem_info\necho \"Memory: ${mem_info[used_mb]}/${mem_info[total_mb]}MB\"\n</code></pre>"},{"location":"bash/lib/system_functions.html#automated-memory-management","title":"Automated Memory Management","text":"<pre><code>#!/bin/bash\nsource \"lib/system_functions.sh\"\n\n# Check memory pressure\nif check_memory_pressure; then\n    echo \"Memory pressure detected\"\n\n    # Get current memory info\n    declare -A mem_info\n    get_memory_info mem_info\n\n    # Purge if beneficial (5% free, 15% inactive minimum)\n    if purge_memory 5 15; then\n        echo \"Memory purged\"\n\n        # Get updated info\n        get_memory_info mem_info\n        echo \"Free memory after purge: ${mem_info[free_mb]}MB\"\n    else\n        echo \"Memory purge not beneficial\"\n    fi\nfi\n</code></pre>"},{"location":"bash/lib/system_functions.html#disk-space-monitoring","title":"Disk Space Monitoring","text":"<pre><code>#!/bin/bash\nsource \"lib/system_functions.sh\"\n\n# Check multiple mount points\nfor mount in \"/\" \"/var\" \"/tmp\"; do\n    if [[ -d \"$mount\" ]]; then\n        declare -A disk_info\n        get_disk_usage \"$mount\" disk_info\n\n        echo \"$mount: ${disk_info[used_percent]}% used\"\n\n        if [[ \"${disk_info[used_percent]%\\%}\" -gt 90 ]]; then\n            echo \"Warning: $mount is over 90% full\"\n        fi\n    fi\ndone\n</code></pre>"},{"location":"bash/lib/system_functions.html#application-inventory","title":"Application Inventory","text":"<pre><code>#!/bin/bash\nsource \"lib/system_functions.sh\"\n\necho \"Application Inventory\"\necho \"====================\"\n\n# System applications\ndeclare -a apps\nlist_applications apps\necho \"Applications found: ${#apps[@]}\"\n\n# Homebrew packages\ndeclare -a packages\ncheck_homebrew_packages packages\necho \"Homebrew packages: ${#packages[@]}\"\n</code></pre>"},{"location":"bash/lib/system_functions.html#cross-platform-support","title":"Cross-Platform Support","text":""},{"location":"bash/lib/system_functions.html#macos-specific-functions","title":"macOS-Specific Functions","text":"<ul> <li><code>find_disk_by_label()</code> - Uses diskutil</li> <li><code>purge_memory()</code> - Uses macOS purge command</li> <li><code>get_memory_info()</code> - Uses vm_stat</li> </ul>"},{"location":"bash/lib/system_functions.html#linux-specific-functions","title":"Linux-Specific Functions","text":"<ul> <li>Memory functions use /proc/meminfo</li> <li>Disk functions use df and lsblk</li> <li>Process functions use ps and proc filesystem</li> </ul>"},{"location":"bash/lib/system_functions.html#universal-functions","title":"Universal Functions","text":"<ul> <li><code>get_system_info()</code> - Adapts to platform</li> <li><code>check_process_running()</code> - Uses ps command</li> <li><code>get_cpu_usage()</code> - Platform-appropriate methods</li> </ul>"},{"location":"bash/lib/system_functions.html#performance-considerations","title":"Performance Considerations","text":""},{"location":"bash/lib/system_functions.html#memory-operations","title":"Memory Operations","text":"<ul> <li>Functions cache results when appropriate</li> <li>Expensive operations (like disk enumeration) minimized</li> <li>Memory info gathering optimized for frequent calls</li> </ul>"},{"location":"bash/lib/system_functions.html#process-monitoring","title":"Process Monitoring","text":"<ul> <li>Efficient process checking using appropriate tools</li> <li>Minimal overhead for status checks</li> <li>Batch operations when possible</li> </ul>"},{"location":"bash/lib/system_functions.html#error-handling","title":"Error Handling","text":""},{"location":"bash/lib/system_functions.html#graceful-degradation","title":"Graceful Degradation","text":"<pre><code># Handle missing tools gracefully\nif ! command -v diskutil &gt;/dev/null 2&gt;&amp;1; then\n    echo \"Warning: diskutil not available (macOS only)\"\n    return 1\nfi\n</code></pre>"},{"location":"bash/lib/system_functions.html#platform-detection","title":"Platform Detection","text":"<pre><code># Adapt to platform capabilities\nif is_macos; then\n    # macOS-specific implementation\nelif is_linux; then\n    # Linux-specific implementation\nelse\n    echo \"Unsupported platform\"\n    return 1\nfi\n</code></pre>"},{"location":"bash/lib/system_functions.html#security-considerations","title":"Security Considerations","text":"<ul> <li>Safe Command Execution: No arbitrary command construction</li> <li>Input Validation: All parameters validated</li> <li>Privilege Awareness: Functions respect user privileges</li> <li>Path Safety: All file operations use validated paths</li> </ul>"},{"location":"bash/lib/system_functions.html#see-also","title":"See Also","text":"<ul> <li>Common Functions - Core utility functions</li> <li>System Administration Scripts - Scripts using these functions</li> <li>Memory Purge Loop - Automated memory management</li> </ul> <p>Script Location: <code>bash/lib/system_functions.sh</code> Author: Alexander Kucera / babylondreams.de</p>"},{"location":"bash/lib/writeToLogAndEcho.html","title":"Log and Echo Utilities (writeToLogAndEcho.sh)","text":"<p>Simple logging utilities for writing messages to both console and log files, with flexible configuration options.</p>"},{"location":"bash/lib/writeToLogAndEcho.html#overview","title":"Overview","text":"<p>Provides convenient functions for dual output (console + log file) and log-only output. Based on proven patterns for bash logging, enhanced with modern error handling and configuration validation.</p>"},{"location":"bash/lib/writeToLogAndEcho.html#functions","title":"Functions","text":""},{"location":"bash/lib/writeToLogAndEcho.html#logmessage","title":"<code>log(message)</code>","text":"<p>Writes a message to the log file only.</p> <pre><code>log \"Processing started at $(date)\"\n</code></pre>"},{"location":"bash/lib/writeToLogAndEcho.html#messagemessage","title":"<code>message(message)</code>","text":"<p>Writes a message to both console and log file.</p> <pre><code>message \"Processing completed successfully\"\n</code></pre>"},{"location":"bash/lib/writeToLogAndEcho.html#usage","title":"Usage","text":""},{"location":"bash/lib/writeToLogAndEcho.html#as-sourced-library","title":"As Sourced Library","text":"<pre><code>#!/bin/bash\nsource \"lib/writeToLogAndEcho.sh\"\n\n# Set log file (optional - has default)\nexport LOG_FILE=\"/var/log/myapp.log\"\n\n# Log-only message\nlog \"Background process started\"\n\n# Console and log message\nmessage \"User action completed\"\n</code></pre>"},{"location":"bash/lib/writeToLogAndEcho.html#as-standalone-script","title":"As Standalone Script","text":"<pre><code># Run for demonstration\n./writeToLogAndEcho.sh\n\n# Shows example usage:\n# \"Echoed to console only\"\n# \"Written to log file only\"\n# \"To console and log\"\n</code></pre>"},{"location":"bash/lib/writeToLogAndEcho.html#configuration","title":"Configuration","text":""},{"location":"bash/lib/writeToLogAndEcho.html#environment-variables","title":"Environment Variables","text":""},{"location":"bash/lib/writeToLogAndEcho.html#log_file","title":"<code>LOG_FILE</code>","text":"<p>Sets the target log file location.</p> <pre><code>export LOG_FILE=\"/var/log/application.log\"\nexport LOG_FILE=\"${HOME}/logs/debug.log\"\nexport LOG_FILE=\"./processing.log\"\n</code></pre> <p>Default: <code>${HOME}/script.log</code> if not set</p>"},{"location":"bash/lib/writeToLogAndEcho.html#directory-validation","title":"Directory Validation","text":"<p>The script automatically: - Validates the log file directory exists - Creates parent directories if needed (when possible) - Reports errors for invalid log locations</p>"},{"location":"bash/lib/writeToLogAndEcho.html#examples","title":"Examples","text":""},{"location":"bash/lib/writeToLogAndEcho.html#application-logging","title":"Application Logging","text":"<pre><code>#!/bin/bash\nsource \"lib/writeToLogAndEcho.sh\"\n\nexport LOG_FILE=\"/var/log/backup.log\"\n\nmessage \"=== Backup Process Started ===\"\nlog \"Backup configuration loaded\"\n\nfor file in ~/Documents/*; do\n    log \"Processing: $file\"\n    # ... backup logic ...\ndone\n\nmessage \"=== Backup Process Completed ===\"\n</code></pre>"},{"location":"bash/lib/writeToLogAndEcho.html#debug-logging","title":"Debug Logging","text":"<pre><code>#!/bin/bash\nsource \"lib/writeToLogAndEcho.sh\"\n\nexport LOG_FILE=\"./debug_$(date +%Y%m%d).log\"\n\nmessage \"Debug session started\"\n\n# Verbose logging for troubleshooting\nlog \"Variable state: INPUT_DIR=$INPUT_DIR\"\nlog \"Environment: PATH=$PATH\"\n\nmessage \"Processing step 1\"\nlog \"Step 1: Validating inputs\"\n# ... processing ...\n\nmessage \"All steps completed\"\n</code></pre>"},{"location":"bash/lib/writeToLogAndEcho.html#service-integration","title":"Service Integration","text":"<pre><code>#!/bin/bash\n# Service startup script\nsource \"lib/writeToLogAndEcho.sh\"\n\nexport LOG_FILE=\"/var/log/service.log\"\n\nmessage \"Service starting up...\"\nlog \"Configuration file: $CONFIG_FILE\"\nlog \"PID: $$\"\n\n# ... service logic ...\n\nmessage \"Service ready - listening on port 8080\"\n</code></pre>"},{"location":"bash/lib/writeToLogAndEcho.html#integration-patterns","title":"Integration Patterns","text":""},{"location":"bash/lib/writeToLogAndEcho.html#with-error-handling","title":"With Error Handling","text":"<pre><code>#!/bin/bash\nsource \"lib/writeToLogAndEcho.sh\"\n\nexport LOG_FILE=\"./operation.log\"\n\nperform_operation() {\n    message \"Starting critical operation\"\n\n    if risky_command; then\n        log \"Operation succeeded\"\n        message \"\u2713 Critical operation completed\"\n    else\n        log \"Operation failed with exit code $?\"\n        message \"\u2717 Critical operation failed\"\n        return 1\n    fi\n}\n</code></pre>"},{"location":"bash/lib/writeToLogAndEcho.html#with-timestamped-logs","title":"With Timestamped Logs","text":"<pre><code>#!/bin/bash\nsource \"lib/writeToLogAndEcho.sh\"\nsource \"lib/common.sh\"  # For get_timestamp()\n\nexport LOG_FILE=\"./timestamped.log\"\n\n# Enhanced logging with timestamps\ntimestamped_log() {\n    local timestamp=$(get_timestamp)\n    log \"[$timestamp] $1\"\n}\n\ntimestamped_message() {\n    local timestamp=$(get_timestamp)\n    message \"[$timestamp] $1\"\n}\n\n# Usage\ntimestamped_message \"Process started\"\ntimestamped_log \"Configuration loaded from config.json\"\n</code></pre>"},{"location":"bash/lib/writeToLogAndEcho.html#batch-processing","title":"Batch Processing","text":"<pre><code>#!/bin/bash\nsource \"lib/writeToLogAndEcho.sh\"\n\nexport LOG_FILE=\"./batch_$(date +%Y%m%d_%H%M%S).log\"\n\nmessage \"=== Batch Processing Started ===\"\n\nfor item in \"${items[@]}\"; do\n    message \"Processing: $item\"\n    log \"  - Validation: $(validate_item \"$item\")\"\n    log \"  - Processing: $(process_item \"$item\")\"\n    log \"  - Result: Success\"\ndone\n\nmessage \"=== Batch Processing Completed ===\"\n</code></pre>"},{"location":"bash/lib/writeToLogAndEcho.html#best-practices","title":"Best Practices","text":""},{"location":"bash/lib/writeToLogAndEcho.html#log-file-management","title":"Log File Management","text":"<ol> <li>Descriptive Names: Use meaningful log file names</li> <li>Date/Time Stamps: Include timestamps in log filenames for rotation</li> <li>Appropriate Locations: Use <code>/var/log/</code> for system services, local directories for user scripts</li> <li>Permissions: Ensure write access to log directories</li> </ol>"},{"location":"bash/lib/writeToLogAndEcho.html#message-guidelines","title":"Message Guidelines","text":"<ol> <li>Log vs Message: Use <code>log()</code> for detailed info, <code>message()</code> for user-relevant updates</li> <li>Clear Formatting: Use consistent formatting for different message types</li> <li>Context Information: Include relevant context (timestamps, variables, etc.)</li> <li>Error Details: Log error codes and conditions for troubleshooting</li> </ol>"},{"location":"bash/lib/writeToLogAndEcho.html#integration-tips","title":"Integration Tips","text":"<ol> <li>Early Setup: Set LOG_FILE early in scripts</li> <li>Combine with Common Functions: Use with timestamp and validation functions</li> <li>Error Handling: Always check log file accessibility</li> <li>Cleanup: Consider log rotation for long-running processes</li> </ol>"},{"location":"bash/lib/writeToLogAndEcho.html#error-handling","title":"Error Handling","text":""},{"location":"bash/lib/writeToLogAndEcho.html#missing-log_file","title":"Missing LOG_FILE","text":"<p>If <code>LOG_FILE</code> is not set, the script: - Displays a warning - Uses default log file (<code>${HOME}/script.log</code>) - Continues operation normally</p>"},{"location":"bash/lib/writeToLogAndEcho.html#invalid-log-directory","title":"Invalid Log Directory","text":"<p>If the log directory doesn't exist or isn't writable: - Reports clear error message - Exits with error code 1 - Prevents further execution</p>"},{"location":"bash/lib/writeToLogAndEcho.html#permission-issues","title":"Permission Issues","text":"<p>For permission-denied scenarios: - Clear error reporting - Guidance on fixing permissions - Graceful script termination</p>"},{"location":"bash/lib/writeToLogAndEcho.html#technical-details","title":"Technical Details","text":""},{"location":"bash/lib/writeToLogAndEcho.html#dependencies","title":"Dependencies","text":"<ul> <li>Common Functions: Uses <code>validate_directory()</code> from common.sh</li> <li>Bash Features: Uses standard bash I/O redirection</li> <li>File Operations: Safe file writing with error checking</li> </ul>"},{"location":"bash/lib/writeToLogAndEcho.html#based-on","title":"Based On","text":"<ul> <li>Reference: http://stackoverflow.com/a/18462920</li> <li>Enhanced with modern error handling and validation</li> <li>Integrated with shared library ecosystem</li> </ul>"},{"location":"bash/lib/writeToLogAndEcho.html#security-considerations","title":"Security Considerations","text":"<ul> <li>Path Validation: Log file paths validated before use</li> <li>Safe Operations: No arbitrary command execution</li> <li>Input Sanitization: Log messages handled safely</li> </ul>"},{"location":"bash/lib/writeToLogAndEcho.html#see-also","title":"See Also","text":"<ul> <li>Common Functions - Core validation and utility functions</li> <li>System Functions - System information for enhanced logging</li> <li>Development Tools - Scripts using logging utilities</li> </ul> <p>Script Location: <code>bash/lib/writeToLogAndEcho.sh</code> Based On: http://stackoverflow.com/a/18462920 Enhanced by: Alexander Kucera / babylondreams.de</p>"},{"location":"bash/media/convert_images_to_h264.html","title":"Images to H.264 Converter (convert_images_to_h264.sh)","text":"<p>Convert image sequences to H.264 video format with professional encoding settings and configurable quality parameters.</p>"},{"location":"bash/media/convert_images_to_h264.html#overview","title":"Overview","text":"<p>The <code>convert_images_to_h264.sh</code> script transforms image sequences into high-quality H.264 video files using FFmpeg. It provides professional-grade encoding options with optimized settings for different resolution and quality requirements, making it ideal for animation, time-lapse, and video production workflows.</p>"},{"location":"bash/media/convert_images_to_h264.html#usage","title":"Usage","text":"<pre><code>convert_images_to_h264.sh &lt;path_to_file&gt; [resolution] [framerate] [quality] [max_bitrate]\n</code></pre>"},{"location":"bash/media/convert_images_to_h264.html#arguments","title":"Arguments","text":"Argument Type Description Default <code>path_to_file</code> Required Path to input image sequence or video file - <code>resolution</code> Optional Output resolution (e.g., 1920x1080) 1920x1080 <code>framerate</code> Optional Frame rate in fps 25 <code>quality</code> Optional Quality setting (lower = better quality) 20 <code>max_bitrate</code> Optional Maximum bitrate in kbps 10000"},{"location":"bash/media/convert_images_to_h264.html#options","title":"Options","text":"Option Description <code>-h, --help</code> Show help message and exit"},{"location":"bash/media/convert_images_to_h264.html#examples","title":"Examples","text":""},{"location":"bash/media/convert_images_to_h264.html#basic-image-sequence-conversion","title":"Basic Image Sequence Conversion","text":"<pre><code># Convert numbered image sequence\n./convert_images_to_h264.sh sequence.%04d.jpg\n\n# Convert with default settings (1920x1080, 25fps, quality 20)\n./convert_images_to_h264.sh frame_%03d.png\n</code></pre>"},{"location":"bash/media/convert_images_to_h264.html#custom-quality-settings","title":"Custom Quality Settings","text":"<pre><code># High quality for professional use\n./convert_images_to_h264.sh images.%04d.tiff 1920x1080 25 18 15000\n\n# Web-optimized version\n./convert_images_to_h264.sh sequence.%04d.jpg 1280x720 30 22 8000\n\n# 4K high-quality encode\n./convert_images_to_h264.sh frames.%05d.exr 3840x2160 24 16 50000\n</code></pre>"},{"location":"bash/media/convert_images_to_h264.html#different-input-formats","title":"Different Input Formats","text":"<pre><code># From TIFF sequence (professional photography)\n./convert_images_to_h264.sh photos_%04d.tiff 1920x1080 24 18 12000\n\n# From PNG sequence (animation/graphics)\n./convert_images_to_h264.sh animation_%03d.png 1920x1080 30 20 10000\n\n# From EXR sequence (VFX/rendering)\n./convert_images_to_h264.sh render_%05d.exr 2048x1556 24 16 20000\n</code></pre>"},{"location":"bash/media/convert_images_to_h264.html#features","title":"Features","text":""},{"location":"bash/media/convert_images_to_h264.html#professional-encoding","title":"\ud83c\udfa5 Professional Encoding","text":"<ul> <li>H.264 Codec: Industry-standard compression with excellent quality/size ratio</li> <li>Configurable Quality: CRF-based quality control for consistent results</li> <li>Bitrate Control: Maximum bitrate limiting for streaming/delivery requirements</li> <li>Frame Rate Flexibility: Support for any frame rate from 1fps to 120fps</li> </ul>"},{"location":"bash/media/convert_images_to_h264.html#resolution-support","title":"\ud83d\udcd0 Resolution Support","text":"<ul> <li>Standard Formats: HD (1920x1080), 4K (3840x2160), 2K (2048x1556)</li> <li>Custom Resolutions: Any resolution supported by FFmpeg</li> <li>Aspect Ratio Preservation: Maintains proper aspect ratios</li> <li>Scaling Quality: High-quality scaling algorithms</li> </ul>"},{"location":"bash/media/convert_images_to_h264.html#advanced-options","title":"\ud83d\udee0\ufe0f Advanced Options","text":"<ul> <li>Input Validation: Comprehensive validation of input files and parameters</li> <li>Progress Monitoring: Real-time encoding progress feedback</li> <li>Error Handling: Robust error detection and reporting</li> <li>Shared Library Integration: Uses optimized codec setup functions</li> </ul>"},{"location":"bash/media/convert_images_to_h264.html#bitrate-guidelines","title":"Bitrate Guidelines","text":"Resolution Recommended Bitrate Range Use Case SD (480p) 2,000 - 5,000 kbps Web delivery, mobile 720p HD 5,000 - 10,000 kbps Standard HD, streaming 1080p HD 10,000 - 20,000 kbps Full HD, broadcast 2K 20,000 - 30,000 kbps Cinema, professional 4K 30,000 - 60,000 kbps Ultra HD, premium content"},{"location":"bash/media/convert_images_to_h264.html#quality-settings","title":"Quality Settings","text":"CRF Value Quality Level Use Case 16-18 Excellent Professional/broadcast 20-22 High Standard production 23-25 Good Web delivery 26-28 Acceptable High compression needs"},{"location":"bash/media/convert_images_to_h264.html#how-it-works","title":"How It Works","text":""},{"location":"bash/media/convert_images_to_h264.html#processing-pipeline","title":"Processing Pipeline","text":"<ol> <li>Input Validation: Verifies image sequence files exist and are accessible</li> <li>Parameter Setup: Configures encoding parameters based on input arguments</li> <li>Codec Configuration: Sets up H.264 encoder with optimized settings</li> <li>FFmpeg Execution: Runs FFmpeg with constructed command line</li> <li>Progress Monitoring: Provides real-time feedback during encoding</li> <li>Output Verification: Confirms successful completion and output file creation</li> </ol>"},{"location":"bash/media/convert_images_to_h264.html#encoding-configuration","title":"Encoding Configuration","text":"<p>The script uses optimized H.264 settings: - Profile: High profile for maximum compatibility - Preset: Balanced preset for quality vs. speed - Rate Control: CRF (Constant Rate Factor) for consistent quality - Bitrate Limiting: Maximum bitrate caps for delivery requirements</p>"},{"location":"bash/media/convert_images_to_h264.html#input-formats","title":"Input Formats","text":""},{"location":"bash/media/convert_images_to_h264.html#supported-image-formats","title":"Supported Image Formats","text":"<ul> <li>JPEG/JPG: Standard photography, compressed images</li> <li>PNG: Lossless graphics, transparency support</li> <li>TIFF: Professional photography, high bit depth</li> <li>EXR: VFX and rendering, HDR images</li> <li>DPX: Film/broadcast industry standard</li> <li>BMP: Windows bitmap format</li> </ul>"},{"location":"bash/media/convert_images_to_h264.html#sequence-naming-patterns","title":"Sequence Naming Patterns","text":"<pre><code># Common patterns (use %d for frame numbers)\nframe_%04d.jpg     # frame_0001.jpg, frame_0002.jpg...\nimage_%03d.png     # image_001.png, image_002.png...\nrender_%05d.exr    # render_00001.exr, render_00002.exr...\n</code></pre>"},{"location":"bash/media/convert_images_to_h264.html#configuration","title":"Configuration","text":""},{"location":"bash/media/convert_images_to_h264.html#environment-variables","title":"Environment Variables","text":"<p>No environment variables required. All configuration through command-line arguments.</p>"},{"location":"bash/media/convert_images_to_h264.html#ffmpeg-dependencies","title":"FFmpeg Dependencies","text":"<ul> <li>FFmpeg: Required with H.264 encoder support</li> <li>x264: H.264 encoding library (usually included with FFmpeg)</li> </ul>"},{"location":"bash/media/convert_images_to_h264.html#integration","title":"Integration","text":""},{"location":"bash/media/convert_images_to_h264.html#animation-workflows","title":"Animation Workflows","text":"<pre><code>#!/bin/bash\n# Animation rendering pipeline\nSEQUENCE_DIR=\"~/renders/animation\"\nOUTPUT_DIR=\"~/output/videos\"\n\n# Multiple quality versions\n./convert_images_to_h264.sh \"$SEQUENCE_DIR/frame_%04d.png\" 1920x1080 24 18 15000\nmv output.mp4 \"$OUTPUT_DIR/animation_high.mp4\"\n\n./convert_images_to_h264.sh \"$SEQUENCE_DIR/frame_%04d.png\" 1280x720 24 22 8000\nmv output.mp4 \"$OUTPUT_DIR/animation_web.mp4\"\n</code></pre>"},{"location":"bash/media/convert_images_to_h264.html#batch-processing","title":"Batch Processing","text":"<pre><code>#!/bin/bash\n# Process multiple sequences\nfor sequence in ~/sequences/*.%04d.jpg; do\n    base_name=$(basename \"$sequence\" .%04d.jpg)\n    ./convert_images_to_h264.sh \"$sequence\" 1920x1080 25 20 12000\n    mv output.mp4 \"~/videos/${base_name}_h264.mp4\"\ndone\n</code></pre>"},{"location":"bash/media/convert_images_to_h264.html#time-lapse-creation","title":"Time-lapse Creation","text":"<pre><code># Time-lapse from photos\n./convert_images_to_h264.sh timelapse_%04d.jpg 1920x1080 30 20 15000\n\n# Hyperlapse with motion blur\n./convert_images_to_h264.sh hyperlapse_%05d.tiff 3840x2160 60 18 40000\n</code></pre>"},{"location":"bash/media/convert_images_to_h264.html#best-practices","title":"Best Practices","text":""},{"location":"bash/media/convert_images_to_h264.html#pre-processing","title":"Pre-Processing","text":"<ol> <li>Consistent Naming: Use consistent frame numbering (e.g., %04d)</li> <li>Frame Rate Planning: Choose appropriate frame rate for content type</li> <li>Resolution Decisions: Match output resolution to intended use</li> <li>Quality Testing: Test quality settings on a short sequence first</li> </ol>"},{"location":"bash/media/convert_images_to_h264.html#encoding-optimization","title":"Encoding Optimization","text":"<ol> <li>Quality vs. Size: Balance CRF and bitrate for optimal results</li> <li>Target Platform: Consider playback device capabilities</li> <li>Delivery Method: Optimize for streaming vs. download</li> <li>Storage Constraints: Adjust settings based on storage limitations</li> </ol>"},{"location":"bash/media/convert_images_to_h264.html#quality-control","title":"Quality Control","text":"<ol> <li>Preview Encoding: Test settings on a small sample first</li> <li>Visual Inspection: Always review encoded output</li> <li>Bitrate Analysis: Monitor actual vs. maximum bitrate usage</li> <li>Compatibility Testing: Verify playback on target devices</li> </ol>"},{"location":"bash/media/convert_images_to_h264.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"bash/media/convert_images_to_h264.html#common-issues","title":"Common Issues","text":"<p>FFmpeg Not Found - Install FFmpeg with H.264 support - Ensure FFmpeg is in system PATH - Verify x264 encoder availability</p> <p>Input File Errors - Check image sequence naming pattern matches - Verify all sequence files exist and are readable - Ensure image format is supported by FFmpeg</p> <p>Quality Issues - Lower CRF value for better quality (but larger files) - Increase maximum bitrate for complex content - Consider different preset for speed vs. quality trade-off</p> <p>Performance Problems - Use hardware acceleration if available - Adjust FFmpeg preset for faster encoding - Process smaller batches for memory management</p>"},{"location":"bash/media/convert_images_to_h264.html#technical-details","title":"Technical Details","text":""},{"location":"bash/media/convert_images_to_h264.html#dependencies","title":"Dependencies","text":"<ul> <li>FFmpeg: With H.264/x264 encoder support</li> <li>Shared Libraries: Uses media_functions.sh for codec setup</li> <li>Common Functions: Input validation and error handling</li> </ul>"},{"location":"bash/media/convert_images_to_h264.html#encoding-command-structure","title":"Encoding Command Structure","text":"<pre><code>ffmpeg -r $FRAMERATE -i \"$INPUT_PATTERN\" \\\n       -c:v libx264 -crf $QUALITY \\\n       -maxrate ${MAX_BITRATE}k -bufsize $((MAX_BITRATE * 2))k \\\n       -s $RESOLUTION -pix_fmt yuv420p \\\n       \"$OUTPUT_FILE\"\n</code></pre>"},{"location":"bash/media/convert_images_to_h264.html#security-considerations","title":"Security Considerations","text":"<ul> <li>Input Validation: All parameters validated before use</li> <li>Path Safety: No arbitrary command construction</li> <li>File Validation: Input files verified before processing</li> </ul>"},{"location":"bash/media/convert_images_to_h264.html#see-also","title":"See Also","text":"<ul> <li>Images to ProRes Converter - Professional codec alternative</li> <li>Movie to H.264 Converter - Video file input version</li> <li>Media Functions - Shared encoding functions</li> <li>Media Processing Overview - All media tools</li> </ul> <p>Script Location: <code>bash/media/convert_images_to_h264.sh</code> Author: Alexander Kucera / babylondreams.de Copyright: 2012 BabylonDreams. All rights reserved.</p>"},{"location":"bash/media/convert_images_to_prores.html","title":"Images to ProRes Converter (convert_images_to_prores.sh)","text":"<p>Convert image sequences to Apple ProRes format with professional-grade quality settings for broadcast and post-production workflows.</p>"},{"location":"bash/media/convert_images_to_prores.html#overview","title":"Overview","text":"<p>The <code>convert_images_to_prores.sh</code> script transforms image sequences into Apple ProRes video files, the industry standard for professional video production. It supports all ProRes variants from Proxy to 4444, providing optimal quality for editing, color grading, and broadcast delivery.</p>"},{"location":"bash/media/convert_images_to_prores.html#usage","title":"Usage","text":"<pre><code>convert_images_to_prores.sh &lt;path_to_file&gt; [resolution] [framerate] [quality] [format]\n</code></pre>"},{"location":"bash/media/convert_images_to_prores.html#arguments","title":"Arguments","text":"Argument Type Description Default <code>path_to_file</code> Required Path to input image sequence - <code>resolution</code> Optional Output resolution 1920x1080 <code>framerate</code> Optional Frame rate in fps 25 <code>quality</code> Optional Quality setting 20 <code>format</code> Optional ProRes format (0-4) 4 (4444)"},{"location":"bash/media/convert_images_to_prores.html#prores-formats","title":"ProRes Formats","text":"Value Format Description Use Case 0 Proxy Low resolution/bitrate Offline editing 1 LT Light compression Standard editing 2 Standard Balanced quality/size General production 3 HQ High quality Professional delivery 4 4444 Highest quality + alpha VFX, color grading"},{"location":"bash/media/convert_images_to_prores.html#examples","title":"Examples","text":""},{"location":"bash/media/convert_images_to_prores.html#professional-workflows","title":"Professional Workflows","text":"<pre><code># VFX sequence to ProRes 4444\n./convert_images_to_prores.sh vfx_%05d.exr 2048x1556 24 18 4\n\n# Animation to ProRes HQ\n./convert_images_to_prores.sh anim_%04d.png 1920x1080 24 20 3\n\n# Proxy for offline editing\n./convert_images_to_prores.sh dailies_%04d.jpg 1920x1080 25 22 0\n</code></pre>"},{"location":"bash/media/convert_images_to_prores.html#broadcast-production","title":"Broadcast Production","text":"<pre><code># Broadcast standard (ProRes HQ)\n./convert_images_to_prores.sh sequence_%04d.tiff 1920x1080 25 18 3\n\n# 4K production (ProRes 4444)\n./convert_images_to_prores.sh frames_%05d.dpx 3840x2160 24 16 4\n</code></pre>"},{"location":"bash/media/convert_images_to_prores.html#see-also","title":"See Also","text":"<ul> <li>Images to H.264 Converter - Web delivery alternative</li> <li>Media Functions - ProRes encoding setup</li> <li>Media Processing Overview - All media tools</li> </ul> <p>Script Location: <code>bash/media/convert_images_to_prores.sh</code> Author: Alexander Kucera / babylondreams.de</p>"},{"location":"bash/media/convert_movie_to_h264.html","title":"Movie to H.264 Converter (convert_movie_to_h264.sh)","text":"<p>Convert video files to H.264 format with optimized settings for web delivery, streaming, and distribution.</p>"},{"location":"bash/media/convert_movie_to_h264.html#overview","title":"Overview","text":"<p>Convert existing video files to H.264 format using professional encoding settings. Ideal for creating web-optimized versions, streaming content, and cross-platform compatible video files.</p>"},{"location":"bash/media/convert_movie_to_h264.html#usage","title":"Usage","text":"<pre><code>convert_movie_to_h264.sh &lt;path_to_file&gt; [resolution] [quality] [max_bitrate]\n</code></pre>"},{"location":"bash/media/convert_movie_to_h264.html#arguments","title":"Arguments","text":"Argument Type Description Default <code>path_to_file</code> Required Path to input video file - <code>resolution</code> Optional Output resolution 1920x1080 <code>quality</code> Optional Quality setting (CRF) 20 <code>max_bitrate</code> Optional Maximum bitrate in kbps 10000"},{"location":"bash/media/convert_movie_to_h264.html#examples","title":"Examples","text":""},{"location":"bash/media/convert_movie_to_h264.html#basic-conversion","title":"Basic Conversion","text":"<pre><code># Convert with default settings\n./convert_movie_to_h264.sh input.mov\n\n# Web-optimized version\n./convert_movie_to_h264.sh source.avi 1280x720 22 8000\n\n# High quality for distribution\n./convert_movie_to_h264.sh master.mov 1920x1080 18 15000\n</code></pre>"},{"location":"bash/media/convert_movie_to_h264.html#batch-processing","title":"Batch Processing","text":"<pre><code># Convert all MOV files in directory\nfor file in *.mov; do\n    ./convert_movie_to_h264.sh \"$file\" 1920x1080 20 12000\ndone\n</code></pre>"},{"location":"bash/media/convert_movie_to_h264.html#bitrate-guidelines","title":"Bitrate Guidelines","text":"<p>Same as Images to H.264 - optimized for different resolutions and use cases.</p>"},{"location":"bash/media/convert_movie_to_h264.html#see-also","title":"See Also","text":"<ul> <li>Images to H.264 Converter - Image sequence version</li> <li>Movie to ProRes Converter - Professional alternative</li> <li>Movie to Web Converter - Multi-format web output</li> </ul> <p>Script Location: <code>bash/media/convert_movie_to_h264.sh</code> Author: Alexander Kucera / babylondreams.de</p>"},{"location":"bash/media/convert_movie_to_prores.html","title":"Movie to ProRes Converter (convert_movie_to_prores.sh)","text":"<p>Convert video files to Apple ProRes format for professional post-production and broadcast workflows.</p>"},{"location":"bash/media/convert_movie_to_prores.html#usage","title":"Usage","text":"<pre><code>convert_movie_to_prores.sh &lt;path_to_file&gt; [resolution] [framerate] [quality] [format]\n</code></pre>"},{"location":"bash/media/convert_movie_to_prores.html#prores-formats","title":"ProRes Formats","text":"<ul> <li>0: Proxy - Offline editing</li> <li>1: LT - Standard editing  </li> <li>2: Standard - General production</li> <li>3: HQ - Professional delivery</li> <li>4: 4444 - VFX, color grading (default)</li> </ul>"},{"location":"bash/media/convert_movie_to_prores.html#examples","title":"Examples","text":"<pre><code># Convert to ProRes 4444 for color grading\n./convert_movie_to_prores.sh source.mov 1920x1080 25 18 4\n\n# Create proxy for offline editing\n./convert_movie_to_prores.sh master.avi 1920x1080 25 22 0\n\n# Professional delivery format\n./convert_movie_to_prores.sh final.mp4 1920x1080 24 18 3\n</code></pre>"},{"location":"bash/media/convert_movie_to_prores.html#see-also","title":"See Also","text":"<ul> <li>Images to ProRes Converter - Image sequence version</li> <li>Movie to H.264 Converter - Web delivery alternative</li> </ul> <p>Script Location: <code>bash/media/convert_movie_to_prores.sh</code> Author: Alexander Kucera / babylondreams.de</p>"},{"location":"bash/media/movie_to_web.html","title":"Movie to Web Converter (movie_to_web.sh)","text":"<p>Convert video files to web-optimized formats (MP4 and WebM) for maximum browser compatibility and streaming performance.</p>"},{"location":"bash/media/movie_to_web.html#overview","title":"Overview","text":"<p>Creates web-optimized video files in both MP4 (H.264) and WebM formats, ensuring maximum compatibility across all browsers and devices. Optimized for web delivery with balanced quality and file size.</p>"},{"location":"bash/media/movie_to_web.html#usage","title":"Usage","text":"<pre><code>movie_to_web.sh &lt;path_to_file&gt;\n</code></pre>"},{"location":"bash/media/movie_to_web.html#arguments","title":"Arguments","text":"Argument Type Description <code>path_to_file</code> Required Path to input video file"},{"location":"bash/media/movie_to_web.html#features","title":"Features","text":"<ul> <li>Dual Format Output: Creates both MP4 and WebM versions</li> <li>Web Optimization: Settings optimized for web streaming</li> <li>Browser Compatibility: Ensures playback across all major browsers</li> <li>Automatic Quality: Pre-configured quality settings for web delivery</li> </ul>"},{"location":"bash/media/movie_to_web.html#examples","title":"Examples","text":"<pre><code># Convert for web deployment\n./movie_to_web.sh promotional_video.mov\n\n# Process training videos\n./movie_to_web.sh training_session.avi\n\n# Convert product demos\n./movie_to_web.sh product_demo.mp4\n</code></pre>"},{"location":"bash/media/movie_to_web.html#output-files","title":"Output Files","text":"<ul> <li><code>filename_web.mp4</code> - H.264 version for broad compatibility</li> <li><code>filename_web.webm</code> - WebM version for modern browsers</li> </ul>"},{"location":"bash/media/movie_to_web.html#see-also","title":"See Also","text":"<ul> <li>Movie to H.264 Converter - H.264-only output</li> <li>Media Processing Overview - All media tools</li> </ul> <p>Script Location: <code>bash/media/movie_to_web.sh</code> Author: Alexander Kucera / babylondreams.de</p>"},{"location":"bash/media/split_stereo_to_mono.html","title":"Stereo to Mono Audio Split (split_stereo_to_mono.sh)","text":"<p>Split stereo audio files into separate mono channel files with lossless quality preservation.</p>"},{"location":"bash/media/split_stereo_to_mono.html#overview","title":"Overview","text":"<p>Separates stereo audio files into individual left and right channel mono files using Apple Lossless format. Essential for audio post-production, music production, and broadcast workflows where channel separation is required.</p>"},{"location":"bash/media/split_stereo_to_mono.html#usage","title":"Usage","text":"<pre><code>split_stereo_to_mono.sh &lt;path_to_file&gt;\n</code></pre>"},{"location":"bash/media/split_stereo_to_mono.html#arguments","title":"Arguments","text":"Argument Type Description <code>path_to_file</code> Required Path to input stereo audio file"},{"location":"bash/media/split_stereo_to_mono.html#features","title":"Features","text":"<ul> <li>Lossless Quality: Uses Apple Lossless format for quality preservation</li> <li>Channel Separation: Creates separate left and right channel files</li> <li>Format Support: Handles WAV, AIFF, MP3, and other common audio formats</li> <li>Professional Output: Apple Lossless suitable for further processing</li> </ul>"},{"location":"bash/media/split_stereo_to_mono.html#examples","title":"Examples","text":"<pre><code># Split music recording\n./split_stereo_to_mono.sh song_stereo.wav\n\n# Process podcast audio\n./split_stereo_to_mono.sh interview.aiff\n\n# Separate dialogue tracks\n./split_stereo_to_mono.sh dialogue_stereo.mp3\n</code></pre>"},{"location":"bash/media/split_stereo_to_mono.html#output-files","title":"Output Files","text":"<ul> <li><code>filename_left.m4a</code> - Left channel in Apple Lossless</li> <li><code>filename_right.m4a</code> - Right channel in Apple Lossless</li> </ul>"},{"location":"bash/media/split_stereo_to_mono.html#use-cases","title":"Use Cases","text":"<ul> <li>Music Production: Separate instruments recorded on different channels</li> <li>Podcast Production: Split host and guest recordings</li> <li>Audio Restoration: Process channels independently</li> <li>Broadcast: Create separate mono feeds for different outputs</li> </ul>"},{"location":"bash/media/split_stereo_to_mono.html#see-also","title":"See Also","text":"<ul> <li>Media Functions - Audio processing utilities</li> <li>Media Processing Overview - All media tools</li> </ul> <p>Script Location: <code>bash/media/split_stereo_to_mono.sh</code> Author: Alexander Kucera / babylondreams.de</p>"},{"location":"bash/rendering/mail_send.html","title":"Mail Notifications (mail_send.sh)","text":"<p>Send email notifications for completed renders with timing information and system details.</p>"},{"location":"bash/rendering/mail_send.html#overview","title":"Overview","text":"<p>Automated email notification system for render completion with detailed timing statistics, machine identification, and professional formatting. Essential for long-running render processes and distributed rendering workflows.</p>"},{"location":"bash/rendering/mail_send.html#usage","title":"Usage","text":"<pre><code>mail_send.sh\n</code></pre>"},{"location":"bash/rendering/mail_send.html#features","title":"Features","text":"<ul> <li>Render Timing: Tracks start time, end time, and total duration</li> <li>Machine Identification: Includes hostname in notifications</li> <li>Professional Formatting: Clean, informative email content</li> <li>Error Handling: Validates email configuration and connectivity</li> </ul>"},{"location":"bash/rendering/mail_send.html#configuration","title":"Configuration","text":""},{"location":"bash/rendering/mail_send.html#email-settings","title":"Email Settings","text":"<p>Edit <code>config/mail_send.conf</code>: <pre><code>FROM_ADDRESS=\"renders@yourcompany.com\"\nTO_ADDRESS=\"team@yourcompany.com\"\nSERVER=\"smtp.yourserver.com\"\nUSER=\"smtp_username\"\n# PASS set via environment variable\n</code></pre></p>"},{"location":"bash/rendering/mail_send.html#environment-variables","title":"Environment Variables","text":"<pre><code>export MAIL_PASSWORD=\"your_smtp_password\"\n</code></pre>"},{"location":"bash/rendering/mail_send.html#examples","title":"Examples","text":"<pre><code># Basic render notification\n./mail_send.sh\n\n# Integration with render scripts\n./render_job.sh &amp;&amp; ./mail_send.sh\n\n# Conditional notifications\nif render_command; then\n    ./mail_send.sh\nelse\n    echo \"Render failed - notification not sent\"\nfi\n</code></pre>"},{"location":"bash/rendering/mail_send.html#email-content","title":"Email Content","text":"<p>The notification includes: - Machine Name: Which system completed the render - Start Time: When the render began - End Time: When the render completed - Duration: Total render time in hours:minutes:seconds format - Professional Formatting: Clean, readable layout</p>"},{"location":"bash/rendering/mail_send.html#requirements","title":"Requirements","text":"<ul> <li>sendemail: Command-line email utility</li> <li>SMTP Access: Configured email server</li> <li>Network Connectivity: For email delivery</li> </ul>"},{"location":"bash/rendering/mail_send.html#security","title":"Security","text":"<ul> <li>No Hardcoded Passwords: Uses environment variables</li> <li>Validated Configuration: Checks all required settings</li> <li>Error Reporting: Clear messages for configuration issues</li> </ul>"},{"location":"bash/rendering/mail_send.html#see-also","title":"See Also","text":"<ul> <li>Nuke Render Automation - Integrated render notifications</li> <li>Mail Configuration - Email setup details</li> </ul> <p>Script Location: <code>bash/rendering/mail_send.sh</code> Author: Alexander Kucera / babylondreams.de</p>"},{"location":"bash/rendering/nukerender_bash.html","title":"Nuke Render Automation (nukerender_bash.sh)","text":"<p>Automated Nuke rendering with interactive configuration, email notifications, and comprehensive error handling.</p>"},{"location":"bash/rendering/nukerender_bash.html#overview","title":"Overview","text":"<p>Professional Nuke rendering automation that provides interactive setup for render options, automatic email notifications, and detailed progress tracking. Designed for production environments where reliable render execution and notification are critical.</p>"},{"location":"bash/rendering/nukerender_bash.html#usage","title":"Usage","text":"<pre><code>nukerender_bash.sh &lt;nuke_script&gt; [output_path]\n</code></pre>"},{"location":"bash/rendering/nukerender_bash.html#arguments","title":"Arguments","text":"Argument Type Description <code>nuke_script</code> Required Path to Nuke script file (.nk) <code>output_path</code> Optional Output path for rendered files"},{"location":"bash/rendering/nukerender_bash.html#interactive-configuration","title":"Interactive Configuration","text":"<p>The script prompts for render settings:</p> <ol> <li>Render Range: Custom frame range (e.g., <code>-F 12-13</code>) or comp default</li> <li>GPU Usage: Enable/disable GPU acceleration</li> <li>Interactive License: Required for Furnace tools and certain plugins</li> </ol>"},{"location":"bash/rendering/nukerender_bash.html#features","title":"Features","text":""},{"location":"bash/rendering/nukerender_bash.html#render-management","title":"\ud83c\udfac Render Management","text":"<ul> <li>Frame Range Control: Custom ranges or script defaults</li> <li>GPU Acceleration: Optional GPU rendering support</li> <li>Interactive Licensing: Support for Furnace and commercial plugins</li> <li>Multi-core Utilization: Automatic CPU core detection and usage</li> </ul>"},{"location":"bash/rendering/nukerender_bash.html#notification-system","title":"\ud83d\udce7 Notification System","text":"<ul> <li>Email Integration: Automatic completion notifications</li> <li>Timing Tracking: Detailed start/end times and duration</li> <li>Machine Identification: Hostname included in notifications</li> <li>Error Reporting: Failed renders reported via email</li> </ul>"},{"location":"bash/rendering/nukerender_bash.html#safety-features","title":"\ud83d\udee1\ufe0f Safety Features","text":"<ul> <li>Input Validation: Comprehensive script and path validation</li> <li>Environment Checks: Validates Nuke installation and paths</li> <li>Error Handling: Graceful handling of render failures</li> <li>Configuration Validation: Checks email and system setup</li> </ul>"},{"location":"bash/rendering/nukerender_bash.html#environment-setup","title":"Environment Setup","text":""},{"location":"bash/rendering/nukerender_bash.html#required-environment-variables","title":"Required Environment Variables","text":"<pre><code>export NUKEPATH=\"/Applications/Nuke/Nuke15.0v4/Nuke15.0v4\"\nexport MAIL_PASSWORD=\"your_smtp_password\"\n</code></pre>"},{"location":"bash/rendering/nukerender_bash.html#configuration-files","title":"Configuration Files","text":"<ul> <li><code>config/mail_send.conf</code>: Email notification settings</li> </ul>"},{"location":"bash/rendering/nukerender_bash.html#examples","title":"Examples","text":""},{"location":"bash/rendering/nukerender_bash.html#basic-rendering","title":"Basic Rendering","text":"<pre><code># Render with interactive setup\n./nukerender_bash.sh shot_001.nk\n\n# Render to specific output location\n./nukerender_bash.sh shot_001.nk /renders/shot_001/\n</code></pre>"},{"location":"bash/rendering/nukerender_bash.html#production-workflows","title":"Production Workflows","text":"<pre><code>#!/bin/bash\n# Batch render script\nfor script in shots/*.nk; do\n    echo \"Rendering: $script\"\n    ./nukerender_bash.sh \"$script\"\n\n    if [[ $? -eq 0 ]]; then\n        echo \"\u2713 $script completed successfully\"\n    else\n        echo \"\u2717 $script failed\"\n        # Continue with next script\n    fi\ndone\n</code></pre>"},{"location":"bash/rendering/nukerender_bash.html#render-command-examples","title":"Render Command Examples","text":"<p>The script provides helpful command-line examples:</p> <pre><code># Render specific frame\nnuke -F 5 -x myscript.nk\n\n# Render frame range\nnuke -F 30-50 -x myscript.nk\n\n# Multiple ranges\nnuke -F 10-20 -F 34-60 -x myscript.nk\n\n# Every tenth frame\nnuke -F 1-50x10 -x myscript.nk\n\n# Specific write node\nnuke -X WriteBlur myscript.nk 1-20\n</code></pre>"},{"location":"bash/rendering/nukerender_bash.html#notification-content","title":"Notification Content","text":"<p>Email notifications include: - Machine Hostname: Which system completed the render - Script Name: Nuke script that was rendered - Start/End Times: Complete timing information - Total Duration: Formatted as hours:minutes:seconds - Render Settings: GPU usage, frame range, license type</p>"},{"location":"bash/rendering/nukerender_bash.html#error-handling","title":"Error Handling","text":""},{"location":"bash/rendering/nukerender_bash.html#common-issues","title":"Common Issues","text":"<ul> <li>Missing Nuke Path: Validates NUKEPATH environment variable</li> <li>Script Validation: Checks Nuke script exists and is readable</li> <li>Email Configuration: Validates mail settings before render</li> <li>Render Failures: Captures and reports Nuke errors</li> </ul>"},{"location":"bash/rendering/nukerender_bash.html#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Permission Issues: Ensure script has execute permissions</li> <li>Network Problems: Check email server connectivity</li> <li>Nuke Licensing: Verify appropriate Nuke licenses available</li> <li>Path Issues: Use absolute paths for reliability</li> </ul>"},{"location":"bash/rendering/nukerender_bash.html#integration","title":"Integration","text":""},{"location":"bash/rendering/nukerender_bash.html#farm-rendering","title":"Farm Rendering","text":"<pre><code># Render farm integration\nexport NUKEPATH=\"/path/to/nuke\"\nexport MAIL_PASSWORD=\"$RENDER_FARM_MAIL_PASS\"\n\n./nukerender_bash.sh \"$SHOT_SCRIPT\" \"$RENDER_OUTPUT\"\n</code></pre>"},{"location":"bash/rendering/nukerender_bash.html#cicd-pipelines","title":"CI/CD Pipelines","text":"<pre><code># Automated rendering in pipelines\nif ./nukerender_bash.sh daily_comp.nk /output/; then\n    echo \"Daily render completed\"\n    deploy_to_review_system\nelse\n    echo \"Daily render failed\"\n    alert_team\nfi\n</code></pre>"},{"location":"bash/rendering/nukerender_bash.html#requirements","title":"Requirements","text":""},{"location":"bash/rendering/nukerender_bash.html#software-dependencies","title":"Software Dependencies","text":"<ul> <li>Nuke: Foundry Nuke with command-line support</li> <li>sendemail: For email notifications</li> <li>Network Access: For email delivery</li> </ul>"},{"location":"bash/rendering/nukerender_bash.html#system-requirements","title":"System Requirements","text":"<ul> <li>macOS/Linux: Unix-like operating system</li> <li>Sufficient RAM: Based on Nuke script complexity</li> <li>Disk Space: For rendered output files</li> </ul>"},{"location":"bash/rendering/nukerender_bash.html#see-also","title":"See Also","text":"<ul> <li>Mail Notifications - Email notification setup</li> <li>System Functions - System information utilities</li> <li>Mail Configuration - Email setup details</li> </ul> <p>Script Location: <code>bash/rendering/nukerender_bash.sh</code> Author: Alexander Kucera / babylondreams.de</p>"},{"location":"bash/system/application_list_updater.html","title":"Application List Updater (application_list_updater.sh)","text":"<p>Generate comprehensive lists of installed applications for backup and restoration purposes.</p>"},{"location":"bash/system/application_list_updater.html#overview","title":"Overview","text":"<p>Creates detailed inventories of all installed applications on macOS systems, including system applications, user applications, Homebrew packages, and App Store applications. Essential for system migration, backup planning, and software auditing.</p>"},{"location":"bash/system/application_list_updater.html#usage","title":"Usage","text":"<pre><code>application_list_updater.sh [output_file]\n</code></pre>"},{"location":"bash/system/application_list_updater.html#arguments","title":"Arguments","text":"Argument Type Description Default <code>output_file</code> Optional Path for output file ~/Documents/ApplicationList.txt"},{"location":"bash/system/application_list_updater.html#features","title":"Features","text":"<ul> <li>Complete Coverage: Lists applications from multiple sources</li> <li>Organized Output: Categorizes applications by installation method</li> <li>Homebrew Integration: Includes both packages and casks</li> <li>App Store Detection: Identifies Mac App Store applications</li> <li>Timestamp Tracking: Includes generation date for reference</li> </ul>"},{"location":"bash/system/application_list_updater.html#application-sources","title":"Application Sources","text":"Category Location Description System Apps /Applications Standard macOS applications User Apps ~/Applications User-specific applications Homebrew Packages brew list Command-line tools and libraries Homebrew Casks brew list --cask GUI applications installed via Homebrew App Store mas list Mac App Store applications"},{"location":"bash/system/application_list_updater.html#examples","title":"Examples","text":"<pre><code># Generate default application list\n./application_list_updater.sh\n\n# Custom output location\n./application_list_updater.sh ~/Backups/apps_$(date +%Y%m%d).txt\n\n# Store in project directory\n./application_list_updater.sh ./system_apps.txt\n</code></pre>"},{"location":"bash/system/application_list_updater.html#output-format","title":"Output Format","text":"<pre><code>Application List - Generated Mon Jul  5 13:30:00 CEST 2025\n==================================================\n\nThis file lists all installed applications for restoration purposes.\nNote: Actual applications are not backed up, only their names.\n\n=== SYSTEM APPLICATIONS ===\nActivity Monitor\nApp Store\nCalculator\nCalendar\n...\n\n=== HOMEBREW PACKAGES ===\nffmpeg\ngit\nnode\n...\n\n=== HOMEBREW CASKS ===\nvisual-studio-code\nchrome\nfirefox\n...\n\n=== MAC APP STORE APPLICATIONS ===\nXcode (497799835)\nPages (409201541)\n...\n</code></pre>"},{"location":"bash/system/application_list_updater.html#integration","title":"Integration","text":""},{"location":"bash/system/application_list_updater.html#backup-workflows","title":"Backup Workflows","text":"<pre><code>#!/bin/bash\n# System backup script\nBACKUP_DATE=$(date +%Y%m%d)\nBACKUP_DIR=\"~/Backups/$BACKUP_DATE\"\n\nmkdir -p \"$BACKUP_DIR\"\n./application_list_updater.sh \"$BACKUP_DIR/applications.txt\"\n</code></pre>"},{"location":"bash/system/application_list_updater.html#system-migration","title":"System Migration","text":"<pre><code># Pre-migration inventory\n./application_list_updater.sh ~/Desktop/old_system_apps.txt\n\n# Post-migration comparison\n./application_list_updater.sh ~/Desktop/new_system_apps.txt\ndiff ~/Desktop/old_system_apps.txt ~/Desktop/new_system_apps.txt\n</code></pre>"},{"location":"bash/system/application_list_updater.html#see-also","title":"See Also","text":"<ul> <li>System Functions - System information utilities</li> <li>System Administration Overview - Related tools</li> </ul> <p>Script Location: <code>bash/system/application_list_updater.sh</code> Author: Alexander Kucera / babylondreams.de</p>"},{"location":"bash/system/checkLogSize.html","title":"Log Size Checker (checkLogSize.sh)","text":"<p>Monitor log file sizes and validate they stay within specified limits for automated monitoring and maintenance.</p>"},{"location":"bash/system/checkLogSize.html#usage","title":"Usage","text":"<pre><code>checkLogSize.sh [log_file] [max_size_kb]\n</code></pre>"},{"location":"bash/system/checkLogSize.html#arguments","title":"Arguments","text":"Argument Type Description Default <code>log_file</code> Optional Path to log file ~/Documents/scripts/mount_unmount_bootable.log <code>max_size_kb</code> Optional Maximum size in KB 128"},{"location":"bash/system/checkLogSize.html#exit-codes","title":"Exit Codes","text":"<ul> <li>0: File size within limits</li> <li>1: File size exceeds limit or error occurred</li> </ul>"},{"location":"bash/system/checkLogSize.html#examples","title":"Examples","text":"<pre><code># Check default log file\n./checkLogSize.sh\n\n# Check custom log with 256KB limit\n./checkLogSize.sh /var/log/my.log 256\n\n# Check with 1MB limit\n./checkLogSize.sh ~/logs/debug.log 1024\n</code></pre>"},{"location":"bash/system/checkLogSize.html#automation","title":"Automation","text":"<pre><code># Cron job for daily monitoring\n0 9 * * * /path/to/checkLogSize.sh /var/log/app.log 500 || echo \"Log file too large\"\n\n# Script integration\nif ./checkLogSize.sh ~/app.log 1000; then\n    echo \"Log size OK\"\nelse\n    echo \"Log rotation needed\"\n    logrotate ~/app.log\nfi\n</code></pre>"},{"location":"bash/system/checkLogSize.html#see-also","title":"See Also","text":"<ul> <li>Log Collector - Advanced log processing</li> <li>System Functions - Log management utilities</li> </ul> <p>Script Location: <code>bash/system/checkLogSize.sh</code> Author: Alexander Kucera / babylondreams.de</p>"},{"location":"bash/system/duplicate_folder_structure.html","title":"duplicate_folder_structure.sh","text":"<p>Efficient shell script for duplicating directory structures without copying files. Creates exact replicas of folder hierarchies using optimized find and mkdir operations.</p>"},{"location":"bash/system/duplicate_folder_structure.html#overview","title":"Overview","text":"<p>duplicate_folder_structure.sh creates a complete copy of a directory tree structure without copying any files. This shell script provides a fast, lightweight solution for creating template directory structures, preparing backup locations, or setting up parallel folder hierarchies.</p> <p>I created both a Python and Shell version since they serve slightly different use cases:</p> <ul> <li>Python version (duplicate_folder_structure.py): For integration into Python workflows, with advanced features like progress tracking and flexible configuration</li> <li>Shell version (duplicate_folder_structure.sh): For quick command-line use and shell scripting integration</li> </ul>"},{"location":"bash/system/duplicate_folder_structure.html#features","title":"Features","text":"<ul> <li>High Performance - Optimized using <code>find</code> and <code>mkdir -p</code> for maximum efficiency</li> <li>Flexible Naming - Automatic destination generation with suffix/prefix options</li> <li>Safety Features - Dry-run mode, path validation, and confirmation prompts  </li> <li>Progress Tracking - Progress indicators for large directory operations</li> <li>Error Handling - Comprehensive error reporting with proper exit codes</li> <li>Shell Integration - Perfect for shell scripts and automation workflows</li> <li>Resource Efficient - Minimal memory usage regardless of directory size</li> </ul>"},{"location":"bash/system/duplicate_folder_structure.html#usage","title":"Usage","text":""},{"location":"bash/system/duplicate_folder_structure.html#basic-usage","title":"Basic Usage","text":"<pre><code># Duplicate structure to specific destination\n./duplicate_folder_structure.sh /source/project /backup/structure\n\n# Generate destination with suffix\n./duplicate_folder_structure.sh /project --suffix \"_backup\"\n\n# Generate destination with prefix\n./duplicate_folder_structure.sh /data --prefix \"structure_\"\n\n# Dry-run to preview what would be created\n./duplicate_folder_structure.sh /source /dest --dry-run\n</code></pre>"},{"location":"bash/system/duplicate_folder_structure.html#advanced-usage","title":"Advanced Usage","text":"<pre><code># Verbose output with detailed progress\n./duplicate_folder_structure.sh /large/project /backup --verbose\n\n# Skip confirmation prompts for automation\n./duplicate_folder_structure.sh /source /dest --force\n\n# Combine options for automated workflows\n./duplicate_folder_structure.sh /project \\\n    --suffix \"_template\" \\\n    --verbose \\\n    --force\n</code></pre>"},{"location":"bash/system/duplicate_folder_structure.html#command-line-options","title":"Command-Line Options","text":"Option Short Description Default <code>SOURCE</code> - Source directory to duplicate structure from Required <code>DESTINATION</code> - Destination directory (optional with --suffix/--prefix) None <code>--suffix</code> <code>-s</code> Add suffix to source directory name for destination None <code>--prefix</code> <code>-p</code> Add prefix to source directory name for destination None <code>--dry-run</code> <code>-d</code> Show what would be done without making changes False <code>--verbose</code> <code>-v</code> Show detailed output and progress False <code>--force</code> <code>-f</code> Skip confirmation prompts False <code>--help</code> <code>-h</code> Show help message -"},{"location":"bash/system/duplicate_folder_structure.html#examples","title":"Examples","text":""},{"location":"bash/system/duplicate_folder_structure.html#example-1-project-template-creation","title":"Example 1: Project Template Creation","text":"<pre><code># Create a template structure for new projects  \n./duplicate_folder_structure.sh /master/project_template /new/client_project --verbose\n\n# Output shows progress:\n# Found 45 directories to duplicate\n# Creating directory structure in: /new/client_project\n# ================================================\n# Created: /new/client_project/src\n# Created: /new/client_project/src/components\n# Created: /new/client_project/tests\n# ...\n# Operation completed in 0h:00m:02s\n</code></pre>"},{"location":"bash/system/duplicate_folder_structure.html#example-2-backup-structure-preparation","title":"Example 2: Backup Structure Preparation","text":"<pre><code># Prepare backup directory structure\n./duplicate_folder_structure.sh /important/data --suffix \"_backup_structure\"\n\n# Creates: /important/data_backup_structure/\n# With all subdirectories from /important/data/ but no files\n</code></pre>"},{"location":"bash/system/duplicate_folder_structure.html#example-3-multiple-environment-setup","title":"Example 3: Multiple Environment Setup","text":"<pre><code>#!/bin/bash\n# Set up development, staging, and production structures\n\nSOURCE_ENV=\"/app/production\"\n\n./duplicate_folder_structure.sh \"$SOURCE_ENV\" --prefix \"dev_\" --force\n./duplicate_folder_structure.sh \"$SOURCE_ENV\" --prefix \"staging_\" --force  \n./duplicate_folder_structure.sh \"$SOURCE_ENV\" --prefix \"test_\" --force\n\necho \"All environment structures created\"\n</code></pre>"},{"location":"bash/system/duplicate_folder_structure.html#example-4-large-directory-tree-processing","title":"Example 4: Large Directory Tree Processing","text":"<pre><code># Process large directory with progress tracking\n./duplicate_folder_structure.sh /massive/dataset /backup/structure \\\n    --verbose \\\n    --dry-run\n\n# Review the dry-run output, then execute:\n./duplicate_folder_structure.sh /massive/dataset /backup/structure --verbose\n\n# Output for large operations:\n# Found 1,247 directories to duplicate\n# Creating directory structure in: /backup/structure\n# Processed 100/1247 directories...\n# Processed 200/1247 directories...\n# ...\n# Operation completed in 0h:02m:15s\n</code></pre>"},{"location":"bash/system/duplicate_folder_structure.html#advanced-features","title":"Advanced Features","text":""},{"location":"bash/system/duplicate_folder_structure.html#automatic-path-generation","title":"Automatic Path Generation","text":"<p>The script can automatically generate destination paths using patterns:</p> <pre><code># Suffix generation\n./duplicate_folder_structure.sh /project --suffix \"_folders\"\n# Creates: /project_folders/\n\n# Prefix generation  \n./duplicate_folder_structure.sh /data --prefix \"structure_\"\n# Creates: /structure_data/\n\n# Cannot use both suffix and prefix\n./duplicate_folder_structure.sh /data --suffix \"_a\" --prefix \"b_\"\n# Error: Cannot use both --suffix and --prefix\n</code></pre>"},{"location":"bash/system/duplicate_folder_structure.html#path-validation-and-safety","title":"Path Validation and Safety","text":"<p>The script includes comprehensive safety checks:</p> <pre><code># Prevents dangerous operations\n./duplicate_folder_structure.sh / /backup           # Error: Protected path\n./duplicate_folder_structure.sh /source /source     # Error: Same path  \n./duplicate_folder_structure.sh /parent /parent/sub # Error: Destination inside source\n</code></pre>"},{"location":"bash/system/duplicate_folder_structure.html#performance-optimization","title":"Performance Optimization","text":"<p>The script uses optimized shell operations for maximum performance:</p> <pre><code># Uses find with null-terminated output for safety\nfind \"$source\" -type d -print0 | while IFS= read -r -d '' dir; do\n    # Process each directory efficiently\ndone\n\n# Batch directory creation with mkdir -p\nmkdir -p \"$target_dir\"\n</code></pre>"},{"location":"bash/system/duplicate_folder_structure.html#integration-examples","title":"Integration Examples","text":""},{"location":"bash/system/duplicate_folder_structure.html#shell-script-integration","title":"Shell Script Integration","text":"<pre><code>#!/bin/bash\n# Project initialization script\n\nsetup_project_structure() {\n    local template_dir=\"$1\"\n    local project_name=\"$2\"\n    local base_dir=\"/projects\"\n\n    local project_dir=\"$base_dir/$project_name\"\n\n    echo \"Setting up project: $project_name\"\n\n    # Create directory structure\n    if ./duplicate_folder_structure.sh \"$template_dir\" \"$project_dir\" --force --verbose; then\n        echo \"\u2713 Directory structure created\"\n\n        # Additional setup\n        setup_config_files \"$project_dir\"\n        set_permissions \"$project_dir\"\n\n        echo \"\u2713 Project setup complete: $project_dir\"\n        return 0\n    else\n        echo \"\u2717 Failed to create project structure\"\n        return 1\n    fi\n}\n\nsetup_config_files() {\n    local project_dir=\"$1\"\n    # Copy template configuration files\n    cp /templates/config.template \"$project_dir/config.ini\"\n    cp /templates/README.template \"$project_dir/README.md\"\n}\n\nset_permissions() {\n    local project_dir=\"$1\"\n    # Set appropriate permissions\n    find \"$project_dir\" -type d -exec chmod 755 {} \\;\n}\n\n# Usage\nsetup_project_structure \"/templates/web_app\" \"new_client_site\"\n</code></pre>"},{"location":"bash/system/duplicate_folder_structure.html#automated-backup-workflow","title":"Automated Backup Workflow","text":"<pre><code>#!/bin/bash\n# Backup structure preparation script\n\nBACKUP_BASE=\"/backup/structures\"\nLOG_FILE=\"/var/log/backup_prep.log\"\n\nprepare_backup_structures() {\n    local -a source_dirs=(\"$@\")\n    local timestamp=\"$(date +%Y%m%d_%H%M%S)\"\n\n    echo \"Starting backup structure preparation: $(date)\" | tee -a \"$LOG_FILE\"\n\n    for source in \"${source_dirs[@]}\"; do\n        if [[ ! -d \"$source\" ]]; then\n            echo \"\u2717 Source does not exist: $source\" | tee -a \"$LOG_FILE\"\n            continue\n        fi\n\n        local source_name=\"$(basename \"$source\")\"\n        local backup_dest=\"$BACKUP_BASE/${source_name}_${timestamp}\"\n\n        echo \"Preparing backup structure for: $source_name\" | tee -a \"$LOG_FILE\"\n\n        # Create backup directory structure\n        if ./duplicate_folder_structure.sh \"$source\" \"$backup_dest\" --force --verbose &gt;&gt; \"$LOG_FILE\" 2&gt;&amp;1; then\n            echo \"\u2713 Structure prepared: $backup_dest\" | tee -a \"$LOG_FILE\"\n        else\n            echo \"\u2717 Failed: $source_name\" | tee -a \"$LOG_FILE\"\n        fi\n    done\n\n    echo \"Backup structure preparation completed: $(date)\" | tee -a \"$LOG_FILE\"\n}\n\n# Usage\nprepare_backup_structures \"/home/user\" \"/var/www\" \"/opt/applications\"\n</code></pre>"},{"location":"bash/system/duplicate_folder_structure.html#cicd-pipeline-integration","title":"CI/CD Pipeline Integration","text":"<pre><code>#!/bin/bash\n# CI/CD deployment structure setup\n\nsetup_deployment_structure() {\n    local environment=\"$1\"\n    local version=\"$2\"\n\n    local source_structure=\"/templates/deployment_template\"\n    local deployment_base=\"/deployments\"\n    local deployment_dir=\"$deployment_base/${environment}_${version}\"\n\n    echo \"Setting up deployment structure for $environment v$version\"\n\n    # Create deployment directory structure\n    if ./duplicate_folder_structure.sh \"$source_structure\" \"$deployment_dir\" --force; then\n        echo \"\u2713 Deployment structure created: $deployment_dir\"\n\n        # Set environment-specific permissions\n        case \"$environment\" in\n            \"production\")\n                chmod -R 755 \"$deployment_dir\"\n                ;;\n            \"staging\"|\"development\")  \n                chmod -R 775 \"$deployment_dir\"\n                ;;\n        esac\n\n        # Create environment marker\n        echo \"$environment\" &gt; \"$deployment_dir/.environment\"\n        echo \"$version\" &gt; \"$deployment_dir/.version\"\n\n        return 0\n    else\n        echo \"\u2717 Failed to create deployment structure\"\n        return 1\n    fi\n}\n\n# Usage in CI/CD pipeline\nENVIRONMENT=\"${CI_ENVIRONMENT_NAME:-development}\"\nVERSION=\"${CI_COMMIT_SHORT_SHA:-unknown}\"\n\nsetup_deployment_structure \"$ENVIRONMENT\" \"$VERSION\"\n</code></pre>"},{"location":"bash/system/duplicate_folder_structure.html#batch-processing-script","title":"Batch Processing Script","text":"<pre><code>#!/bin/bash\n# Batch directory structure duplication\n\nbatch_duplicate_structures() {\n    local config_file=\"$1\"\n    local dry_run=\"${2:-false}\"\n\n    # Config file format: source_dir|destination_pattern|options\n    while IFS='|' read -r source dest_pattern options; do\n        # Skip comments and empty lines\n        [[ \"$source\" =~ ^#.*$ ]] || [[ -z \"$source\" ]] &amp;&amp; continue\n\n        echo \"Processing: $source\"\n\n        # Build command\n        local cmd_args=(\"$source\")\n\n        # Add destination or pattern\n        if [[ \"$dest_pattern\" == --* ]]; then\n            cmd_args+=(\"$dest_pattern\")\n        else\n            cmd_args+=(\"$dest_pattern\")\n        fi\n\n        # Add additional options\n        if [[ -n \"$options\" ]]; then\n            read -ra opts &lt;&lt;&lt; \"$options\"\n            cmd_args+=(\"${opts[@]}\")\n        fi\n\n        # Add dry-run if requested\n        if [[ \"$dry_run\" == true ]]; then\n            cmd_args+=(\"--dry-run\")\n        fi\n\n        # Execute command\n        echo \"Executing: ./duplicate_folder_structure.sh ${cmd_args[*]}\"\n\n        if ./duplicate_folder_structure.sh \"${cmd_args[@]}\"; then\n            echo \"\u2713 Completed: $source\"\n        else\n            echo \"\u2717 Failed: $source\"\n        fi\n\n        echo \"---\"\n\n    done &lt; \"$config_file\"\n}\n\n# Example config file (batch_config.txt):\n# /projects/template_a|--suffix \"_copy\"|--verbose\n# /projects/template_b|/backup/template_b_structure|--force\n# /data/important|--prefix \"backup_\"|--verbose --force\n\n# Usage\nbatch_duplicate_structures \"batch_config.txt\" true   # Dry-run first\nbatch_duplicate_structures \"batch_config.txt\" false  # Execute\n</code></pre>"},{"location":"bash/system/duplicate_folder_structure.html#error-handling-and-recovery","title":"Error Handling and Recovery","text":""},{"location":"bash/system/duplicate_folder_structure.html#comprehensive-error-handling","title":"Comprehensive Error Handling","text":"<p>The script includes robust error handling for common scenarios:</p> <pre><code># Invalid source directory\n./duplicate_folder_structure.sh /nonexistent /dest\n# Error: source directory '/nonexistent' does not exist\n\n# Source is not a directory  \n./duplicate_folder_structure.sh /etc/passwd /dest\n# Error: source directory '/etc/passwd' does not exist\n\n# Destination inside source (prevents infinite recursion)\n./duplicate_folder_structure.sh /parent /parent/child\n# Error: Destination cannot be inside source directory\n\n# Permission issues are handled gracefully\n./duplicate_folder_structure.sh /restricted /dest\n# Error: Failed to create directory: /dest/restricted_subdir\n# Errors encountered: 5\n# (Continues with accessible directories)\n</code></pre>"},{"location":"bash/system/duplicate_folder_structure.html#recovery-and-validation","title":"Recovery and Validation","text":"<pre><code>#!/bin/bash\n# Structure validation and recovery script\n\nvalidate_structure() {\n    local source=\"$1\"\n    local destination=\"$2\"\n\n    echo \"Validating structure duplication...\"\n\n    # Count directories in source\n    local source_count\n    source_count=$(find \"$source\" -type d | wc -l)\n\n    # Count directories in destination  \n    local dest_count\n    dest_count=$(find \"$destination\" -type d 2&gt;/dev/null | wc -l)\n\n    if [[ \"$source_count\" -eq \"$dest_count\" ]]; then\n        echo \"\u2713 Structure validation passed: $source_count directories\"\n        return 0\n    else\n        echo \"\u2717 Structure validation failed:\"\n        echo \"  Source: $source_count directories\"\n        echo \"  Destination: $dest_count directories\"\n        return 1\n    fi\n}\n\nretry_failed_duplication() {\n    local source=\"$1\"\n    local destination=\"$2\"\n    local max_retries=\"${3:-3}\"\n\n    for ((i=1; i&lt;=max_retries; i++)); do\n        echo \"Attempt $i/$max_retries: Duplicating structure\"\n\n        if ./duplicate_folder_structure.sh \"$source\" \"$destination\" --force; then\n            if validate_structure \"$source\" \"$destination\"; then\n                echo \"\u2713 Structure duplication successful on attempt $i\"\n                return 0\n            fi\n        fi\n\n        echo \"Attempt $i failed, retrying...\"\n        sleep 2\n    done\n\n    echo \"\u2717 Structure duplication failed after $max_retries attempts\"\n    return 1\n}\n\n# Usage\nretry_failed_duplication \"/complex/source\" \"/backup/destination\"\n</code></pre>"},{"location":"bash/system/duplicate_folder_structure.html#performance-considerations","title":"Performance Considerations","text":""},{"location":"bash/system/duplicate_folder_structure.html#optimization-for-large-directory-trees","title":"Optimization for Large Directory Trees","text":"<pre><code># For very large directory structures, monitor progress\n./duplicate_folder_structure.sh /massive/dataset /backup \\\n    --verbose \\\n    2&gt;&amp;1 | tee duplication.log\n\n# The script automatically shows progress for large operations:\n# Processed 100/1247 directories...\n# Processed 200/1247 directories...\n</code></pre>"},{"location":"bash/system/duplicate_folder_structure.html#benchmarking-performance","title":"Benchmarking Performance","text":"<pre><code>#!/bin/bash\n# Benchmark duplicate_folder_structure.sh performance\n\nbenchmark_duplication() {\n    local source=\"$1\"\n    local destination_base=\"$2\"\n    local iterations=\"${3:-3}\"\n\n    echo \"Benchmarking directory structure duplication\"\n    echo \"Source: $source\"\n    echo \"Iterations: $iterations\"\n    echo \"\"\n\n    local total_time=0\n    local successful_runs=0\n\n    for ((i=1; i&lt;=iterations; i++)); do\n        local dest=\"${destination_base}_test_${i}\"\n\n        # Clean up any existing destination\n        [[ -d \"$dest\" ]] &amp;&amp; rm -rf \"$dest\"\n\n        echo \"Iteration $i:\"\n        local start_time=$(date +%s)\n\n        if ./duplicate_folder_structure.sh \"$source\" \"$dest\" --force; then\n            local end_time=$(date +%s)\n            local duration=$((end_time - start_time))\n\n            echo \"  Time: ${duration}s\"\n            total_time=$((total_time + duration))\n            ((successful_runs++))\n        else\n            echo \"  FAILED\"\n        fi\n\n        echo \"\"\n    done\n\n    if [[ $successful_runs -gt 0 ]]; then\n        local avg_time=$((total_time / successful_runs))\n        echo \"Results:\"\n        echo \"  Successful runs: $successful_runs/$iterations\"\n        echo \"  Average time: ${avg_time}s\"\n        echo \"  Total time: ${total_time}s\"\n    else\n        echo \"No successful runs\"\n    fi\n}\n\n# Usage\nbenchmark_duplication \"/large/source\" \"/tmp/benchmark\" 5\n</code></pre>"},{"location":"bash/system/duplicate_folder_structure.html#best-practices","title":"Best Practices","text":""},{"location":"bash/system/duplicate_folder_structure.html#directory-structure-planning","title":"Directory Structure Planning","text":"<ol> <li>Test First - Always use <code>--dry-run</code> to preview operations</li> <li>Use Descriptive Names - Choose clear suffix/prefix patterns</li> <li>Validate Paths - Ensure source paths are correct before execution</li> <li>Check Permissions - Verify write access to destination areas</li> </ol>"},{"location":"bash/system/duplicate_folder_structure.html#shell-script-integration_1","title":"Shell Script Integration","text":"<ol> <li>Use --force Flag - For automated scripts to skip prompts</li> <li>Capture Exit Codes - Check <code>$?</code> after script execution</li> <li>Log Operations - Redirect output to log files for audit trails</li> <li>Handle Errors - Implement proper error handling in calling scripts</li> </ol>"},{"location":"bash/system/duplicate_folder_structure.html#safety-procedures","title":"Safety Procedures","text":"<ol> <li>Backup Important Paths - Don't duplicate over critical directories</li> <li>Test on Copies - Test with non-critical data first</li> <li>Monitor Disk Space - Ensure adequate space for new structures</li> <li>Document Operations - Keep records of structure duplications</li> </ol> <p>duplicate_folder_structure.sh provides high-performance directory structure duplication with optimized shell operations, comprehensive error handling, and seamless integration capabilities for automation workflows.</p>"},{"location":"bash/system/getDiskDevice.html","title":"Disk Device Finder (getDiskDevice.sh)","text":"<p>Find disk device identifiers by searching for volume labels on macOS systems.</p>"},{"location":"bash/system/getDiskDevice.html#usage","title":"Usage","text":"<pre><code>getDiskDevice.sh [label]\n</code></pre>"},{"location":"bash/system/getDiskDevice.html#arguments","title":"Arguments","text":"Argument Type Description Default <code>label</code> Optional Disk label to search for BackupSystem"},{"location":"bash/system/getDiskDevice.html#features","title":"Features","text":"<ul> <li>Label-Based Lookup: Find disks by human-readable names</li> <li>Device Identification: Returns BSD device identifiers (e.g., /dev/disk2s1)</li> <li>macOS Integration: Uses diskutil for accurate disk information</li> <li>Mount Status: Works with both mounted and unmounted volumes</li> </ul>"},{"location":"bash/system/getDiskDevice.html#examples","title":"Examples","text":"<pre><code># Search for default \"BackupSystem\" disk\n./getDiskDevice.sh\n\n# Find Time Machine disk\n./getDiskDevice.sh \"Time Machine\"\n\n# Find external drive\n./getDiskDevice.sh \"My External Drive\"\n\n# Use in scripts\nDEVICE=$(./getDiskDevice.sh \"Backup Drive\")\nif [[ -n \"$DEVICE\" ]]; then\n    echo \"Found backup disk at $DEVICE\"\nfi\n</code></pre>"},{"location":"bash/system/getDiskDevice.html#exit-codes","title":"Exit Codes","text":"<ul> <li>0: Disk found successfully</li> <li>1: Disk not found or error occurred</li> </ul>"},{"location":"bash/system/getDiskDevice.html#use-cases","title":"Use Cases","text":"<ul> <li>Backup Scripts: Locate backup drives automatically</li> <li>Maintenance Tasks: Find specific volumes for operations</li> <li>System Administration: Automate disk-based workflows</li> </ul>"},{"location":"bash/system/getDiskDevice.html#see-also","title":"See Also","text":"<ul> <li>System Functions - Disk management utilities</li> <li>System Administration Overview - Related tools</li> </ul> <p>Script Location: <code>bash/system/getDiskDevice.sh</code> Author: Alexander Kucera / babylondreams.de</p>"},{"location":"bash/system/log_collector.html","title":"Log Collector (log_collector.sh)","text":"<p>Advanced log collection and filtering system with category-based organization and time-based queries.</p>"},{"location":"bash/system/log_collector.html#overview","title":"Overview","text":"<p>The log collector is a standalone, comprehensive log monitoring tool that provides advanced filtering, category-based organization, and flexible time-based queries. Designed for system administrators and developers who need powerful log analysis capabilities.</p>"},{"location":"bash/system/log_collector.html#location","title":"Location","text":"<pre><code>bash/system/log_collector/\n\u251c\u2500\u2500 log_collector.sh      # Main script\n\u2514\u2500\u2500 log_sources.conf      # Configuration file\n</code></pre>"},{"location":"bash/system/log_collector.html#features","title":"Features","text":"<ul> <li>Category-Based Filtering: Organize logs by system, application, security, etc.</li> <li>Time-Based Queries: Filter logs by time ranges</li> <li>Configurable Sources: Define custom log sources and categories</li> <li>Advanced Options: Multiple output formats and filtering options</li> <li>Standalone Design: Self-contained with comprehensive functionality</li> </ul>"},{"location":"bash/system/log_collector.html#basic-usage","title":"Basic Usage","text":"<pre><code>cd bash/system/log_collector/\n\n# Show usage information\n./log_collector.sh --help\n\n# Create example configuration\n./log_collector.sh --create-config\n\n# Basic log collection (last 10 minutes)\n./log_collector.sh -t 10 -l 20\n</code></pre>"},{"location":"bash/system/log_collector.html#configuration","title":"Configuration","text":"<p>The <code>log_sources.conf</code> file defines log sources by category using pipe-delimited format:</p> <pre><code>system|/var/log/system.log|System messages\napplication|/var/log/app.log|Application logs\nsecurity|/var/log/auth.log|Security events\n</code></pre>"},{"location":"bash/system/log_collector.html#advanced-features","title":"Advanced Features","text":"<ul> <li>Multiple Categories: Filter logs by specific categories</li> <li>Custom Time Ranges: Flexible time-based filtering</li> <li>Output Control: Configurable line limits and formatting</li> <li>Real-time Monitoring: Live log tail functionality</li> <li>Export Options: Multiple output formats for analysis</li> </ul>"},{"location":"bash/system/log_collector.html#independence","title":"Independence","text":"<p>This script is intentionally kept standalone and does not use shared libraries, making it portable and self-contained for system administration tasks.</p>"},{"location":"bash/system/log_collector.html#see-also","title":"See Also","text":"<ul> <li>Log Size Checker - Monitor log file sizes</li> <li>System Administration Overview - Related tools</li> </ul> <p>Script Location: <code>bash/system/log_collector/log_collector.sh</code> Author: Alexander Kucera / babylondreams.de</p>"},{"location":"bash/system/purgeLoop.html","title":"Memory Purge Loop (purgeLoop.sh)","text":"<p>Automated memory management for macOS with intelligent monitoring and safe purging thresholds.</p>"},{"location":"bash/system/purgeLoop.html#usage","title":"Usage","text":"<pre><code>purgeLoop.sh [interval_minutes] [min_ram_percent] [inactive_percent]\n</code></pre>"},{"location":"bash/system/purgeLoop.html#arguments","title":"Arguments","text":"Argument Type Description Default <code>interval_minutes</code> Optional Check interval in minutes 15 <code>min_ram_percent</code> Optional Min free RAM % before purge 5 <code>inactive_percent</code> Optional Min inactive RAM % required 15"},{"location":"bash/system/purgeLoop.html#safety-features","title":"Safety Features","text":"<ul> <li>Intelligent Thresholds: Only purges when beneficial</li> <li>Continuous Monitoring: Regular memory status checks</li> <li>Safe Defaults: Conservative settings prevent system issues</li> <li>Manual Override: Ctrl+C to stop monitoring</li> </ul>"},{"location":"bash/system/purgeLoop.html#examples","title":"Examples","text":"<pre><code># Use defaults (15min intervals, 5% RAM, 15% inactive)\n./purgeLoop.sh\n\n# Check every 30 minutes\n./purgeLoop.sh 30\n\n# Aggressive settings (10min, 3% RAM, 20% inactive)\n./purgeLoop.sh 10 3 20\n\n# Conservative settings (60min, 2% RAM, 25% inactive)\n./purgeLoop.sh 60 2 25\n</code></pre>"},{"location":"bash/system/purgeLoop.html#how-it-works","title":"How It Works","text":"<ol> <li>Memory Monitoring: Continuously checks RAM usage</li> <li>Threshold Evaluation: Compares against configured limits</li> <li>Benefit Analysis: Only purges when inactive RAM is high enough</li> <li>Safe Purging: Uses macOS <code>purge</code> command when beneficial</li> <li>Status Reporting: Shows before/after memory statistics</li> </ol>"},{"location":"bash/system/purgeLoop.html#use-cases","title":"Use Cases","text":"<ul> <li>Long-Running Systems: Servers and workstations</li> <li>Memory-Intensive Work: Video editing, 3D rendering</li> <li>Background Maintenance: Automated system optimization</li> </ul>"},{"location":"bash/system/purgeLoop.html#see-also","title":"See Also","text":"<ul> <li>System Functions - Memory management utilities</li> <li>System Administration Overview - Related tools</li> </ul> <p>Script Location: <code>bash/system/purgeLoop.sh</code> Author: Alexander Kucera / babylondreams.de</p>"},{"location":"config/log_sources.html","title":"Log Sources Configuration (log_sources.conf)","text":"<p>Configuration file defining log sources and categories for the advanced log collection system.</p>"},{"location":"config/log_sources.html#configuration-file","title":"Configuration File","text":"<p>Location: <code>config/log_sources.conf</code></p>"},{"location":"config/log_sources.html#format","title":"Format","text":"<pre><code>category|log_path|description\n</code></pre>"},{"location":"config/log_sources.html#example-configuration","title":"Example Configuration","text":"<pre><code>system|/var/log/system.log|System messages and kernel events\napplication|/var/log/app.log|Application-specific logging\nsecurity|/var/log/auth.log|Authentication and security events\nnetwork|/var/log/network.log|Network connectivity and traffic\ndatabase|/var/log/mysql/error.log|Database errors and warnings\nweb|/var/log/apache2/access.log|Web server access logs\nmail|/var/log/mail.log|Email server notifications\ncustom|/path/to/custom.log|Custom application logs\n</code></pre>"},{"location":"config/log_sources.html#categories","title":"Categories","text":""},{"location":"config/log_sources.html#standard-categories","title":"Standard Categories","text":"<ul> <li>system - Core system messages</li> <li>application - Application-specific logs</li> <li>security - Security and authentication</li> <li>network - Network-related events</li> <li>database - Database operations</li> <li>web - Web server logs</li> <li>mail - Email system logs</li> </ul>"},{"location":"config/log_sources.html#custom-categories","title":"Custom Categories","text":"<p>Add your own categories for specific applications or services: <pre><code>render|/var/log/render.log|3D rendering operations\nbackup|/var/log/backup.log|Backup system status\nmonitoring|/var/log/monitor.log|System monitoring alerts\n</code></pre></p>"},{"location":"config/log_sources.html#usage-examples","title":"Usage Examples","text":""},{"location":"config/log_sources.html#system-administration","title":"System Administration","text":"<pre><code>system|/var/log/syslog|System daemon messages\nkernel|/var/log/kern.log|Kernel messages\nauth|/var/log/auth.log|User authentication\ncron|/var/log/cron.log|Scheduled task execution\n</code></pre>"},{"location":"config/log_sources.html#development-environment","title":"Development Environment","text":"<pre><code>app|/var/log/myapp.log|Main application logs\ndebug|/var/log/myapp_debug.log|Debug information\nerror|/var/log/myapp_error.log|Error tracking\nperformance|/var/log/performance.log|Performance metrics\n</code></pre>"},{"location":"config/log_sources.html#production-services","title":"Production Services","text":"<pre><code>nginx|/var/log/nginx/access.log|Web server access\nredis|/var/log/redis/redis.log|Cache server logs\npostgres|/var/log/postgresql/postgres.log|Database operations\ndocker|/var/log/docker.log|Container operations\n</code></pre>"},{"location":"config/log_sources.html#log-collection-usage","title":"Log Collection Usage","text":""},{"location":"config/log_sources.html#category-based-filtering","title":"Category-Based Filtering","text":"<pre><code># Collect system logs only\n./log_collector.sh -c system -t 60\n\n# Multiple categories\n./log_collector.sh -c \"system,security\" -t 30\n</code></pre>"},{"location":"config/log_sources.html#time-based-queries","title":"Time-Based Queries","text":"<pre><code># Last hour from all sources\n./log_collector.sh -t 60 -l 50\n\n# Last 24 hours from specific category\n./log_collector.sh -c application -t 1440\n</code></pre>"},{"location":"config/log_sources.html#best-practices","title":"Best Practices","text":""},{"location":"config/log_sources.html#file-paths","title":"File Paths","text":"<ol> <li>Use absolute paths for all log file locations</li> <li>Verify file permissions - ensure log files are readable</li> <li>Check file existence before adding to configuration</li> <li>Consider log rotation - paths should account for rotated logs</li> </ol>"},{"location":"config/log_sources.html#category-naming","title":"Category Naming","text":"<ol> <li>Use descriptive names that clearly indicate log source</li> <li>Keep names short for command-line convenience</li> <li>Use consistent naming across similar services</li> <li>Avoid special characters in category names</li> </ol>"},{"location":"config/log_sources.html#descriptions","title":"Descriptions","text":"<ol> <li>Provide clear descriptions for each log source</li> <li>Include service names where applicable</li> <li>Note any special formatting or important details</li> <li>Keep descriptions concise but informative</li> </ol>"},{"location":"config/log_sources.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"config/log_sources.html#file-not-found","title":"File Not Found","text":"<ul> <li>Verify log file paths exist</li> <li>Check file permissions (must be readable)</li> <li>Ensure services are actually writing to specified paths</li> </ul>"},{"location":"config/log_sources.html#permission-denied","title":"Permission Denied","text":"<ul> <li>Add read permissions: <code>chmod +r /var/log/logfile</code></li> <li>Add user to appropriate groups for log access</li> <li>Use sudo if necessary for system logs</li> </ul>"},{"location":"config/log_sources.html#empty-results","title":"Empty Results","text":"<ul> <li>Verify logs are being written to specified files</li> <li>Check that time range includes recent activity</li> <li>Ensure log format is compatible with collection tools</li> </ul>"},{"location":"config/log_sources.html#used-by","title":"Used By","text":"<ul> <li>Log Collector - Advanced log processing system</li> </ul> <p>Configuration file: <code>config/log_sources.conf</code></p>"},{"location":"config/mail_send.html","title":"Mail Configuration (mail_send.conf)","text":"<p>Email notification configuration for render completion alerts and system notifications.</p>"},{"location":"config/mail_send.html#configuration-file","title":"Configuration File","text":"<p>Location: <code>config/mail_send.conf</code></p>"},{"location":"config/mail_send.html#basic-configuration","title":"Basic Configuration","text":"<pre><code># SMTP server settings\nFROM_ADDRESS=\"renders@yourcompany.com\"\nTO_ADDRESS=\"team@yourcompany.com\"\nSERVER=\"smtp.yourserver.com\"\nUSER=\"smtp_username\"\n\n# Note: Password set via MAIL_PASSWORD environment variable\n</code></pre>"},{"location":"config/mail_send.html#environment-variables","title":"Environment Variables","text":""},{"location":"config/mail_send.html#required","title":"Required","text":"<pre><code>export MAIL_PASSWORD=\"your_smtp_password\"\n</code></pre>"},{"location":"config/mail_send.html#smtp-provider-examples","title":"SMTP Provider Examples","text":""},{"location":"config/mail_send.html#gmailgoogle-workspace","title":"Gmail/Google Workspace","text":"<pre><code>FROM_ADDRESS=\"notifications@yourcompany.com\"\nTO_ADDRESS=\"alerts@yourcompany.com\"\nSERVER=\"smtp.gmail.com:587\"\nUSER=\"notifications@yourcompany.com\"\n</code></pre>"},{"location":"config/mail_send.html#office-365","title":"Office 365","text":"<pre><code>FROM_ADDRESS=\"system@yourcompany.com\"\nTO_ADDRESS=\"team@yourcompany.com\"\nSERVER=\"smtp.office365.com:587\"\nUSER=\"system@yourcompany.com\"\n</code></pre>"},{"location":"config/mail_send.html#custom-smtp","title":"Custom SMTP","text":"<pre><code>FROM_ADDRESS=\"noreply@yourserver.com\"\nTO_ADDRESS=\"admin@yourserver.com\"\nSERVER=\"mail.yourserver.com:587\"\nUSER=\"smtp_user\"\n</code></pre>"},{"location":"config/mail_send.html#security-setup","title":"Security Setup","text":""},{"location":"config/mail_send.html#app-passwords","title":"App Passwords","text":"<p>For Gmail and Office 365, use app-specific passwords:</p> <ol> <li>Enable 2-factor authentication</li> <li>Generate app-specific password</li> <li>Use app password as MAIL_PASSWORD</li> </ol>"},{"location":"config/mail_send.html#environment-variable-setup","title":"Environment Variable Setup","text":"<pre><code># Add to ~/.bashrc or ~/.zshrc\nexport MAIL_PASSWORD=\"app_specific_password\"\n\n# For secure server deployment\necho 'export MAIL_PASSWORD=\"password\"' &gt;&gt; /etc/environment\n</code></pre>"},{"location":"config/mail_send.html#testing-configuration","title":"Testing Configuration","text":""},{"location":"config/mail_send.html#test-email","title":"Test Email","text":"<pre><code># Test with mail notification script\n./bash/rendering/mail_send.sh\n</code></pre>"},{"location":"config/mail_send.html#manual-test","title":"Manual Test","text":"<pre><code># Direct sendemail test\nsendemail -f \"test@yourcompany.com\" \\\n          -t \"admin@yourcompany.com\" \\\n          -m \"Test message\" \\\n          -u \"Test Subject\" \\\n          -s \"smtp.yourserver.com:587\" \\\n          -xu \"smtp_user\" \\\n          -xp \"$MAIL_PASSWORD\"\n</code></pre>"},{"location":"config/mail_send.html#used-by","title":"Used By","text":"<ul> <li>Mail Notifications</li> <li>Nuke Render Automation</li> </ul> <p>Configuration file: <code>config/mail_send.conf</code></p>"},{"location":"config/setup.html","title":"Configuration Setup Guide","text":"<p>Complete guide for configuring the Tinkertoys scripts collection for your environment.</p>"},{"location":"config/setup.html#overview","title":"Overview","text":"<p>The configuration system uses centralized configuration files in the <code>config/</code> directory to manage settings for various tools and services. This approach keeps sensitive information separate from scripts and allows for easy customization.</p>"},{"location":"config/setup.html#configuration-files","title":"Configuration Files","text":""},{"location":"config/setup.html#core-configuration-files","title":"Core Configuration Files","text":"File Purpose Required For <code>mail_send.conf</code> Email notifications Rendering scripts, notifications <code>log_sources.conf</code> Log collection sources Log collector system"},{"location":"config/setup.html#setup-process","title":"Setup Process","text":""},{"location":"config/setup.html#1-email-configuration","title":"1. Email Configuration","text":""},{"location":"config/setup.html#create-mail-configuration","title":"Create Mail Configuration","text":"<pre><code>cp config/mail_send.conf.example config/mail_send.conf\n</code></pre>"},{"location":"config/setup.html#edit-mail-settings","title":"Edit Mail Settings","text":"<pre><code># Email notification configuration\nFROM_ADDRESS=\"renders@yourcompany.com\"\nTO_ADDRESS=\"team@yourcompany.com\"\nSERVER=\"smtp.yourserver.com\"\nUSER=\"smtp_username\"\n# Note: PASS is set via environment variable for security\n</code></pre>"},{"location":"config/setup.html#set-environment-variables","title":"Set Environment Variables","text":"<pre><code># Add to your shell profile (.bashrc, .zshrc, etc.)\nexport MAIL_PASSWORD=\"your_smtp_password\"\n</code></pre>"},{"location":"config/setup.html#2-log-collection-setup","title":"2. Log Collection Setup","text":""},{"location":"config/setup.html#configure-log-sources","title":"Configure Log Sources","text":"<p>Edit <code>config/log_sources.conf</code> to define log sources by category:</p> <pre><code># Format: category|log_path|description\nsystem|/var/log/system.log|System messages and events\napplication|/var/log/app.log|Application-specific logs\nsecurity|/var/log/auth.log|Authentication and security events\ncustom|/path/to/custom.log|Custom application logs\n</code></pre>"},{"location":"config/setup.html#3-environment-variables","title":"3. Environment Variables","text":""},{"location":"config/setup.html#required-variables","title":"Required Variables","text":"<pre><code># Email notifications\nexport MAIL_PASSWORD=\"your_smtp_password\"\n\n# Nuke rendering (if using Nuke scripts)\nexport NUKEPATH=\"/Applications/Nuke/Nuke15.0v4/Nuke15.0v4\"\n\n# Custom log location (optional)\nexport LOG_FILE=\"/var/log/tinkertoys.log\"\n</code></pre>"},{"location":"config/setup.html#shell-profile-setup","title":"Shell Profile Setup","text":"<p>Add environment variables to your shell profile:</p> <pre><code># ~/.bashrc or ~/.zshrc\nexport MAIL_PASSWORD=\"your_smtp_password\"\nexport NUKEPATH=\"/Applications/Nuke/Nuke15.0v4/Nuke15.0v4\"\nexport PATH=\"/path/to/tinkertoys/bash:$PATH\"\n</code></pre>"},{"location":"config/setup.html#4-dependencies-installation","title":"4. Dependencies Installation","text":""},{"location":"config/setup.html#required-software","title":"Required Software","text":"<pre><code># FFmpeg for media processing\nbrew install ffmpeg\n\n# SendEmail for notifications\nbrew install sendemail\n# or download from: http://caspian.dotconf.net/menu/Software/SendEmail/\n\n# Optional: Nuke for rendering scripts\n# Install from Foundry website\n</code></pre>"},{"location":"config/setup.html#python-dependencies","title":"Python Dependencies","text":"<pre><code># If using Python scripts\npip install -r requirements.txt  # if available\n</code></pre>"},{"location":"config/setup.html#5-permissions-setup","title":"5. Permissions Setup","text":""},{"location":"config/setup.html#script-permissions","title":"Script Permissions","text":"<pre><code># Make all scripts executable\nfind bash/ -name \"*.sh\" -exec chmod +x {} \\;\n</code></pre>"},{"location":"config/setup.html#directory-permissions","title":"Directory Permissions","text":"<pre><code># Ensure log directories exist and are writable\nmkdir -p ~/logs\nchmod 755 ~/logs\n\n# For system logs (if needed)\nsudo mkdir -p /var/log/tinkertoys\nsudo chown $(whoami) /var/log/tinkertoys\n</code></pre>"},{"location":"config/setup.html#testing-configuration","title":"Testing Configuration","text":""},{"location":"config/setup.html#email-configuration-test","title":"Email Configuration Test","text":"<pre><code># Test email notifications\n./bash/rendering/mail_send.sh\n</code></pre>"},{"location":"config/setup.html#log-collection-test","title":"Log Collection Test","text":"<pre><code># Test log collector\ncd bash/system/log_collector/\n./log_collector.sh --help\n./log_collector.sh -t 10 -l 5\n</code></pre>"},{"location":"config/setup.html#media-processing-test","title":"Media Processing Test","text":"<pre><code># Test media functions (requires FFmpeg)\n./bash/media/convert_movie_to_h264.sh --help\n</code></pre>"},{"location":"config/setup.html#security-best-practices","title":"Security Best Practices","text":""},{"location":"config/setup.html#sensitive-information","title":"Sensitive Information","text":"<ol> <li>Never commit passwords to version control</li> <li>Use environment variables for all credentials</li> <li>Set appropriate file permissions on configuration files</li> <li>Regularly rotate passwords and update configurations</li> </ol>"},{"location":"config/setup.html#file-permissions","title":"File Permissions","text":"<pre><code># Secure configuration files\nchmod 600 config/mail_send.conf\nchmod 644 config/log_sources.conf\n</code></pre>"},{"location":"config/setup.html#environment-variables","title":"Environment Variables","text":"<pre><code># Verify environment variables are set\necho \"Mail password set: $([[ -n \"$MAIL_PASSWORD\" ]] &amp;&amp; echo \"Yes\" || echo \"No\")\"\necho \"Nuke path set: $([[ -n \"$NUKEPATH\" ]] &amp;&amp; echo \"Yes\" || echo \"No\")\"\n</code></pre>"},{"location":"config/setup.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"config/setup.html#common-issues","title":"Common Issues","text":""},{"location":"config/setup.html#email-not-working","title":"Email Not Working","text":"<ol> <li>Check SMTP server settings in <code>mail_send.conf</code></li> <li>Verify <code>MAIL_PASSWORD</code> environment variable is set</li> <li>Test network connectivity to SMTP server</li> <li>Check firewall settings</li> </ol>"},{"location":"config/setup.html#scripts-not-found","title":"Scripts Not Found","text":"<ol> <li>Verify scripts are executable: <code>ls -la bash/</code></li> <li>Check PATH includes script directories</li> <li>Use absolute paths if needed</li> </ol>"},{"location":"config/setup.html#permission-denied","title":"Permission Denied","text":"<ol> <li>Check file permissions: <code>ls -la config/</code></li> <li>Verify directory write permissions</li> <li>Check ownership of files and directories</li> </ol>"},{"location":"config/setup.html#missing-dependencies","title":"Missing Dependencies","text":"<ol> <li>Install required software (FFmpeg, sendemail, etc.)</li> <li>Verify commands are in PATH: <code>which ffmpeg</code></li> <li>Check version compatibility</li> </ol>"},{"location":"config/setup.html#validation-commands","title":"Validation Commands","text":"<pre><code># Validate configuration\n./bash/test_all_scripts.sh\n\n# Quick validation\n./bash/quick_test.sh\n\n# Comprehensive validation\n./bash/final_validation.sh\n</code></pre>"},{"location":"config/setup.html#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"config/setup.html#custom-log-locations","title":"Custom Log Locations","text":"<pre><code># Per-script log files\nexport LOG_FILE=\"/var/log/media_processing.log\"\n./bash/media/convert_movie_to_h264.sh input.mov\n\n# Temporary log for specific operations\nLOG_FILE=\"./operation_$(date +%Y%m%d).log\" ./bash/script.sh\n</code></pre>"},{"location":"config/setup.html#integration-with-system-services","title":"Integration with System Services","text":"<pre><code># systemd service example (Linux)\n[Unit]\nDescription=Tinkertoys Background Service\nAfter=network.target\n\n[Service]\nType=simple\nEnvironment=MAIL_PASSWORD=your_password\nEnvironment=LOG_FILE=/var/log/tinkertoys.log\nExecStart=/path/to/tinkertoys/bash/script.sh\nRestart=always\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>"},{"location":"config/setup.html#backup-configuration","title":"Backup Configuration","text":"<pre><code># Backup configuration files\ntar -czf tinkertoys_config_$(date +%Y%m%d).tar.gz config/\n\n# Restore configuration\ntar -xzf tinkertoys_config_backup.tar.gz\n</code></pre>"},{"location":"config/setup.html#see-also","title":"See Also","text":"<ul> <li>Mail Configuration - Detailed email setup</li> <li>Log Sources Configuration - Log collection setup</li> <li>Bash Scripts Overview - Script usage patterns</li> </ul> <p>Configuration files located in: <code>config/</code> Author: Alexander Kucera / babylondreams.de</p>"},{"location":"python/overview.html","title":"Python Scripts Overview","text":"<p>Collection of modernized Python utilities for file management, data processing, media conversion, and development workflow automation. All scripts have been upgraded to Python 3.11+ with enhanced security, performance, and usability features.</p>"},{"location":"python/overview.html#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"<p>The Python scripts are organized into logical directories following a modular design:</p> <pre><code>python/\n\u251c\u2500\u2500 data/           # Data processing and export tools\n\u251c\u2500\u2500 development/    # Development workflow utilities  \n\u251c\u2500\u2500 lib/           # Shared libraries and utilities\n\u251c\u2500\u2500 media/         # Media processing tools\n\u2514\u2500\u2500 system/        # System administration utilities\n</code></pre>"},{"location":"python/overview.html#script-categories","title":"\ud83d\udcc1 Script Categories","text":""},{"location":"python/overview.html#data-processing-data","title":"Data Processing (<code>data/</code>)","text":"<p>Advanced tools for data analysis, export, and transformation:</p> <ul> <li>DayOne_split.py - Split DayOne journal exports into individual daily files</li> <li>exportPinboard.py - Export Pinboard bookmarks with automated backup</li> <li>renderstats.py - Analyze render statistics and identify missing/corrupted frames</li> </ul>"},{"location":"python/overview.html#development-tools-development","title":"Development Tools (<code>development/</code>)","text":"<p>Utilities to enhance development workflows:</p> <ul> <li>markemptyfolders.py - Create Git placeholders in empty directories</li> <li>timer.py - Performance timing, stopwatch, and command benchmarking</li> </ul>"},{"location":"python/overview.html#system-utilities-system","title":"System Utilities (<code>system/</code>)","text":"<p>File management and system administration tools:</p> <ul> <li>compareFolders.py - Advanced directory comparison and synchronization analysis</li> <li>compareSizes.py - File integrity verification using size and checksum comparison</li> <li>fix_symlinks.py - Intelligent symlink repair and validation</li> <li>keepLargerVersion.py - Automated duplicate file management</li> <li>switch_paths.py - Bulk path replacement with JSON configuration</li> </ul>"},{"location":"python/overview.html#media-processing-media","title":"Media Processing (<code>media/</code>)","text":"<p>Secure media conversion and processing:</p> <ul> <li>convert_psd_to_exr.py - Safe Photoshop to EXR conversion with security hardening</li> </ul>"},{"location":"python/overview.html#shared-libraries-lib","title":"Shared Libraries (<code>lib/</code>)","text":"<p>Reusable utilities for common operations:</p> <ul> <li>applescript.py - Modern macOS AppleScript integration</li> <li>copyFile.py - Advanced file copying with progress tracking</li> <li>hash_for_file.py - Multi-algorithm file hashing utilities</li> <li>query_yes_no.py - Enhanced interactive user prompts</li> </ul>"},{"location":"python/overview.html#key-features","title":"\ud83d\ude80 Key Features","text":""},{"location":"python/overview.html#security-enhancements","title":"Security Enhancements","text":"<ul> <li>\u2705 No shell injection vulnerabilities - All subprocess calls use secure parameter passing</li> <li>\u2705 No hardcoded paths - All file paths are configurable via command-line arguments</li> <li>\u2705 Input validation - Comprehensive validation of all user inputs and file paths</li> <li>\u2705 Error handling - Robust error handling with meaningful error messages</li> </ul>"},{"location":"python/overview.html#modern-python-311-features","title":"Modern Python 3.11+ Features","text":"<ul> <li>\ud83d\udc0d Type hints - Full type annotation for better code clarity and IDE support</li> <li>\ud83c\udfaf f-string formatting - Modern string formatting throughout</li> <li>\ud83d\udcc1 pathlib - Modern path handling instead of os.path</li> <li>\ud83d\udd27 argparse CLI - Standardized command-line interfaces with comprehensive help</li> </ul>"},{"location":"python/overview.html#performance-optimizations","title":"Performance Optimizations","text":"<ul> <li>\u26a1 Blake2b hashing - Modern, faster hash algorithm as default (replaces SHA1)</li> <li>\ud83d\udcca Progress tracking - Optional progress bars for long-running operations</li> <li>\ud83d\udd04 Generator-based processing - Memory-efficient file processing</li> <li>\ud83c\udf9b\ufe0f Configurable buffer sizes - Optimized I/O performance</li> </ul>"},{"location":"python/overview.html#usability-improvements","title":"Usability Improvements","text":"<ul> <li>\ud83d\udcd6 Comprehensive help - All scripts include <code>--help/-h</code> with detailed usage examples</li> <li>\ud83d\udd0d Verbose modes - Optional detailed output for debugging and monitoring</li> <li>\ud83c\udf27\ufe0f Dry-run support - Preview operations before execution</li> <li>\ud83d\udd04 Backup functionality - Automatic backup creation where appropriate</li> </ul>"},{"location":"python/overview.html#requirements","title":"\ud83d\udee0\ufe0f Requirements","text":""},{"location":"python/overview.html#core-requirements","title":"Core Requirements","text":"<ul> <li>Python 3.11+ - Modern Python with latest features and security updates</li> <li>No mandatory dependencies - All scripts work with standard library</li> </ul>"},{"location":"python/overview.html#optional-dependencies","title":"Optional Dependencies","text":"<ul> <li>tqdm - Progress bars for long operations (<code>pip install tqdm</code>)</li> <li>pytz - Timezone handling for timestamp operations (<code>pip install pytz</code>)</li> <li>parsedatetime - Advanced date parsing (<code>pip install parsedatetime</code>)</li> </ul>"},{"location":"python/overview.html#platform-requirements","title":"Platform Requirements","text":"<ul> <li>Cross-platform - Most scripts work on Windows, macOS, and Linux</li> <li>macOS-specific - AppleScript integration requires macOS</li> <li>Unix-like systems - Some features optimized for Unix-like environments</li> </ul>"},{"location":"python/overview.html#usage-patterns","title":"\ud83d\udccb Usage Patterns","text":""},{"location":"python/overview.html#standard-cli-usage","title":"Standard CLI Usage","text":"<p>All scripts follow consistent command-line patterns:</p> <pre><code># Get help for any script\npython3 script_name.py --help\n\n# Basic usage with required arguments\npython3 script_name.py input_path\n\n# Advanced usage with options\npython3 script_name.py input_path --output-dir /path/to/output --verbose --dry-run\n</code></pre>"},{"location":"python/overview.html#common-options","title":"Common Options","text":"<p>Most scripts support these standard options:</p> <ul> <li><code>--help, -h</code> - Show detailed help and usage examples</li> <li><code>--verbose, -v</code> - Enable detailed output</li> <li><code>--dry-run</code> - Preview operations without making changes</li> <li><code>--output-dir, -o</code> - Specify output directory</li> <li><code>--recursive, -r</code> - Process directories recursively</li> </ul>"},{"location":"python/overview.html#library-usage","title":"Library Usage","text":"<p>Shared libraries can be imported and used programmatically:</p> <pre><code># Import shared utilities\nfrom lib.hash_for_file import hash_for_file\nfrom lib.query_yes_no import query_yes_no\nfrom lib.copyFile import copy_file\n\n# Use in your own scripts\nfile_hash = hash_for_file(\"/path/to/file\", \"blake2b\")\nif query_yes_no(\"Proceed with operation?\"):\n    copy_file(source, destination, verbose=True)\n</code></pre>"},{"location":"python/overview.html#migration-from-legacy-versions","title":"\ud83d\udd04 Migration from Legacy Versions","text":"<p>All scripts maintain backward compatibility while providing modern interfaces:</p>"},{"location":"python/overview.html#legacy-function-support","title":"Legacy Function Support","text":"<ul> <li>Old function names are aliased to new implementations</li> <li>Parameter names updated but old ones still accepted</li> <li>Deprecation warnings guide migration to new syntax</li> </ul>"},{"location":"python/overview.html#configuration-migration","title":"Configuration Migration","text":"<ul> <li>Hardcoded paths replaced with CLI arguments and configuration files</li> <li>Environment variables supported for default values</li> <li>JSON configuration files for complex setups</li> </ul>"},{"location":"python/overview.html#performance-benchmarks","title":"\ud83d\udcca Performance Benchmarks","text":"<p>Recent optimizations have achieved significant performance improvements:</p> <ul> <li>Hash calculations: 40-60% faster using Blake2b vs SHA1</li> <li>File copying: 20-30% faster with optimized buffering</li> <li>Directory scanning: 50-70% faster using pathlib generators</li> <li>Progress feedback: Real-time updates with minimal overhead</li> </ul>"},{"location":"python/overview.html#troubleshooting","title":"\ud83d\udc1b Troubleshooting","text":""},{"location":"python/overview.html#common-issues","title":"Common Issues","text":"<ol> <li>Permission errors - Ensure proper file/directory permissions</li> <li>Missing dependencies - Install optional packages as needed</li> <li>Path encoding - Use absolute paths to avoid encoding issues</li> <li>Python version - Ensure Python 3.11+ for full compatibility</li> </ol>"},{"location":"python/overview.html#getting-help","title":"Getting Help","text":"<ul> <li>Use <code>--help</code> flag for script-specific documentation</li> <li>Check individual script documentation pages</li> <li>Review inline docstrings and type hints for detailed API information</li> </ul> <p>All Python scripts have been modernized and security-hardened as of 2024. Each script includes comprehensive documentation, type hints, and security best practices.</p>"},{"location":"python/data/dayone_split.html","title":"DayOne_split.py","text":"<p>Split DayOne Markdown export into separate files per day with flexible date parsing and configurable output formats.</p>"},{"location":"python/data/dayone_split.html#overview","title":"Overview","text":"<p>DayOne_split.py processes exported DayOne journal files and splits them into individual daily journal entries. The script automatically parses dates from the export format and creates separate files for each day, making it easier to process or migrate journal entries.</p>"},{"location":"python/data/dayone_split.html#features","title":"Features","text":"<ul> <li>Flexible Date Parsing - Supports multiple date formats with fallback parsing</li> <li>Configurable Output - Customizable filename prefixes, suffixes, and extensions</li> <li>Optional Dependencies - Works with or without parsedatetime library</li> <li>Error Handling - Robust error handling for malformed exports</li> <li>CLI Interface - Full command-line interface with comprehensive options</li> </ul>"},{"location":"python/data/dayone_split.html#usage","title":"Usage","text":""},{"location":"python/data/dayone_split.html#basic-usage","title":"Basic Usage","text":"<pre><code># Split a DayOne export file\npython3 DayOne_split.py DayOne.md\n\n# Specify output directory\npython3 DayOne_split.py DayOne.md --output-dir /path/to/split/files\n</code></pre>"},{"location":"python/data/dayone_split.html#advanced-usage","title":"Advanced Usage","text":"<pre><code># Custom filename format\npython3 DayOne_split.py DayOne.md \\\n    --prefix \"diary_\" \\\n    --suffix \"_export\" \\\n    --extension txt\n\n# Custom date format for filenames\npython3 DayOne_split.py DayOne.md --date-format \"%Y_%m_%d\"\n\n# Verbose output\npython3 DayOne_split.py DayOne.md --verbose\n</code></pre>"},{"location":"python/data/dayone_split.html#command-line-options","title":"Command-Line Options","text":"Option Short Description Default <code>input_file</code> - DayOne export file (Markdown format) Required <code>--output-dir</code> <code>-o</code> Output directory for split files Same as input file <code>--prefix</code> <code>-p</code> Filename prefix for split files <code>journal_</code> <code>--suffix</code> <code>-s</code> Filename suffix for split files <code>_dayone-export</code> <code>--extension</code> <code>-e</code> File extension for split files <code>md</code> <code>--date-format</code> <code>-d</code> Date format for filenames <code>%Y-%m-%d</code> <code>--verbose</code> <code>-v</code> Show detailed output False"},{"location":"python/data/dayone_split.html#date-format-examples","title":"Date Format Examples","text":"<p>The <code>--date-format</code> option uses Python's strftime format:</p> <ul> <li><code>%Y-%m-%d</code> \u2192 <code>2024-07-05</code> (default)</li> <li><code>%Y_%m_%d</code> \u2192 <code>2024_07_05</code></li> <li><code>%B_%d_%Y</code> \u2192 <code>July_05_2024</code></li> <li><code>%y%m%d</code> \u2192 <code>240705</code></li> </ul>"},{"location":"python/data/dayone_split.html#supported-date-formats","title":"Supported Date Formats","text":"<p>The script can parse various date formats from DayOne exports:</p> <ul> <li><code>January 15, 2013 at 10:30 AM</code></li> <li><code>January 15, 2013 at 22:30</code></li> <li><code>January 15, 2013</code></li> <li><code>2013-01-15 10:30:00</code></li> <li><code>2013-01-15</code></li> </ul>"},{"location":"python/data/dayone_split.html#output-structure","title":"Output Structure","text":"<p>Given a DayOne export file, the script creates:</p> <pre><code>output_directory/\n\u251c\u2500\u2500 journal_2024-07-01_dayone-export.md\n\u251c\u2500\u2500 journal_2024-07-02_dayone-export.md\n\u251c\u2500\u2500 journal_2024-07-03_dayone-export.md\n\u2514\u2500\u2500 ...\n</code></pre> <p>Each file contains all journal entries for that specific date.</p>"},{"location":"python/data/dayone_split.html#dependencies","title":"Dependencies","text":""},{"location":"python/data/dayone_split.html#required","title":"Required","text":"<ul> <li>Python 3.11+</li> <li>Standard library modules only</li> </ul>"},{"location":"python/data/dayone_split.html#optional","title":"Optional","text":"<ul> <li>parsedatetime - Enhanced date parsing capabilities   <pre><code>pip install parsedatetime\n</code></pre></li> </ul>"},{"location":"python/data/dayone_split.html#error-handling","title":"Error Handling","text":"<p>The script handles various error conditions gracefully:</p> <ul> <li>File not found - Clear error message if input file doesn't exist</li> <li>Invalid dates - Warning messages for unparseable dates with fallback handling</li> <li>Write permissions - Error handling for output directory creation issues</li> <li>Malformed exports - Robust parsing that handles unexpected format variations</li> </ul>"},{"location":"python/data/dayone_split.html#examples","title":"Examples","text":""},{"location":"python/data/dayone_split.html#example-1-basic-split","title":"Example 1: Basic Split","text":"<p><pre><code>python3 DayOne_split.py ~/Desktop/DayOne.md\n</code></pre> Creates files like <code>journal_2024-07-05_dayone-export.md</code> in the same directory.</p>"},{"location":"python/data/dayone_split.html#example-2-custom-organization","title":"Example 2: Custom Organization","text":"<p><pre><code>python3 DayOne_split.py ~/Desktop/DayOne.md \\\n    --output-dir ~/Documents/Journal \\\n    --prefix \"entry_\" \\\n    --suffix \"\" \\\n    --extension txt \\\n    --date-format \"%Y/%m/%d\"\n</code></pre> Creates files like <code>entry_2024/07/05.txt</code> in the Journal directory.</p>"},{"location":"python/data/dayone_split.html#example-3-year-month-organization","title":"Example 3: Year-Month Organization","text":"<p><pre><code>python3 DayOne_split.py ~/Desktop/DayOne.md \\\n    --output-dir ~/Documents/Journal \\\n    --date-format \"%Y-%m/%d\" \\\n    --verbose\n</code></pre> Creates subdirectories by month: <code>2024-07/05_dayone-export.md</code></p>"},{"location":"python/data/dayone_split.html#implementation-details","title":"Implementation Details","text":""},{"location":"python/data/dayone_split.html#date-parsing-strategy","title":"Date Parsing Strategy","text":"<ol> <li>Primary: Use parsedatetime library if available</li> <li>Fallback: Try common date format patterns</li> <li>Graceful degradation: Create fallback files for unparseable dates</li> </ol>"},{"location":"python/data/dayone_split.html#file-organization","title":"File Organization","text":"<ul> <li>Creates output directories automatically if they don't exist</li> <li>Handles duplicate dates by appending to existing files</li> <li>Preserves original content formatting and structure</li> </ul>"},{"location":"python/data/dayone_split.html#memory-efficiency","title":"Memory Efficiency","text":"<ul> <li>Processes files line-by-line to handle large exports</li> <li>Minimal memory footprint regardless of export size</li> </ul>"},{"location":"python/data/dayone_split.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"python/data/dayone_split.html#common-issues","title":"Common Issues","text":"<p>Issue: \"Could not parse date\" warnings <pre><code>Solution: Install parsedatetime for better date parsing:\npip install parsedatetime\n</code></pre></p> <p>Issue: Permission denied errors <pre><code>Solution: Ensure write permissions to output directory:\nchmod 755 /path/to/output/directory\n</code></pre></p> <p>Issue: Empty output files <pre><code>Solution: Check that input file is a valid DayOne export with \"Date:\" lines\n</code></pre></p>"},{"location":"python/data/dayone_split.html#debugging","title":"Debugging","text":"<p>Use the <code>--verbose</code> flag to see detailed processing information:</p> <pre><code>python3 DayOne_split.py DayOne.md --verbose\n</code></pre> <p>This shows: - Files being created - Date parsing results - Processing progress - Any warnings or issues</p>"},{"location":"python/data/dayone_split.html#integration","title":"Integration","text":""},{"location":"python/data/dayone_split.html#workflow-integration","title":"Workflow Integration","text":"<p>The script integrates well with automated workflows:</p> <pre><code># Automated daily journal processing\npython3 DayOne_split.py ~/Dropbox/DayOne.md \\\n    --output-dir ~/Documents/Journal/$(date +%Y) \\\n    --date-format \"%m-%d\" \\\n    --verbose\n</code></pre>"},{"location":"python/data/dayone_split.html#scripting-example","title":"Scripting Example","text":"<pre><code>import subprocess\nimport sys\n\ndef split_dayone_export(export_file, output_dir):\n    \"\"\"Split DayOne export using the script.\"\"\"\n    cmd = [\n        sys.executable, \"DayOne_split.py\",\n        export_file,\n        \"--output-dir\", output_dir,\n        \"--verbose\"\n    ]\n    return subprocess.run(cmd, capture_output=True, text=True)\n</code></pre> <p>DayOne_split.py provides a robust solution for processing DayOne exports with extensive customization options and error handling.</p>"},{"location":"python/data/export_pinboard.html","title":"exportPinboard.py","text":"<p>Export Pinboard bookmarks as XML files for backup and further processing with automated daily backup functionality.</p>"},{"location":"python/data/export_pinboard.html#overview","title":"Overview","text":"<p>exportPinboard.py creates automated backups of your Pinboard bookmarks by connecting to the Pinboard API and downloading all bookmarks in XML format. The script supports both one-time exports and scheduled backups with date-based file organization.</p>"},{"location":"python/data/export_pinboard.html#features","title":"Features","text":"<ul> <li>Secure Authentication - Uses external credentials file for API token storage</li> <li>Automated Backup - Date-based backup file organization</li> <li>Current File Maintenance - Maintains an always-current backup file</li> <li>Error Handling - Comprehensive error handling for network and API issues</li> <li>Configurable Paths - All file paths configurable via command line</li> <li>Rate Limiting - Respects Pinboard API rate limits</li> </ul>"},{"location":"python/data/export_pinboard.html#usage","title":"Usage","text":""},{"location":"python/data/export_pinboard.html#basic-usage","title":"Basic Usage","text":"<pre><code># Export with default paths\npython3 exportPinboard.py\n\n# Specify custom output directory\npython3 exportPinboard.py --output-dir /path/to/backups\n</code></pre>"},{"location":"python/data/export_pinboard.html#advanced-usage","title":"Advanced Usage","text":"<pre><code># Use custom credentials file\npython3 exportPinboard.py --credentials /path/to/credentials.txt\n\n# Custom date format for backup files\npython3 exportPinboard.py --date-format \"%Y-%m-%d\"\n\n# Export to specific file without date-based naming\npython3 exportPinboard.py --output-file /path/to/bookmarks.xml\n\n# Don't update current file\npython3 exportPinboard.py --no-current --verbose\n</code></pre>"},{"location":"python/data/export_pinboard.html#command-line-options","title":"Command-Line Options","text":"Option Short Description Default <code>--output-dir</code> <code>-o</code> Output directory for backups <code>~/Dropbox/Apps/pinboard/</code> <code>--output-file</code> <code>-f</code> Specific output file (overrides date-based naming) None <code>--credentials</code> <code>-c</code> Path to credentials file <code>[output-dir]/pinboard_credentials.txt</code> <code>--date-format</code> <code>-d</code> Date format for backup filenames <code>%m-%d</code> <code>--current-file</code> - Path for 'current' bookmark file <code>[output-dir]/most_current_bookmarks.xml</code> <code>--api-url</code> - Pinboard API base URL <code>https://api.pinboard.in/v1/</code> <code>--no-current</code> - Don't create/update current bookmarks file False <code>--verbose</code> <code>-v</code> Show detailed output False"},{"location":"python/data/export_pinboard.html#setup","title":"Setup","text":""},{"location":"python/data/export_pinboard.html#1-get-pinboard-api-token","title":"1. Get Pinboard API Token","text":"<ol> <li>Log into your Pinboard account</li> <li>Go to Settings \u2192 Password</li> <li>Your API token is shown as <code>username:HEXSTRING</code></li> </ol>"},{"location":"python/data/export_pinboard.html#2-create-credentials-file","title":"2. Create Credentials File","text":"<p>Create a text file containing your credentials: <pre><code>username:your_api_token_here\n</code></pre></p> <p>Security Note: Keep this file secure and never commit it to version control.</p>"},{"location":"python/data/export_pinboard.html#3-set-permissions","title":"3. Set Permissions","text":"<pre><code>chmod 600 /path/to/pinboard_credentials.txt\n</code></pre>"},{"location":"python/data/export_pinboard.html#default-file-organization","title":"Default File Organization","text":"<p>The script creates a hierarchical backup structure:</p> <pre><code>~/Dropbox/Apps/pinboard/\n\u251c\u2500\u2500 pinboard_credentials.txt          # Your API credentials\n\u251c\u2500\u2500 most_current_bookmarks.xml        # Always current backup\n\u251c\u2500\u2500 2024/\n\u2502   \u251c\u2500\u2500 pinboard-backup.01-15.xml    # January 15th backup\n\u2502   \u251c\u2500\u2500 pinboard-backup.01-16.xml    # January 16th backup\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 2023/\n\u2502   \u251c\u2500\u2500 pinboard-backup.12-31.xml\n\u2502   \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"python/data/export_pinboard.html#date-format-examples","title":"Date Format Examples","text":"<p>The <code>--date-format</code> option uses Python's strftime format:</p> <ul> <li><code>%m-%d</code> \u2192 <code>07-05</code> (default)</li> <li><code>%Y-%m-%d</code> \u2192 <code>2024-07-05</code></li> <li><code>%B-%d</code> \u2192 <code>July-05</code></li> <li><code>%Y%m%d</code> \u2192 <code>20240705</code></li> </ul>"},{"location":"python/data/export_pinboard.html#api-integration","title":"API Integration","text":""},{"location":"python/data/export_pinboard.html#authentication","title":"Authentication","text":"<p>The script uses Pinboard's API token authentication: - No OAuth required - Simple username:token format - Secure token storage in external file</p>"},{"location":"python/data/export_pinboard.html#api-endpoint","title":"API Endpoint","text":"<p>Uses the <code>/posts/all</code> endpoint to retrieve all bookmarks: <pre><code>https://api.pinboard.in/v1/posts/all?auth_token=username:token\n</code></pre></p>"},{"location":"python/data/export_pinboard.html#rate-limiting","title":"Rate Limiting","text":"<ul> <li>Respects Pinboard's API rate limits</li> <li>Includes timeout handling for slow responses</li> <li>Proper error handling for rate limit exceeded (429) responses</li> </ul>"},{"location":"python/data/export_pinboard.html#dependencies","title":"Dependencies","text":""},{"location":"python/data/export_pinboard.html#required","title":"Required","text":"<ul> <li>Python 3.11+</li> <li>Standard library modules only</li> </ul>"},{"location":"python/data/export_pinboard.html#optional","title":"Optional","text":"<ul> <li>pytz - For timezone-aware timestamps   <pre><code>pip install pytz\n</code></pre></li> </ul>"},{"location":"python/data/export_pinboard.html#error-handling","title":"Error Handling","text":"<p>The script handles various error conditions:</p> <ul> <li>Authentication failures (401) - Invalid credentials</li> <li>Rate limiting (429) - API rate limit exceeded</li> <li>Network errors - Connection timeouts, DNS failures</li> <li>File system errors - Permission issues, disk space</li> <li>API errors - Malformed responses, server errors</li> </ul>"},{"location":"python/data/export_pinboard.html#examples","title":"Examples","text":""},{"location":"python/data/export_pinboard.html#example-1-daily-automated-backup","title":"Example 1: Daily Automated Backup","text":"<pre><code># Add to crontab for daily backup at 2 AM\n0 2 * * * /usr/bin/python3 /path/to/exportPinboard.py --verbose\n</code></pre>"},{"location":"python/data/export_pinboard.html#example-2-custom-organization","title":"Example 2: Custom Organization","text":"<pre><code>python3 exportPinboard.py \\\n    --output-dir ~/Backups/Pinboard \\\n    --date-format \"%Y-%m-%d\" \\\n    --credentials ~/.config/pinboard/credentials\n</code></pre>"},{"location":"python/data/export_pinboard.html#example-3-one-time-export","title":"Example 3: One-time Export","text":"<pre><code>python3 exportPinboard.py \\\n    --output-file ~/Desktop/pinboard-export-$(date +%Y%m%d).xml \\\n    --no-current\n</code></pre>"},{"location":"python/data/export_pinboard.html#output-format","title":"Output Format","text":"<p>The exported XML follows Pinboard's standard format:</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;posts user=\"username\" update=\"2024-07-05T12:00:00Z\" tag=\"\"&gt;\n    &lt;post href=\"https://example.com\" \n          description=\"Example Bookmark\" \n          extended=\"Longer description here\"\n          meta=\"checksum\" \n          hash=\"hash_value\" \n          time=\"2024-07-05T10:30:00Z\" \n          shared=\"yes\" \n          toread=\"no\" \n          tags=\"python programming\" /&gt;\n    &lt;!-- More bookmarks... --&gt;\n&lt;/posts&gt;\n</code></pre>"},{"location":"python/data/export_pinboard.html#security-considerations","title":"Security Considerations","text":""},{"location":"python/data/export_pinboard.html#credential-storage","title":"Credential Storage","text":"<ul> <li>Store credentials in a separate, secured file</li> <li>Use appropriate file permissions (600)</li> <li>Never hardcode credentials in scripts</li> </ul>"},{"location":"python/data/export_pinboard.html#network-security","title":"Network Security","text":"<ul> <li>Uses HTTPS for all API communication</li> <li>Validates SSL certificates</li> <li>Includes timeout protection</li> </ul>"},{"location":"python/data/export_pinboard.html#file-security","title":"File Security","text":"<ul> <li>Creates backup files with appropriate permissions</li> <li>Supports custom output locations outside of cloud sync</li> <li>Option to disable current file creation for added security</li> </ul>"},{"location":"python/data/export_pinboard.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"python/data/export_pinboard.html#common-issues","title":"Common Issues","text":"<p>Issue: \"Authentication failed\" error <pre><code>Solution: Check credentials file format and API token validity:\n- Format: username:token (no spaces)\n- Verify token in Pinboard settings\n</code></pre></p> <p>Issue: \"Rate limit exceeded\" error <pre><code>Solution: Wait before retrying. Pinboard has strict rate limits:\n- Wait at least 3 seconds between requests\n- Use for scheduled backups, not frequent polling\n</code></pre></p> <p>Issue: Empty export file <pre><code>Solution: Check API response and credentials:\npython3 exportPinboard.py --verbose\n</code></pre></p>"},{"location":"python/data/export_pinboard.html#debugging","title":"Debugging","text":"<p>Use verbose mode to see detailed operation information:</p> <pre><code>python3 exportPinboard.py --verbose\n</code></pre> <p>This shows: - Credential file reading - API request details - File creation progress - Any warnings or errors</p>"},{"location":"python/data/export_pinboard.html#integration","title":"Integration","text":""},{"location":"python/data/export_pinboard.html#backup-scripts","title":"Backup Scripts","text":"<pre><code>#!/bin/bash\n# Complete backup script with error handling\n\nBACKUP_DIR=\"$HOME/Backups/Pinboard\"\nLOG_FILE=\"$BACKUP_DIR/backup.log\"\n\necho \"$(date): Starting Pinboard backup\" &gt;&gt; \"$LOG_FILE\"\n\nif python3 exportPinboard.py --output-dir \"$BACKUP_DIR\" --verbose; then\n    echo \"$(date): Backup completed successfully\" &gt;&gt; \"$LOG_FILE\"\nelse\n    echo \"$(date): Backup failed\" &gt;&gt; \"$LOG_FILE\"\n    exit 1\nfi\n</code></pre>"},{"location":"python/data/export_pinboard.html#python-integration","title":"Python Integration","text":"<pre><code>import subprocess\nimport sys\nfrom pathlib import Path\n\ndef backup_pinboard(output_dir, verbose=False):\n    \"\"\"Create Pinboard backup using the script.\"\"\"\n    cmd = [\n        sys.executable, \"exportPinboard.py\",\n        \"--output-dir\", str(output_dir)\n    ]\n    if verbose:\n        cmd.append(\"--verbose\")\n\n    return subprocess.run(cmd, capture_output=True, text=True)\n\n# Usage\nresult = backup_pinboard(Path(\"~/Backups/Pinboard\"), verbose=True)\nif result.returncode == 0:\n    print(\"Backup successful\")\nelse:\n    print(f\"Backup failed: {result.stderr}\")\n</code></pre> <p>exportPinboard.py provides secure, automated Pinboard bookmark backup with flexible configuration and robust error handling.</p>"},{"location":"python/data/renderstats.html","title":"renderstats.py","text":"<p>Analyze render statistics for image sequences, calculate render times, identify missing frames, and detect corrupted files.</p>"},{"location":"python/data/renderstats.html#overview","title":"Overview","text":"<p>renderstats.py is a comprehensive tool for analyzing rendered image sequences. It examines directories containing sequential images (like render outputs), identifies missing frames, detects corrupted files, and calculates detailed render statistics based on file modification times.</p>"},{"location":"python/data/renderstats.html#features","title":"Features","text":"<ul> <li>Frame Sequence Analysis - Automatic detection of image sequence patterns</li> <li>Missing Frame Detection - Identifies gaps in frame sequences</li> <li>Corruption Detection - Finds files smaller than minimum expected size</li> <li>Render Time Statistics - Calculates total, average, min, and max render times</li> <li>Recursive Processing - Can analyze entire directory trees</li> <li>Multiple Output Formats - Console output or file reports</li> <li>Flexible Configuration - Customizable minimum file sizes and output formats</li> </ul>"},{"location":"python/data/renderstats.html#usage","title":"Usage","text":""},{"location":"python/data/renderstats.html#basic-usage","title":"Basic Usage","text":"<pre><code># Analyze current directory\npython3 renderstats.py .\n\n# Analyze specific directory\npython3 renderstats.py /path/to/renders\n\n# Recursive analysis of all subdirectories\npython3 renderstats.py /path/to/renders --recursive\n</code></pre>"},{"location":"python/data/renderstats.html#advanced-usage","title":"Advanced Usage","text":"<pre><code># Write reports to files instead of stdout\npython3 renderstats.py /path/to/renders --file\n\n# Custom output filename and minimum file size\npython3 renderstats.py /path/to/renders \\\n    --name \"render_report.txt\" \\\n    --min-size 256\n\n# Recursive with verbose output\npython3 renderstats.py /path/to/renders \\\n    --recursive \\\n    --verbose\n</code></pre>"},{"location":"python/data/renderstats.html#command-line-options","title":"Command-Line Options","text":"Option Short Description Default <code>input</code> - Input directory or file to analyze Required <code>--recursive</code> <code>-r</code> Process all subdirectories recursively False <code>--file</code> <code>-f</code> Write statistics to file instead of stdout False <code>--name</code> <code>-n</code> Output filename for statistics <code>renderstats.txt</code> <code>--min-size</code> - Minimum file size in bytes for valid files <code>128</code> <code>--verbose</code> <code>-v</code> Show detailed progress information False"},{"location":"python/data/renderstats.html#supported-image-sequences","title":"Supported Image Sequences","text":"<p>The script automatically detects common image sequence naming patterns:</p>"},{"location":"python/data/renderstats.html#supported-patterns","title":"Supported Patterns","text":"<ul> <li><code>render_001.exr</code>, <code>render_002.exr</code>, ...</li> <li><code>shot_0150.jpg</code>, <code>shot_0151.jpg</code>, ...</li> <li><code>frame.1001.png</code>, <code>frame.1002.png</code>, ...</li> <li><code>beauty_v001_0100.tiff</code>, <code>beauty_v001_0101.tiff</code>, ...</li> </ul>"},{"location":"python/data/renderstats.html#sequence-detection","title":"Sequence Detection","text":"<ul> <li>Uses regex pattern matching to identify frame numbers</li> <li>Supports various numbering schemes (3-6 digits)</li> <li>Handles different separators (underscores, dots, hyphens)</li> <li>Works with any image file extension</li> </ul>"},{"location":"python/data/renderstats.html#analysis-features","title":"Analysis Features","text":""},{"location":"python/data/renderstats.html#frame-analysis","title":"Frame Analysis","text":"<ul> <li>Frame Range Detection - Identifies first and last frame numbers</li> <li>Sequence Validation - Checks for complete frame sequences</li> <li>Gap Detection - Finds missing frames in sequences</li> <li>Range Reporting - Groups consecutive frames into ranges</li> </ul>"},{"location":"python/data/renderstats.html#file-integrity","title":"File Integrity","text":"<ul> <li>Size Validation - Identifies suspiciously small files</li> <li>Corruption Detection - Flags potential render failures</li> <li>Custom Thresholds - Configurable minimum file sizes</li> <li>Pattern Analysis - Correlates file sizes with render quality</li> </ul>"},{"location":"python/data/renderstats.html#render-statistics","title":"Render Statistics","text":"<ul> <li>Total Render Time - Time from first to last frame completion</li> <li>Average Frame Time - Mean time per frame</li> <li>Performance Analysis - Fastest and slowest frame times</li> <li>Timeline Analysis - Render progression over time</li> </ul>"},{"location":"python/data/renderstats.html#output-format","title":"Output Format","text":""},{"location":"python/data/renderstats.html#console-output","title":"Console Output","text":"<pre><code>Analysis for: /path/to/renders\n============================================================\n\nFRAME ANALYSIS:\nFrame range: 1001 to 1100\nTotal frames found: 98\nContinuous ranges: 1001-1050, 1052-1100\n\nMISSING FRAMES (2):\nMissing: 1051\n\nCORRUPTED FILES (1 files &lt; 128 bytes):\nFrames: 1055\n\nRENDER STATISTICS:\nTotal render time: 2 hours 15 minutes 30.50 seconds\nFiles processed: 98\nAverage per frame: 1 minutes 23.78 seconds\nFastest frame: 45.20 seconds\nSlowest frame: 3 minutes 12.10 seconds\n</code></pre>"},{"location":"python/data/renderstats.html#file-output","title":"File Output","text":"<p>When using <code>--file</code> option, creates detailed reports with: - Complete analysis summary - File-by-file details - Statistics breakdown - Timestamp information</p>"},{"location":"python/data/renderstats.html#examples","title":"Examples","text":""},{"location":"python/data/renderstats.html#example-1-basic-analysis","title":"Example 1: Basic Analysis","text":"<p><pre><code>python3 renderstats.py ~/Renders/Shot001\n</code></pre> Analyzes a single shot directory and displays results in console.</p>"},{"location":"python/data/renderstats.html#example-2-batch-processing","title":"Example 2: Batch Processing","text":"<p><pre><code>python3 renderstats.py ~/Renders --recursive --file --verbose\n</code></pre> Processes all shots in the Renders directory, creating individual report files.</p>"},{"location":"python/data/renderstats.html#example-3-quality-control","title":"Example 3: Quality Control","text":"<p><pre><code>python3 renderstats.py ~/Renders/Shot001 \\\n    --min-size 1024 \\\n    --name \"qc_report.txt\" \\\n    --file\n</code></pre> Generates quality control report with stricter file size requirements.</p>"},{"location":"python/data/renderstats.html#example-4-pipeline-integration","title":"Example 4: Pipeline Integration","text":"<pre><code># Process multiple shot directories\nfor shot in ~/Renders/Shot*; do\n    python3 renderstats.py \"$shot\" \\\n        --file \\\n        --name \"$(basename \"$shot\")_stats.txt\"\ndone\n</code></pre>"},{"location":"python/data/renderstats.html#render-time-calculation","title":"Render Time Calculation","text":""},{"location":"python/data/renderstats.html#methodology","title":"Methodology","text":"<p>The script calculates render times based on file modification timestamps:</p> <ol> <li>Collects Timestamps - Gets modification time for all sequence files</li> <li>Sorts Chronologically - Orders files by completion time</li> <li>Calculates Intervals - Measures time between consecutive frames</li> <li>Aggregates Statistics - Computes total, average, min, max times</li> </ol>"},{"location":"python/data/renderstats.html#accuracy-considerations","title":"Accuracy Considerations","text":"<ul> <li>File System Precision - Limited by filesystem timestamp resolution</li> <li>Network Rendering - May be affected by clock synchronization</li> <li>Parallel Rendering - Works best with sequential rendering</li> <li>Post-Processing - Excludes files modified after rendering</li> </ul>"},{"location":"python/data/renderstats.html#integration","title":"Integration","text":""},{"location":"python/data/renderstats.html#pipeline-scripts","title":"Pipeline Scripts","text":"<pre><code>#!/bin/bash\n# Render analysis pipeline\n\nRENDER_DIR=\"$1\"\nREPORT_DIR=\"$HOME/Reports\"\n\necho \"Analyzing renders in: $RENDER_DIR\"\n\n# Generate comprehensive report\npython3 renderstats.py \"$RENDER_DIR\" \\\n    --recursive \\\n    --file \\\n    --name \"render_analysis_$(date +%Y%m%d).txt\" \\\n    --verbose\n\n# Generate summary for email\npython3 renderstats.py \"$RENDER_DIR\" \\\n    --min-size 256 &gt; \"$REPORT_DIR/summary.txt\"\n</code></pre>"},{"location":"python/data/renderstats.html#python-integration","title":"Python Integration","text":"<pre><code>import subprocess\nimport sys\nfrom pathlib import Path\n\ndef analyze_renders(render_dir, output_file=None):\n    \"\"\"Analyze render directory and return statistics.\"\"\"\n    cmd = [\n        sys.executable, \"renderstats.py\",\n        str(render_dir),\n        \"--recursive\"\n    ]\n\n    if output_file:\n        cmd.extend([\"--file\", \"--name\", str(output_file)])\n\n    result = subprocess.run(cmd, capture_output=True, text=True)\n    return result.stdout if result.returncode == 0 else None\n\n# Usage\nstats = analyze_renders(Path(\"~/Renders/Shot001\"))\nif stats:\n    print(\"Analysis completed successfully\")\n    print(stats)\n</code></pre>"},{"location":"python/data/renderstats.html#dependencies","title":"Dependencies","text":""},{"location":"python/data/renderstats.html#required","title":"Required","text":"<ul> <li>Python 3.11+</li> <li>Standard library modules only</li> </ul>"},{"location":"python/data/renderstats.html#integration-with-timer-module","title":"Integration with Timer Module","text":"<ul> <li>Imports timing utilities from <code>development/timer.py</code></li> <li>Uses shared time formatting functions</li> <li>Consistent time display across tools</li> </ul>"},{"location":"python/data/renderstats.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"python/data/renderstats.html#common-issues","title":"Common Issues","text":"<p>Issue: \"No sequential files found\" message <pre><code>Solution: Check that directory contains properly named image sequences:\n- Files should have frame numbers (render_001.exr)\n- Use consistent naming patterns\n- Verify file extensions are recognized\n</code></pre></p> <p>Issue: Incorrect render times <pre><code>Solution: Verify file modification times are accurate:\n- Check if files were copied (preserves original times)\n- Ensure clock synchronization in network rendering\n- Consider using --verbose to see timestamp details\n</code></pre></p> <p>Issue: Large number of \"corrupted\" files <pre><code>Solution: Adjust minimum file size threshold:\npython3 renderstats.py directory --min-size 1024\n</code></pre></p>"},{"location":"python/data/renderstats.html#debugging","title":"Debugging","text":"<p>Use verbose mode for detailed processing information:</p> <pre><code>python3 renderstats.py directory --verbose\n</code></pre> <p>This shows: - Files being processed - Frame number detection - Timestamp analysis - Statistics calculations</p>"},{"location":"python/data/renderstats.html#performance-considerations","title":"Performance Considerations","text":""},{"location":"python/data/renderstats.html#large-datasets","title":"Large Datasets","text":"<ul> <li>Memory Efficient - Processes files incrementally</li> <li>I/O Optimized - Minimal file system calls</li> <li>Scalable - Handles thousands of files efficiently</li> </ul>"},{"location":"python/data/renderstats.html#network-filesystems","title":"Network Filesystems","text":"<ul> <li>Timestamp Caching - Caches file stats to reduce network calls</li> <li>Batch Processing - Groups operations for efficiency</li> <li>Timeout Handling - Graceful handling of slow network access</li> </ul> <p>renderstats.py provides comprehensive analysis of render sequences with detailed statistics and quality control features for production pipelines.</p>"},{"location":"python/development/markemptyfolders.html","title":"markemptyfolders.py","text":"<p>Create placeholder files in empty directories to make them trackable with Git, with comprehensive options for cleanup and customization.</p>"},{"location":"python/development/markemptyfolders.html#overview","title":"Overview","text":"<p>markemptyfolders.py solves the common Git problem of empty directories not being tracked in version control. The script automatically finds empty directories and creates placeholder files (typically <code>.gitkeep</code>) to preserve the directory structure in your repository.</p>"},{"location":"python/development/markemptyfolders.html#features","title":"Features","text":"<ul> <li>Automatic Discovery - Finds all empty directories in a project tree</li> <li>Customizable Placeholders - Configure placeholder filename and content</li> <li>Exclusion Rules - Skip system directories and hidden folders</li> <li>Cleanup Mode - Remove placeholders from directories that are no longer empty</li> <li>Dry Run Support - Preview operations before making changes</li> <li>Verbose Output - Detailed logging of all operations</li> </ul>"},{"location":"python/development/markemptyfolders.html#usage","title":"Usage","text":""},{"location":"python/development/markemptyfolders.html#basic-usage","title":"Basic Usage","text":"<pre><code># Mark empty folders with .gitkeep files\npython3 markemptyfolders.py /path/to/project\n\n# Use custom placeholder filename\npython3 markemptyfolders.py /path/to/project --name \"keepme.md\"\n\n# Dry run to see what would be done\npython3 markemptyfolders.py /path/to/project --dry-run\n</code></pre>"},{"location":"python/development/markemptyfolders.html#advanced-usage","title":"Advanced Usage","text":"<pre><code># Remove existing placeholders from non-empty directories\npython3 markemptyfolders.py /path/to/project --cleanup\n\n# Include hidden directories\npython3 markemptyfolders.py /path/to/project --include-hidden\n\n# Custom exclusions and verbose output\npython3 markemptyfolders.py /path/to/project \\\n    --exclude .git .svn __pycache__ \\\n    --verbose\n</code></pre>"},{"location":"python/development/markemptyfolders.html#command-line-options","title":"Command-Line Options","text":"Option Short Description Default <code>path</code> - Directory path to scan for empty folders Required <code>--name</code> <code>-n</code> Name for placeholder files <code>.gitkeep</code> <code>--content</code> <code>-c</code> Custom content for placeholder files Default explanation <code>--exclude</code> - Directory names to exclude <code>.git .svn .hg __pycache__</code> <code>--include-hidden</code> - Include hidden directories (starting with .) False <code>--cleanup</code> - Remove placeholder files from non-empty directories False <code>--dry-run</code> - Show what would be done without making changes False <code>--verbose</code> <code>-v</code> Show detailed output False"},{"location":"python/development/markemptyfolders.html#default-placeholder-content","title":"Default Placeholder Content","text":"<p>When creating placeholder files, the script uses this default content:</p> <pre><code>This is a placeholder file to keep this directory trackable with Git.\nGit doesn't track empty directories, so this file preserves the\ndirectory structure in version control.\n\nYou can safely delete this file once the directory contains other files.\n</code></pre>"},{"location":"python/development/markemptyfolders.html#exclusion-rules","title":"Exclusion Rules","text":""},{"location":"python/development/markemptyfolders.html#default-exclusions","title":"Default Exclusions","text":"<p>The script automatically excludes common system directories: - <code>.git</code> - Git repository metadata - <code>.svn</code> - Subversion metadata - <code>.hg</code> - Mercurial metadata - <code>__pycache__</code> - Python bytecode cache</p>"},{"location":"python/development/markemptyfolders.html#custom-exclusions","title":"Custom Exclusions","text":"<pre><code># Add custom exclusions\npython3 markemptyfolders.py /path/to/project \\\n    --exclude .git .svn node_modules .vscode\n</code></pre>"},{"location":"python/development/markemptyfolders.html#hidden-directory-handling","title":"Hidden Directory Handling","text":"<p>By default, hidden directories (starting with <code>.</code>) are excluded:</p> <pre><code># Include hidden directories\npython3 markemptyfolders.py /path/to/project --include-hidden\n</code></pre>"},{"location":"python/development/markemptyfolders.html#examples","title":"Examples","text":""},{"location":"python/development/markemptyfolders.html#example-1-new-project-setup","title":"Example 1: New Project Setup","text":"<pre><code># Set up Git placeholders for a new project\ncd /path/to/new/project\npython3 markemptyfolders.py . --verbose\ngit add .\ngit commit -m \"Add directory structure placeholders\"\n</code></pre>"},{"location":"python/development/markemptyfolders.html#example-2-cleanup-after-development","title":"Example 2: Cleanup After Development","text":"<pre><code># Remove unnecessary placeholders\npython3 markemptyfolders.py /path/to/project --cleanup --verbose\n</code></pre>"},{"location":"python/development/markemptyfolders.html#example-3-custom-documentation-placeholders","title":"Example 3: Custom Documentation Placeholders","text":"<pre><code># Create custom README placeholders\npython3 markemptyfolders.py /path/to/project \\\n    --name \"README.md\" \\\n    --content \"# Directory Documentation\\n\\nThis directory is reserved for future content.\"\n</code></pre>"},{"location":"python/development/markemptyfolders.html#example-4-selective-processing","title":"Example 4: Selective Processing","text":"<pre><code># Process only source directories\npython3 markemptyfolders.py /path/to/project/src \\\n    --exclude __pycache__ .pytest_cache \\\n    --name \".keep\" \\\n    --dry-run\n</code></pre>"},{"location":"python/development/markemptyfolders.html#cleanup-mode","title":"Cleanup Mode","text":"<p>The cleanup mode removes placeholder files from directories that are no longer empty:</p> <pre><code>python3 markemptyfolders.py /path/to/project --cleanup\n</code></pre>"},{"location":"python/development/markemptyfolders.html#cleanup-logic","title":"Cleanup Logic","text":"<ol> <li>Find Placeholders - Locates all files matching the placeholder name</li> <li>Check Directory - Counts other files in the same directory</li> <li>Remove if Populated - Deletes placeholder if directory has other files</li> <li>Preserve if Empty - Keeps placeholder in still-empty directories</li> </ol>"},{"location":"python/development/markemptyfolders.html#cleanup-output","title":"Cleanup Output","text":"<pre><code>Cleaning up placeholder files named '.gitkeep'\nRemoved: /project/src/utils/.gitkeep (directory now has 3 other files)\nRemoved: /project/docs/api/.gitkeep (directory now has 1 other files)\nRemoved 2 placeholder files from non-empty directories\n</code></pre>"},{"location":"python/development/markemptyfolders.html#integration","title":"Integration","text":""},{"location":"python/development/markemptyfolders.html#git-workflow","title":"Git Workflow","text":"<pre><code>#!/bin/bash\n# Git pre-commit hook for directory structure\n\necho \"Checking for empty directories...\"\npython3 /tools/markemptyfolders.py . --dry-run\n\nif [ $? -eq 0 ]; then\n    echo \"Directory structure preserved\"\nelse\n    echo \"Adding placeholder files...\"\n    python3 /tools/markemptyfolders.py . --verbose\n    git add .gitkeep\nfi\n</code></pre>"},{"location":"python/development/markemptyfolders.html#build-scripts","title":"Build Scripts","text":"<pre><code>#!/bin/bash\n# Project initialization script\n\necho \"Setting up project structure...\"\n\n# Create initial directories\nmkdir -p {src,tests,docs,config}/{api,utils,models}\n\n# Add Git placeholders\npython3 markemptyfolders.py . --verbose\n\n# Initialize Git repository\ngit init\ngit add .\ngit commit -m \"Initial project structure\"\n</code></pre>"},{"location":"python/development/markemptyfolders.html#cicd-integration","title":"CI/CD Integration","text":"<pre><code># GitHub Actions workflow\nname: Check Directory Structure\non: [push, pull_request]\n\njobs:\n  check-structure:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: Check for empty directories\n      run: |\n        python3 markemptyfolders.py . --dry-run\n        if [ $? -ne 0 ]; then\n          echo \"Empty directories found without placeholders\"\n          exit 1\n        fi\n</code></pre>"},{"location":"python/development/markemptyfolders.html#directory-structure-analysis","title":"Directory Structure Analysis","text":""},{"location":"python/development/markemptyfolders.html#before-processing","title":"Before Processing","text":"<pre><code>project/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 api/          # Empty\n\u2502   \u251c\u2500\u2500 models/       # Empty\n\u2502   \u2514\u2500\u2500 utils/\n\u2502       \u2514\u2500\u2500 helpers.py\n\u251c\u2500\u2500 tests/            # Empty\n\u251c\u2500\u2500 docs/\n\u2502   \u2514\u2500\u2500 README.md\n\u2514\u2500\u2500 config/           # Empty\n</code></pre>"},{"location":"python/development/markemptyfolders.html#after-processing","title":"After Processing","text":"<pre><code>project/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 api/\n\u2502   \u2502   \u2514\u2500\u2500 .gitkeep  # Added\n\u2502   \u251c\u2500\u2500 models/\n\u2502   \u2502   \u2514\u2500\u2500 .gitkeep  # Added\n\u2502   \u2514\u2500\u2500 utils/\n\u2502       \u2514\u2500\u2500 helpers.py\n\u251c\u2500\u2500 tests/\n\u2502   \u2514\u2500\u2500 .gitkeep      # Added\n\u251c\u2500\u2500 docs/\n\u2502   \u2514\u2500\u2500 README.md\n\u2514\u2500\u2500 config/\n    \u2514\u2500\u2500 .gitkeep      # Added\n</code></pre>"},{"location":"python/development/markemptyfolders.html#performance-considerations","title":"Performance Considerations","text":""},{"location":"python/development/markemptyfolders.html#large-repositories","title":"Large Repositories","text":"<ul> <li>Efficient Scanning - Uses <code>pathlib.rglob()</code> for fast directory traversal</li> <li>Memory Efficient - Processes directories one at a time</li> <li>I/O Optimized - Minimal file system operations</li> </ul>"},{"location":"python/development/markemptyfolders.html#network-filesystems","title":"Network Filesystems","text":"<ul> <li>Batch Operations - Groups file operations when possible</li> <li>Error Handling - Graceful handling of permission issues</li> <li>Timeout Resistance - Continues processing if individual operations fail</li> </ul>"},{"location":"python/development/markemptyfolders.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"python/development/markemptyfolders.html#common-issues","title":"Common Issues","text":"<p>Issue: Permission denied errors <pre><code>Solution: Ensure write permissions to target directories:\nchmod -R u+w /path/to/project\n</code></pre></p> <p>Issue: Placeholders not being created <pre><code>Solution: Check exclusion rules and directory permissions:\npython3 markemptyfolders.py /path/to/project --verbose --dry-run\n</code></pre></p> <p>Issue: Too many placeholder files created <pre><code>Solution: Use exclusion rules to skip unwanted directories:\npython3 markemptyfolders.py /path/to/project \\\n    --exclude .git .svn node_modules .vscode __pycache__\n</code></pre></p>"},{"location":"python/development/markemptyfolders.html#debugging","title":"Debugging","text":"<p>Use verbose and dry-run modes together for detailed analysis:</p> <pre><code>python3 markemptyfolders.py /path/to/project --verbose --dry-run\n</code></pre> <p>This shows: - Directories being scanned - Exclusion rule applications - Files that would be created - Any errors or issues encountered</p>"},{"location":"python/development/markemptyfolders.html#best-practices","title":"Best Practices","text":""},{"location":"python/development/markemptyfolders.html#repository-setup","title":"Repository Setup","text":"<ol> <li>Run Early - Execute during initial project setup</li> <li>Include in Documentation - Document placeholder strategy in README</li> <li>Automate - Include in project initialization scripts</li> <li>Regular Cleanup - Periodically remove unnecessary placeholders</li> </ol>"},{"location":"python/development/markemptyfolders.html#placeholder-management","title":"Placeholder Management","text":"<ol> <li>Consistent Naming - Use standard names like <code>.gitkeep</code> or <code>.keep</code></li> <li>Descriptive Content - Include helpful explanations in placeholder files</li> <li>Version Control - Commit placeholders with meaningful messages</li> <li>Team Communication - Ensure team understands placeholder purpose</li> </ol>"},{"location":"python/development/markemptyfolders.html#automation","title":"Automation","text":"<ol> <li>Pre-commit Hooks - Automatically check for empty directories</li> <li>CI/CD Integration - Validate directory structure in pipelines</li> <li>Build Scripts - Include in project setup automation</li> <li>Documentation - Keep usage examples in project docs</li> </ol> <p>markemptyfolders.py provides comprehensive directory structure preservation for Git repositories with flexible configuration and cleanup capabilities.</p>"},{"location":"python/development/timer.html","title":"timer.py","text":"<p>Comprehensive timing utilities for debugging, performance measurement, interactive stopwatch functionality, and command benchmarking.</p>"},{"location":"python/development/timer.html#overview","title":"Overview","text":"<p>timer.py provides both library functions for programmatic timing and a full CLI application for interactive timing operations. It includes stopwatch functionality, command execution timing, countdown timers, and performance benchmarking tools.</p>"},{"location":"python/development/timer.html#features","title":"Features","text":"<ul> <li>Library Functions - Import and use timing functions in your scripts</li> <li>Interactive Stopwatch - Full-featured CLI stopwatch with lap times</li> <li>Command Timing - Benchmark command execution with statistics</li> <li>Countdown Timer - Visual countdown with cancellation support</li> <li>Performance Analysis - Statistical analysis of multiple runs</li> <li>Human-Readable Output - Automatic formatting of time durations</li> </ul>"},{"location":"python/development/timer.html#usage","title":"Usage","text":""},{"location":"python/development/timer.html#library-usage","title":"Library Usage","text":"<pre><code>from timer import timer, secondsToHoursMinutesSeconds, Stopwatch\n\n# Basic timing\nstart = timer()\n# ... do some work ...\ntimer(start, \"Operation completed\")\n\n# Advanced stopwatch\nsw = Stopwatch(\"Database Query\")\nsw.start()\n# ... perform query ...\nsw.lap(\"Connection established\")\n# ... process results ...\nsw.stop()\n</code></pre>"},{"location":"python/development/timer.html#cli-usage","title":"CLI Usage","text":"<pre><code># Interactive stopwatch\npython3 timer.py --interactive\n\n# Time a command execution\npython3 timer.py --command \"ls -la\"\n\n# Time with multiple iterations\npython3 timer.py --command \"python script.py\" --iterations 5\n\n# Countdown timer\npython3 timer.py --countdown 300\n</code></pre>"},{"location":"python/development/timer.html#command-line-options","title":"Command-Line Options","text":"Option Short Description Default <code>--interactive</code> <code>-i</code> Run interactive stopwatch mode False <code>--command</code> <code>-c</code> Command to time (e.g., 'ls -la') None <code>--iterations</code> <code>-n</code> Number of iterations for command timing 1 <code>--countdown</code> <code>-t</code> Countdown timer in seconds None <code>--name</code> - Name for the timer <code>Timer</code>"},{"location":"python/development/timer.html#library-functions","title":"Library Functions","text":""},{"location":"python/development/timer.html#timerelapsed00-name","title":"timer(elapsed=0.0, name='')","text":"<p>Basic timing function for simple operations:</p> <pre><code># Start timing\nstart_time = timer()\n\n# End timing with label\nelapsed = timer(start_time, \"Processing completed\")\n</code></pre> <p>Parameters: - <code>elapsed</code> - Start time from previous call (0.0 to start) - <code>name</code> - Optional name for the timer operation</p> <p>Returns: Current timestamp for subsequent calls</p>"},{"location":"python/development/timer.html#secondstohoursminutessecondsseconds","title":"secondsToHoursMinutesSeconds(seconds)","text":"<p>Convert seconds to human-readable format:</p> <pre><code># Convert duration to readable format\nreadable = secondsToHoursMinutesSeconds(3725.5)\n# Returns: \"1 hours 2 minutes 5.50 seconds\"\n</code></pre>"},{"location":"python/development/timer.html#stopwatch-class","title":"Stopwatch Class","text":"<p>Advanced timing with lap functionality:</p> <pre><code># Create named stopwatch\nstopwatch = Stopwatch(\"Performance Test\")\n\n# Control operations\nstopwatch.start()\nstopwatch.lap(\"Checkpoint 1\")\nstopwatch.lap(\"Checkpoint 2\")\ntotal_time = stopwatch.stop()\n\n# Status checking\nstopwatch.status()\nstopwatch.reset()\n</code></pre>"},{"location":"python/development/timer.html#interactive-stopwatch-mode","title":"Interactive Stopwatch Mode","text":""},{"location":"python/development/timer.html#commands","title":"Commands","text":"<ul> <li><code>start</code> - Start the timer</li> <li><code>lap</code> - Record a lap time</li> <li><code>stop</code> - Stop the timer</li> <li><code>reset</code> - Reset the timer</li> <li><code>status</code> - Show current status</li> <li><code>quit</code> - Exit the application</li> </ul>"},{"location":"python/development/timer.html#example-session","title":"Example Session","text":"<pre><code>Interactive Stopwatch: Performance Test\nCommands: start, lap, stop, reset, status, quit\n\ntimer&gt; start\nPerformance Test: Started\n\ntimer&gt; lap\nPerformance Test: Lap 1 - 12.34 seconds\n\ntimer&gt; lap\nPerformance Test: Lap 2 - 8.76 seconds\n\ntimer&gt; stop\nPerformance Test: Stopped\nPerformance Test: Total time - 21.10 seconds\n</code></pre>"},{"location":"python/development/timer.html#command-timing","title":"Command Timing","text":""},{"location":"python/development/timer.html#single-execution","title":"Single Execution","text":"<pre><code>python3 timer.py --command \"python script.py\"\n</code></pre> <p>Output: <pre><code>Timing command: python script.py\nExecution time: 2 minutes 15.30 seconds\n</code></pre></p>"},{"location":"python/development/timer.html#multiple-iterations","title":"Multiple Iterations","text":"<pre><code>python3 timer.py --command \"python script.py\" --iterations 5\n</code></pre> <p>Output: <pre><code>Timing command: python script.py\nRunning 5 iterations...\nIteration 1: 2 minutes 15.30 seconds\nIteration 2: 2 minutes 12.85 seconds\nIteration 3: 2 minutes 14.10 seconds\nIteration 4: 2 minutes 13.45 seconds\nIteration 5: 2 minutes 16.20 seconds\n\nResults for 5 iterations:\n  Average: 2 minutes 14.38 seconds\n  Minimum: 2 minutes 12.85 seconds\n  Maximum: 2 minutes 16.20 seconds\n</code></pre></p>"},{"location":"python/development/timer.html#countdown-timer","title":"Countdown Timer","text":""},{"location":"python/development/timer.html#basic-countdown","title":"Basic Countdown","text":"<pre><code>python3 timer.py --countdown 300\n</code></pre> <p>Output: <pre><code>Countdown: 300 seconds\n300 seconds remaining...\n299 seconds remaining...\n...\n  1 seconds remaining...\n  0 seconds remaining... Time's up!\n</code></pre></p>"},{"location":"python/development/timer.html#cancellation","title":"Cancellation","text":"<p>Press <code>Ctrl+C</code> to cancel countdown: <pre><code>Countdown cancelled.\n</code></pre></p>"},{"location":"python/development/timer.html#examples","title":"Examples","text":""},{"location":"python/development/timer.html#example-1-script-performance-analysis","title":"Example 1: Script Performance Analysis","text":"<pre><code>#!/usr/bin/env python3\nfrom timer import Stopwatch\n\ndef analyze_performance():\n    sw = Stopwatch(\"Data Processing\")\n    sw.start()\n\n    # Load data\n    load_data()\n    sw.lap(\"Data loaded\")\n\n    # Process data\n    process_data()\n    sw.lap(\"Data processed\")\n\n    # Save results\n    save_results()\n    sw.stop()\n\nif __name__ == \"__main__\":\n    analyze_performance()\n</code></pre>"},{"location":"python/development/timer.html#example-2-database-benchmark","title":"Example 2: Database Benchmark","text":"<pre><code># Time database operations\npython3 timer.py --command \"psql -c 'SELECT COUNT(*) FROM large_table;'\" --iterations 10\n</code></pre>"},{"location":"python/development/timer.html#example-3-build-time-monitoring","title":"Example 3: Build Time Monitoring","text":"<pre><code>import subprocess\nfrom timer import timer\n\ndef time_build():\n    start = timer()\n\n    # Run build\n    result = subprocess.run(['make', 'all'], check=True)\n\n    timer(start, \"Build completed\")\n    return result.returncode == 0\n</code></pre>"},{"location":"python/development/timer.html#example-4-automated-testing","title":"Example 4: Automated Testing","text":"<pre><code>#!/bin/bash\necho \"Running test suite with timing...\"\n\npython3 timer.py --command \"pytest tests/\" --name \"Test Suite\"\npython3 timer.py --command \"flake8 src/\" --name \"Linting\"\npython3 timer.py --command \"mypy src/\" --name \"Type Checking\"\n</code></pre>"},{"location":"python/development/timer.html#integration","title":"Integration","text":""},{"location":"python/development/timer.html#cicd-pipeline","title":"CI/CD Pipeline","text":"<pre><code># GitHub Actions example\n- name: Run timed tests\n  run: |\n    python3 timer.py --command \"pytest tests/\" --iterations 3\n</code></pre>"},{"location":"python/development/timer.html#development-workflow","title":"Development Workflow","text":"<pre><code># Development timing decorator\nfrom functools import wraps\nfrom timer import timer\n\ndef timed(name):\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            start = timer()\n            result = func(*args, **kwargs)\n            timer(start, f\"{name} - {func.__name__}\")\n            return result\n        return wrapper\n    return decorator\n\n@timed(\"Database Operation\")\ndef fetch_user_data(user_id):\n    # Implementation here\n    pass\n</code></pre>"},{"location":"python/development/timer.html#performance-monitoring","title":"Performance Monitoring","text":"<pre><code>#!/usr/bin/env python3\nimport sys\nfrom timer import Stopwatch\n\nclass PerformanceMonitor:\n    def __init__(self):\n        self.stopwatch = Stopwatch(\"System Monitor\")\n\n    def monitor_system(self):\n        self.stopwatch.start()\n\n        # Check system resources\n        self.check_cpu()\n        self.stopwatch.lap(\"CPU check\")\n\n        # Check memory\n        self.check_memory()\n        self.stopwatch.lap(\"Memory check\")\n\n        # Check disk\n        self.check_disk()\n        self.stopwatch.lap(\"Disk check\")\n\n        self.stopwatch.stop()\n\nif __name__ == \"__main__\":\n    monitor = PerformanceMonitor()\n    monitor.monitor_system()\n</code></pre>"},{"location":"python/development/timer.html#error-handling","title":"Error Handling","text":""},{"location":"python/development/timer.html#common-errors","title":"Common Errors","text":"<ul> <li>Command not found - Clear error message for invalid commands</li> <li>Permission denied - Handles execution permission issues</li> <li>Keyboard interruption - Graceful handling of Ctrl+C</li> <li>Invalid arguments - Validation of numeric inputs</li> </ul>"},{"location":"python/development/timer.html#exception-handling","title":"Exception Handling","text":"<pre><code>from timer import Stopwatch, timer\n\ntry:\n    sw = Stopwatch(\"Critical Operation\")\n    sw.start()\n    # ... risky operation ...\n    sw.stop()\nexcept KeyboardInterrupt:\n    print(\"Operation cancelled by user\")\nexcept Exception as e:\n    print(f\"Operation failed: {e}\")\nfinally:\n    # Cleanup if needed\n    pass\n</code></pre>"},{"location":"python/development/timer.html#dependencies","title":"Dependencies","text":""},{"location":"python/development/timer.html#required","title":"Required","text":"<ul> <li>Python 3.11+</li> <li>Standard library modules only</li> </ul>"},{"location":"python/development/timer.html#no-external-dependencies","title":"No External Dependencies","text":"<ul> <li>Uses only built-in modules</li> <li>No additional packages required</li> <li>Works in minimal Python environments</li> </ul>"},{"location":"python/development/timer.html#advanced-features","title":"Advanced Features","text":""},{"location":"python/development/timer.html#lap-time-analysis","title":"Lap Time Analysis","text":"<pre><code>sw = Stopwatch(\"Complex Operation\")\nsw.start()\n\nfor i in range(10):\n    # Process batch\n    process_batch(i)\n    sw.lap(f\"Batch {i+1}\")\n\n# All lap times are stored and can be analyzed\ntotal_time = sw.stop()\n</code></pre>"},{"location":"python/development/timer.html#statistical-analysis","title":"Statistical Analysis","text":"<p>The command timing feature provides: - Average execution time across multiple runs - Minimum and maximum execution times - Standard deviation calculations (when running many iterations) - Performance consistency analysis</p> <p>timer.py provides comprehensive timing utilities for development, debugging, and performance analysis with both library and CLI interfaces.</p>"},{"location":"python/lib/applescript.html","title":"applescript.py","text":"<p>Modern macOS AppleScript integration with comprehensive error handling, timeout support, and convenient utility functions for automating macOS applications.</p>"},{"location":"python/lib/applescript.html#overview","title":"Overview","text":"<p>applescript.py provides a secure, modern interface for executing AppleScript code from Python on macOS. It includes proper error handling, timeout support, string escaping utilities, and convenient functions for common macOS automation tasks.</p>"},{"location":"python/lib/applescript.html#features","title":"Features","text":"<ul> <li>Secure Execution - No shell injection vulnerabilities with proper subprocess handling</li> <li>Timeout Support - Configurable timeouts to prevent hanging operations</li> <li>Error Handling - Comprehensive error reporting and exception management</li> <li>String Escaping - Automatic handling of quotes and special characters</li> <li>Utility Functions - Pre-built functions for common automation tasks</li> <li>Cross-Platform Detection - Graceful handling on non-macOS systems</li> <li>Legacy Compatibility - Backward compatibility with existing code</li> </ul>"},{"location":"python/lib/applescript.html#core-functions","title":"Core Functions","text":""},{"location":"python/lib/applescript.html#run_applescriptscript-timeoutnone","title":"run_applescript(script, timeout=None)","text":"<p>Execute AppleScript code and return the output.</p> <p>Parameters: - <code>script</code> (str): AppleScript code to execute - <code>timeout</code> (float, optional): Maximum execution time in seconds</p> <p>Returns: - <code>str</code>: Standard output from AppleScript</p> <p>Raises: - <code>AppleScriptError</code>: If script execution fails - <code>OSError</code>: If osascript is not available - <code>TimeoutExpired</code>: If script execution times out</p> <p>Example: <pre><code>from applescript import run_applescript\n\n# Simple AppleScript execution\nresult = run_applescript('return \"Hello from AppleScript!\"')\nprint(result)  # Output: Hello from AppleScript!\n\n# With timeout\ntry:\n    result = run_applescript('''\n        tell application \"Finder\"\n            return name of startup disk\n        end tell\n    ''', timeout=5.0)\n    print(f\"Startup disk: {result}\")\nexcept AppleScriptError as e:\n    print(f\"Script failed: {e}\")\n</code></pre></p>"},{"location":"python/lib/applescript.html#quote_stringtext","title":"quote_string(text)","text":"<p>Properly escape strings for use in AppleScript.</p> <p>Parameters: - <code>text</code> (str): Text to escape for AppleScript</p> <p>Returns: - <code>str</code>: Properly quoted string for AppleScript use</p> <p>Example: <pre><code>from applescript import quote_string, run_applescript\n\n# Handle strings with quotes\nmessage = 'Hello \"World\" from Python!'\nquoted = quote_string(message)\n\nscript = f'''\ntell application \"Finder\"\n    display dialog {quoted}\nend tell\n'''\n\nrun_applescript(script)\n</code></pre></p>"},{"location":"python/lib/applescript.html#utility-functions","title":"Utility Functions","text":""},{"location":"python/lib/applescript.html#get_app_infoapp_name","title":"get_app_info(app_name)","text":"<p>Get information about a running macOS application.</p> <p>Parameters: - <code>app_name</code> (str): Name of the application</p> <p>Returns: - <code>dict</code>: Application information with keys:   - <code>running</code> (bool): Whether app is running   - <code>visible</code> (bool): Whether app is visible (if running)   - <code>frontmost</code> (bool): Whether app is frontmost (if running)</p> <p>Example: <pre><code>from applescript import get_app_info\n\n# Check if Finder is running and visible\nfinder_info = get_app_info(\"Finder\")\nif finder_info['running']:\n    print(f\"Finder is running, visible: {finder_info['visible']}\")\nelse:\n    print(\"Finder is not running\")\n</code></pre></p>"},{"location":"python/lib/applescript.html#display_notificationtitle-subtitle-message-sound_namenone","title":"display_notification(title, subtitle=\"\", message=\"\", sound_name=None)","text":"<p>Display a macOS notification.</p> <p>Parameters: - <code>title</code> (str): Notification title - <code>subtitle</code> (str, optional): Notification subtitle - <code>message</code> (str, optional): Notification message - <code>sound_name</code> (str, optional): Sound to play</p> <p>Example: <pre><code>from applescript import display_notification\n\n# Simple notification\ndisplay_notification(\"Process Complete\", message=\"All files have been processed\")\n\n# Notification with sound\ndisplay_notification(\n    \"Backup Finished\",\n    subtitle=\"Daily Backup\", \n    message=\"All files backed up successfully\",\n    sound_name=\"Glass\"\n)\n</code></pre></p>"},{"location":"python/lib/applescript.html#advanced-usage-examples","title":"Advanced Usage Examples","text":""},{"location":"python/lib/applescript.html#application-control","title":"Application Control","text":"<pre><code>from applescript import run_applescript, quote_string\n\ndef control_music_app(action, track_name=None):\n    \"\"\"Control macOS Music app.\"\"\"\n\n    if action == \"play\":\n        script = '''\n        tell application \"Music\"\n            play\n        end tell\n        '''\n\n    elif action == \"pause\":\n        script = '''\n        tell application \"Music\"\n            pause\n        end tell\n        '''\n\n    elif action == \"play_track\" and track_name:\n        quoted_track = quote_string(track_name)\n        script = f'''\n        tell application \"Music\"\n            play track {quoted_track}\n        end tell\n        '''\n\n    elif action == \"get_current\":\n        script = '''\n        tell application \"Music\"\n            if player state is playing then\n                return name of current track &amp; \" by \" &amp; artist of current track\n            else\n                return \"Not playing\"\n            end if\n        end tell\n        '''\n\n    try:\n        result = run_applescript(script, timeout=10)\n        return result\n    except Exception as e:\n        print(f\"Music control failed: {e}\")\n        return None\n\n# Usage examples\ncontrol_music_app(\"play\")\ncurrent_track = control_music_app(\"get_current\")\nprint(f\"Now playing: {current_track}\")\n</code></pre>"},{"location":"python/lib/applescript.html#file-system-operations","title":"File System Operations","text":"<pre><code>from applescript import run_applescript, quote_string\nimport os\n\ndef finder_operations(operation, path=None, target_path=None):\n    \"\"\"Perform Finder operations via AppleScript.\"\"\"\n\n    if operation == \"reveal\":\n        # Reveal file in Finder\n        if not os.path.exists(path):\n            raise ValueError(f\"Path does not exist: {path}\")\n\n        quoted_path = quote_string(path)\n        script = f'''\n        tell application \"Finder\"\n            reveal POSIX file {quoted_path}\n            activate\n        end tell\n        '''\n\n    elif operation == \"move_to_trash\":\n        # Move file to trash\n        quoted_path = quote_string(path)\n        script = f'''\n        tell application \"Finder\"\n            move POSIX file {quoted_path} to trash\n        end tell\n        '''\n\n    elif operation == \"get_selection\":\n        # Get currently selected files in Finder\n        script = '''\n        tell application \"Finder\"\n            set selected_items to selection\n            set file_paths to {}\n            repeat with item_ref in selected_items\n                set end of file_paths to POSIX path of (item_ref as alias)\n            end repeat\n            return file_paths as string\n        end tell\n        '''\n\n    elif operation == \"new_folder\":\n        # Create new folder\n        quoted_path = quote_string(path)\n        folder_name = quote_string(os.path.basename(target_path))\n        script = f'''\n        tell application \"Finder\"\n            make new folder at POSIX file {quoted_path} with properties {{name:{folder_name}}}\n        end tell\n        '''\n\n    try:\n        result = run_applescript(script, timeout=15)\n        return result\n    except Exception as e:\n        print(f\"Finder operation failed: {e}\")\n        return None\n\n# Usage examples\nfinder_operations(\"reveal\", \"/Users/alex/Documents/important.pdf\")\nselected_files = finder_operations(\"get_selection\")\nfinder_operations(\"new_folder\", \"/Users/alex/Desktop\", \"New Project\")\n</code></pre>"},{"location":"python/lib/applescript.html#email-automation","title":"Email Automation","text":"<pre><code>from applescript import run_applescript, quote_string\n\nclass MailAutomation:\n    \"\"\"Automate Apple Mail using AppleScript.\"\"\"\n\n    def __init__(self):\n        self.timeout = 30  # Email operations can be slow\n\n    def send_email(self, to_address, subject, body, attachments=None):\n        \"\"\"Send email via Apple Mail.\"\"\"\n\n        quoted_to = quote_string(to_address)\n        quoted_subject = quote_string(subject)\n        quoted_body = quote_string(body)\n\n        script = f'''\n        tell application \"Mail\"\n            set new_message to make new outgoing message with properties {{\n                subject: {quoted_subject},\n                content: {quoted_body},\n                visible: true\n            }}\n\n            tell new_message\n                make new to recipient at end of to recipients with properties {{\n                    address: {quoted_to}\n                }}\n        '''\n\n        # Add attachments if provided\n        if attachments:\n            for attachment_path in attachments:\n                if os.path.exists(attachment_path):\n                    quoted_attachment = quote_string(attachment_path)\n                    script += f'''\n                make new attachment with properties {{\n                    file name: POSIX file {quoted_attachment}\n                }} at after the last paragraph\n                    '''\n\n        script += '''\n            end tell\n\n            send new_message\n        end tell\n        '''\n\n        try:\n            run_applescript(script, timeout=self.timeout)\n            return True\n        except Exception as e:\n            print(f\"Email sending failed: {e}\")\n            return False\n\n    def get_unread_count(self):\n        \"\"\"Get count of unread emails.\"\"\"\n        script = '''\n        tell application \"Mail\"\n            return unread count of inbox\n        end tell\n        '''\n\n        try:\n            result = run_applescript(script, timeout=10)\n            return int(result)\n        except Exception as e:\n            print(f\"Failed to get unread count: {e}\")\n            return 0\n\n    def mark_as_read(self, message_count=1):\n        \"\"\"Mark recent messages as read.\"\"\"\n        script = f'''\n        tell application \"Mail\"\n            set recent_messages to messages 1 thru {message_count} of inbox\n            repeat with msg in recent_messages\n                set read status of msg to true\n            end repeat\n        end tell\n        '''\n\n        try:\n            run_applescript(script, timeout=15)\n            return True\n        except Exception as e:\n            print(f\"Failed to mark as read: {e}\")\n            return False\n\n# Usage\nmail = MailAutomation()\n\n# Send automated report\nmail.send_email(\n    \"manager@company.com\",\n    \"Daily Report - \" + datetime.now().strftime(\"%Y-%m-%d\"),\n    \"Please find today's report attached.\",\n    attachments=[\"/path/to/report.pdf\"]\n)\n\n# Check for new emails\nunread = mail.get_unread_count()\nprint(f\"You have {unread} unread emails\")\n</code></pre>"},{"location":"python/lib/applescript.html#system-information-gathering","title":"System Information Gathering","text":"<pre><code>from applescript import run_applescript\n\ndef get_system_info():\n    \"\"\"Gather system information via AppleScript.\"\"\"\n\n    scripts = {\n        'computer_name': '''\n        tell application \"System Events\"\n            return computer name of local domain\n        end tell\n        ''',\n\n        'current_user': '''\n        tell application \"System Events\"\n            return name of current user\n        end tell\n        ''',\n\n        'screen_resolution': '''\n        tell application \"Finder\"\n            return bounds of window of desktop\n        end tell\n        ''',\n\n        'running_applications': '''\n        tell application \"System Events\"\n            return name of every application process whose visible is true\n        end tell\n        ''',\n\n        'system_version': '''\n        tell application \"System Events\"\n            return system version\n        end tell\n        ''',\n\n        'free_disk_space': '''\n        tell application \"Finder\"\n            return free space of startup disk\n        end tell\n        '''\n    }\n\n    system_info = {}\n\n    for key, script in scripts.items():\n        try:\n            result = run_applescript(script, timeout=10)\n            system_info[key] = result\n        except Exception as e:\n            system_info[key] = f\"Error: {e}\"\n\n    return system_info\n\n# Usage\ninfo = get_system_info()\nfor key, value in info.items():\n    print(f\"{key}: {value}\")\n</code></pre>"},{"location":"python/lib/applescript.html#error-handling-and-best-practices","title":"Error Handling and Best Practices","text":""},{"location":"python/lib/applescript.html#comprehensive-error-handling","title":"Comprehensive Error Handling","text":"<pre><code>from applescript import run_applescript, AppleScriptError, is_macos\n\ndef safe_applescript_execution(script_name, script_code, timeout=30):\n    \"\"\"Safely execute AppleScript with comprehensive error handling.\"\"\"\n\n    # Check if running on macOS\n    if not is_macos():\n        print(\"AppleScript is only available on macOS\")\n        return None\n\n    try:\n        print(f\"Executing {script_name}...\")\n        result = run_applescript(script_code, timeout=timeout)\n        print(f\"\u2713 {script_name} completed successfully\")\n        return result\n\n    except AppleScriptError as e:\n        print(f\"\u2717 AppleScript error in {script_name}: {e}\")\n        return None\n\n    except TimeoutError:\n        print(f\"\u2717 {script_name} timed out after {timeout} seconds\")\n        return None\n\n    except OSError as e:\n        print(f\"\u2717 System error in {script_name}: {e}\")\n        return None\n\n    except Exception as e:\n        print(f\"\u2717 Unexpected error in {script_name}: {e}\")\n        return None\n\n# Usage with error handling\nscript = '''\ntell application \"Terminal\"\n    do script \"echo 'Hello from Terminal'\"\nend tell\n'''\n\nresult = safe_applescript_execution(\"Terminal Hello\", script)\n</code></pre>"},{"location":"python/lib/applescript.html#retry-logic-for-flaky-operations","title":"Retry Logic for Flaky Operations","text":"<pre><code>import time\nfrom applescript import run_applescript, AppleScriptError\n\ndef retry_applescript(script, max_retries=3, delay=1.0, timeout=30):\n    \"\"\"Execute AppleScript with retry logic for flaky operations.\"\"\"\n\n    last_error = None\n\n    for attempt in range(max_retries):\n        try:\n            result = run_applescript(script, timeout=timeout)\n            if attempt &gt; 0:\n                print(f\"\u2713 Succeeded on attempt {attempt + 1}\")\n            return result\n\n        except AppleScriptError as e:\n            last_error = e\n            if attempt &lt; max_retries - 1:\n                print(f\"Attempt {attempt + 1} failed: {e}\")\n                print(f\"Retrying in {delay} seconds...\")\n                time.sleep(delay)\n            else:\n                print(f\"All {max_retries} attempts failed\")\n\n        except Exception as e:\n            # Don't retry for non-AppleScript errors\n            print(f\"Non-retryable error: {e}\")\n            raise\n\n    # If we get here, all retries failed\n    raise last_error\n\n# Usage with retry logic\nflaky_script = '''\ntell application \"SomeFlakeyApp\"\n    -- This might fail occasionally\n    perform some action\nend tell\n'''\n\ntry:\n    result = retry_applescript(flaky_script, max_retries=3, delay=2.0)\n    print(\"Operation succeeded\")\nexcept AppleScriptError as e:\n    print(f\"Operation failed after retries: {e}\")\n</code></pre>"},{"location":"python/lib/applescript.html#integration-patterns","title":"Integration Patterns","text":""},{"location":"python/lib/applescript.html#cli-tool-integration","title":"CLI Tool Integration","text":"<pre><code>import argparse\nfrom applescript import run_applescript, display_notification, is_macos\n\ndef create_notification_cli():\n    \"\"\"Command-line tool for sending macOS notifications.\"\"\"\n\n    if not is_macos():\n        print(\"This tool only works on macOS\")\n        return 1\n\n    parser = argparse.ArgumentParser(description=\"Send macOS notifications\")\n    parser.add_argument(\"title\", help=\"Notification title\")\n    parser.add_argument(\"--message\", \"-m\", help=\"Notification message\")\n    parser.add_argument(\"--subtitle\", \"-s\", help=\"Notification subtitle\") \n    parser.add_argument(\"--sound\", help=\"Notification sound\")\n\n    args = parser.parse_args()\n\n    try:\n        display_notification(\n            args.title,\n            subtitle=args.subtitle or \"\",\n            message=args.message or \"\",\n            sound_name=args.sound\n        )\n        return 0\n    except Exception as e:\n        print(f\"Failed to send notification: {e}\")\n        return 1\n\n# Usage: python notify.py \"Build Complete\" -m \"All tests passed\" -s \"Success\"\n</code></pre>"},{"location":"python/lib/applescript.html#automation-workflows","title":"Automation Workflows","text":"<pre><code>from applescript import run_applescript, display_notification\nimport time\n\nclass MacOSWorkflow:\n    \"\"\"Automation workflow for macOS tasks.\"\"\"\n\n    def __init__(self, name):\n        self.name = name\n        self.steps = []\n\n    def add_step(self, step_name, applescript_code, timeout=30):\n        \"\"\"Add a step to the workflow.\"\"\"\n        self.steps.append({\n            'name': step_name,\n            'script': applescript_code,\n            'timeout': timeout\n        })\n\n    def execute(self, show_notifications=True):\n        \"\"\"Execute the complete workflow.\"\"\"\n        start_time = time.time()\n\n        if show_notifications:\n            display_notification(f\"Starting {self.name}\", message=\"Workflow beginning...\")\n\n        for i, step in enumerate(self.steps, 1):\n            try:\n                print(f\"Step {i}/{len(self.steps)}: {step['name']}\")\n\n                result = run_applescript(step['script'], timeout=step['timeout'])\n\n                print(f\"\u2713 {step['name']} completed\")\n\n            except Exception as e:\n                error_msg = f\"Step {i} failed: {step['name']} - {e}\"\n                print(f\"\u2717 {error_msg}\")\n\n                if show_notifications:\n                    display_notification(\n                        f\"{self.name} Failed\", \n                        message=error_msg,\n                        sound_name=\"Basso\"\n                    )\n\n                return False\n\n        elapsed = time.time() - start_time\n        success_msg = f\"{self.name} completed in {elapsed:.1f} seconds\"\n        print(f\"\u2713 {success_msg}\")\n\n        if show_notifications:\n            display_notification(\n                f\"{self.name} Complete\",\n                message=success_msg,\n                sound_name=\"Glass\"\n            )\n\n        return True\n\n# Example workflow\ndef create_daily_setup_workflow():\n    \"\"\"Create a workflow for daily work setup.\"\"\"\n\n    workflow = MacOSWorkflow(\"Daily Setup\")\n\n    # Open essential applications\n    workflow.add_step(\"Open Terminal\", '''\n    tell application \"Terminal\"\n        activate\n        do script \"cd ~/Projects\"\n    end tell\n    ''')\n\n    workflow.add_step(\"Open VS Code\", '''\n    tell application \"Visual Studio Code\"\n        activate\n    end tell\n    ''')\n\n    workflow.add_step(\"Check Calendar\", '''\n    tell application \"Calendar\"\n        activate\n    end tell\n    ''')\n\n    workflow.add_step(\"Set Do Not Disturb\", '''\n    tell application \"System Events\"\n        tell process \"Control Center\"\n            click menu bar item \"Control Center\" of menu bar 1\n            delay 1\n            click button \"Do Not Disturb\" of window 1\n        end tell\n    end tell\n    ''')\n\n    return workflow\n\n# Execute workflow\ndaily_setup = create_daily_setup_workflow()\ndaily_setup.execute()\n</code></pre>"},{"location":"python/lib/applescript.html#legacy-compatibility","title":"Legacy Compatibility","text":""},{"location":"python/lib/applescript.html#backward-compatibility","title":"Backward Compatibility","text":"<pre><code># Legacy aliases for existing code\nasrun = run_applescript\nasquote = quote_string\n\n# Migration examples\ndef migrate_legacy_code():\n    \"\"\"Examples of migrating from legacy to new API.\"\"\"\n\n    # Old way (still works)\n    result = asrun('return \"Hello\"')\n    quoted = asquote(\"Text with \\\"quotes\\\"\")\n\n    # New way (recommended)\n    result = run_applescript('return \"Hello\"', timeout=10)\n    quoted = quote_string(\"Text with \\\"quotes\\\"\")\n\n    return result, quoted\n</code></pre> <p>applescript.py provides modern, secure AppleScript integration for macOS automation with comprehensive error handling, timeout support, and convenient utility functions for common automation tasks.</p> <p>Based on:</p> <p>http://www.leancrew.com/all-this/2013/03/combining-python-and-applescript/</p> <p>Combining Python and AppleScript</p> <p>March 6, 2013 at 10:34 PM by Dr. Drang</p> <p>You may remember this post from last June, in which I had to rewrite a script that printed out the current iTunes track. The original script was written in Python and used Hamish Sanderson\u2019s appscript library; the replacement was written in AppleScript.</p> <p>I had to do the rewrite because an update to iTunes had broken the way appscript gets at an application\u2019s AppleScript dictionary. Hamish had stopped developing appscript because Apple had deprecated the Carbon libraries he used to develop it and hadn\u2019t replaced them with Cocoa equivalents.</p> <p>That post generated many thousands of words of commentary, most of it by Hamish and most of the rest by Matt Neuburg. Although Matt came up with a clever workaround to Ruby-appscript\u2019s access to application dictionaries, and I thought seriously about mimicking his work for Python-appscript, eventually I decided that I should just abandon appscript. Because Apple has no proprietary interest in appscript, it will almost certainly continue to make changes that undermine it.</p> <p>Ferreting out all my appscript-using programs and changing them into pure AppleScript or some Python/AppleScript hybrid wasn\u2019t appealing, so I decided to just wait until a script broke before rewriting it. Recently, my script for automatically generating invoice emails broke, and I rewrote it into a combination of two AppleScripts and one Python script. It worked, but I wasn\u2019t happy with the results\u2014it seemed both kludgy and fragile. What I needed was a more general way to run AppleScript code from within my Python scripts.</p> <p>I\u2019ve touched on this topic before. Back then, I thought Kenneth Reitz\u2019s envoy module was the solution. I still like the idea of envoy, but the GitHub page has no real documentation, and Kenneth\u2019s own site seems to have been purged of most of his coding work in favor of writing, photography, and music. Besides, envoy is a bit more general-purpose than I need. Basically, I just want one or two wrapper functions around Python\u2019s subprocess module that will allow me to</p> <p>Write an AppleScript as a Python string. Run it from within my Python program. Collect any output it generates. With this, I\u2019ll be able to keep all the code in one script instead of artificially breaking it up into separate AppleScript and Python parts.</p> <p>Here\u2019s the module, applescript.py:</p> <p>1  #!/usr/bin/python  2  3  import subprocess  4  5  def asrun(ascript):  6    \"Run the given AppleScript and return the standard output and error.\"  7  8    osa = subprocess.Popen(['osascript', '-'],  9                           stdin=subprocess.PIPE, 10                           stdout=subprocess.PIPE) 11    return osa.communicate(ascript)[0] 12 13  def asquote(astr): 14    \"Return the AppleScript equivalent of the given string.\" 15 16    astr = astr.replace('\"', '\" &amp; quote &amp; \"') 17    return '\"{}\"'.format(astr)</p> <p>Without line numbers There are just two functions: asrun, which takes the AppleScript string as its only argument, runs it, and returns the output, if any; and asquote, which reconfigures any string into a string that AppleScript can parse.</p> <p>There\u2019s not much to either one of these functions, but I can think of two things worth a little explanation. You\u2019ll note that the Popen in asrun doesn\u2019t change the stderr parameter from its default value of None. That\u2019s because I wanted any AppleScript errors that arise to propagate out into the surrounding script and get handled like any other Python error\u2014shutting the program down unless it\u2019s in a try block. And instead of simply backslash-escaping double quotes in asquote, I do the more verbose thing of splitting the string at the double quotes and reconcatenating it with quotes. Doing it this way seemed more AppleScripty, but maybe that\u2019s just me. You could certainly change Line 16 to</p> <p>16    astr = astr.replace('\"', r'\\\"')</p> <p>Without line numbers if you think that\u2019s better. The double backslash is necessary to get around Python\u2019s escaping rules. The raw string gets around Python\u2019s escaping rules.</p> <p>I have applescript.py saved in /Library/Python/2.7/site-packages so it\u2019s available to all my scripts. I have a feeling I\u2019ll be changing it as I use it and find that it fails under certain conditions. So far, though, it\u2019s done what I want.</p> <p>Here\u2019s a short script using both asrun and asquote:</p> <p>1  #!/usr/bin/python  2  3  from applescript import asrun, asquote  4  5  subject = 'A new email'  6  7  body = '''This is the body of my \"email.\"  8  I hope it comes out right.  9 10  Regards, 11  Dr. Drang 12  ''' 13  ascript = ''' 14  tell application \"Mail\" 15    activate 16    make new outgoing message with properties {{visible:true, subject:{0}, content:{1}}} 17  end tell 18  '''.format(asquote(subject), asquote(body)) 19 20  print ascript 21  asrun(ascript)</p> <p>Without line numbers This does pretty much what you\u2019d expect: after printing out the AppleScript source, it runs it through osascript to create a new message in Mail with the Subject and Content fields filled. Except for the format placeholders, and the doubled braces that format requires, the AppleScript in Lines 14-17 is exactly as I\u2019d write it in the AppleScript Editor. I know Clark Goble will disagree, but I prefer this to the appscript syntax, which I found awkward because it didn\u2019t feel like real Python.</p> <p>Since Hamish Sanderson and Matt Neuburg inadvertently contributed to this post, I should recommend their AppleScript books. Hamish\u2019s is the book I reach for now when I have an AppleScript question; Matt\u2019s is more concise and has excellent sections on the structure and philosophy of AppleScript. And if you\u2019re interested in scripting Mail, this tutorial by Ben Waldie at MacTech is a great place to start and may well be where you finish.</p>"},{"location":"python/lib/copy_file.html","title":"copyFile.py","text":"<p>Advanced file copying utilities with optimized buffering, progress tracking, verification, and comprehensive error handling for high-performance file operations.</p>"},{"location":"python/lib/copy_file.html#overview","title":"Overview","text":"<p>copyFile.py provides enterprise-grade file copying capabilities that outperform standard library functions through intelligent buffer optimization, progress tracking, and comprehensive verification features. Designed for scenarios requiring reliable, high-performance file operations with detailed reporting.</p>"},{"location":"python/lib/copy_file.html#features","title":"Features","text":"<ul> <li>Optimized Performance - Intelligent buffer sizing based on file characteristics</li> <li>Progress Tracking - Real-time progress callbacks for long operations</li> <li>Verification Support - Built-in file integrity verification</li> <li>Backup Functionality - Automatic backup creation with conflict resolution</li> <li>Error Recovery - Robust error handling with cleanup on failure</li> <li>Cross-Platform - Works on Windows, macOS, and Linux</li> <li>Memory Efficient - Constant memory usage regardless of file size</li> </ul>"},{"location":"python/lib/copy_file.html#core-functions","title":"Core Functions","text":""},{"location":"python/lib/copy_file.html#copy_filesrc-dst-options","title":"copy_file(src, dst, **options)","text":"<p>Advanced file copying with comprehensive options and optimizations.</p> <p>Parameters: - <code>src</code> (str/Path): Source file path - <code>dst</code> (str/Path): Destination file path - <code>buffer_size</code> (int): Buffer size for copying (default: 10MB) - <code>preserve_file_date</code> (bool): Preserve original timestamps (default: True) - <code>create_dirs</code> (bool): Create destination directories (default: True) - <code>overwrite</code> (bool): Allow overwriting existing files (default: True) - <code>progress_callback</code> (callable): Progress reporting function</p> <p>Returns: - <code>bool</code>: True if copy was successful</p> <p>Example: <pre><code>from copyFile import copy_file\n\n# Basic usage\nsuccess = copy_file(\"/source/file.txt\", \"/dest/file.txt\")\n\n# With progress tracking\ndef show_progress(bytes_copied, total_size):\n    percent = (bytes_copied / total_size) * 100\n    print(f\"Progress: {percent:.1f}%\")\n\ncopy_file(\n    \"/large/video.mp4\", \n    \"/backup/video.mp4\",\n    progress_callback=show_progress\n)\n\n# Optimized for specific scenarios\ncopy_file(\n    \"/source/database.db\",\n    \"/backup/database.db\", \n    buffer_size=1048576,  # 1MB buffer for large files\n    preserve_file_date=True,\n    create_dirs=True\n)\n</code></pre></p>"},{"location":"python/lib/copy_file.html#advanced-functions","title":"Advanced Functions","text":""},{"location":"python/lib/copy_file.html#copy_file_with_backupsrc-dst-backup_suffixbackup-kwargs","title":"copy_file_with_backup(src, dst, backup_suffix=\".backup\", **kwargs)","text":"<p>Copy file with automatic backup of existing destination.</p> <p>Parameters: - <code>src</code> (str/Path): Source file path - <code>dst</code> (str/Path): Destination file path - <code>backup_suffix</code> (str): Suffix for backup files - <code>**kwargs</code>: Additional arguments passed to copy_file()</p> <p>Example: <pre><code>from copyFile import copy_file_with_backup\n\n# Creates backup if destination exists\ncopy_file_with_backup(\n    \"/new/config.json\",\n    \"/app/config.json\",\n    backup_suffix=\".bak\"\n)\n# If /app/config.json exists, creates /app/config.json.bak\n</code></pre></p>"},{"location":"python/lib/copy_file.html#verify_copysrc-dst-check_sizetrue-check_hashfalse","title":"verify_copy(src, dst, check_size=True, check_hash=False)","text":"<p>Verify that a file copy was successful.</p> <p>Parameters: - <code>src</code> (str/Path): Source file path - <code>dst</code> (str/Path): Destination file path - <code>check_size</code> (bool): Verify file sizes match - <code>check_hash</code> (bool): Verify content hashes match (slower)</p> <p>Returns: - <code>bool</code>: True if files match according to specified checks</p> <p>Example: <pre><code>from copyFile import copy_file, verify_copy\n\n# Copy and verify\nif copy_file(\"/important/data.db\", \"/backup/data.db\"):\n    if verify_copy(\"/important/data.db\", \"/backup/data.db\", check_hash=True):\n        print(\"Copy verified successfully\")\n    else:\n        print(\"Copy verification failed!\")\n</code></pre></p>"},{"location":"python/lib/copy_file.html#performance-optimization","title":"Performance Optimization","text":""},{"location":"python/lib/copy_file.html#buffer-size-selection","title":"Buffer Size Selection","text":"<p>The copy functions automatically optimize buffer sizes, but you can tune for specific scenarios:</p> <pre><code>from copyFile import copy_file\n\n# Small files (&lt; 1MB) - default buffer\ncopy_file(\"config.txt\", \"backup/config.txt\")\n\n# Medium files (1-100MB) - moderate buffer\ncopy_file(\n    \"document.pdf\", \n    \"backup/document.pdf\",\n    buffer_size=65536  # 64KB\n)\n\n# Large files (&gt; 100MB) - large buffer\ncopy_file(\n    \"video.mp4\",\n    \"backup/video.mp4\", \n    buffer_size=1048576  # 1MB\n)\n\n# Network storage - optimized for network latency\ncopy_file(\n    \"local_file.dat\",\n    \"/network/share/file.dat\",\n    buffer_size=2097152  # 2MB\n)\n</code></pre>"},{"location":"python/lib/copy_file.html#performance-benchmarking","title":"Performance Benchmarking","text":"<pre><code>import time\nfrom copyFile import copy_file\n\ndef benchmark_copy_performance(source_file, dest_file, buffer_sizes):\n    \"\"\"Benchmark different buffer sizes for optimal performance.\"\"\"\n    results = {}\n\n    for buffer_size in buffer_sizes:\n        # Clean up any existing destination\n        if os.path.exists(dest_file):\n            os.remove(dest_file)\n\n        start_time = time.time()\n        success = copy_file(source_file, dest_file, buffer_size=buffer_size)\n        end_time = time.time()\n\n        if success:\n            results[buffer_size] = end_time - start_time\n            print(f\"Buffer {buffer_size:8d}: {results[buffer_size]:.2f}s\")\n        else:\n            print(f\"Buffer {buffer_size:8d}: FAILED\")\n\n    return results\n\n# Test different buffer sizes\nbuffer_sizes = [8192, 32768, 65536, 262144, 1048576]\nresults = benchmark_copy_performance(\n    \"/path/to/large_file.bin\",\n    \"/tmp/test_copy.bin\", \n    buffer_sizes\n)\n\n# Find optimal buffer size\noptimal_buffer = min(results, key=results.get)\nprint(f\"Optimal buffer size: {optimal_buffer} bytes\")\n</code></pre>"},{"location":"python/lib/copy_file.html#progress-tracking","title":"Progress Tracking","text":""},{"location":"python/lib/copy_file.html#real-time-progress-display","title":"Real-Time Progress Display","text":"<pre><code>import sys\nfrom copyFile import copy_file\n\ndef progress_bar(bytes_copied, total_size, bar_length=50):\n    \"\"\"Display a progress bar in the terminal.\"\"\"\n    percent = bytes_copied / total_size\n    filled = int(bar_length * percent)\n    bar = '\u2588' * filled + '-' * (bar_length - filled)\n\n    # Clear line and show progress\n    sys.stdout.write(f'\\r[{bar}] {percent*100:.1f}% ')\n    sys.stdout.write(f'({bytes_copied:,}/{total_size:,} bytes)')\n    sys.stdout.flush()\n\n    if bytes_copied == total_size:\n        print()  # New line when complete\n\n# Usage with progress bar\ncopy_file(\n    \"/large/dataset.zip\", \n    \"/backup/dataset.zip\",\n    progress_callback=progress_bar\n)\n</code></pre>"},{"location":"python/lib/copy_file.html#detailed-progress-logging","title":"Detailed Progress Logging","text":"<pre><code>import logging\nfrom datetime import datetime\nfrom copyFile import copy_file\n\ndef detailed_progress_logger(bytes_copied, total_size):\n    \"\"\"Log detailed progress information.\"\"\"\n    percent = (bytes_copied / total_size) * 100\n    mb_copied = bytes_copied / (1024 * 1024)\n    mb_total = total_size / (1024 * 1024)\n\n    logging.info(\n        f\"Copy progress: {percent:.1f}% \"\n        f\"({mb_copied:.1f}/{mb_total:.1f} MB) \"\n        f\"at {datetime.now().strftime('%H:%M:%S')}\"\n    )\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n\n# Copy with detailed logging\ncopy_file(\n    \"/source/large_file.bin\",\n    \"/dest/large_file.bin\",\n    progress_callback=detailed_progress_logger\n)\n</code></pre>"},{"location":"python/lib/copy_file.html#integration-examples","title":"Integration Examples","text":""},{"location":"python/lib/copy_file.html#backup-system-integration","title":"Backup System Integration","text":"<pre><code>import os\nimport shutil\nfrom pathlib import Path\nfrom copyFile import copy_file_with_backup, verify_copy\n\nclass BackupManager:\n    def __init__(self, source_dir, backup_dir):\n        self.source_dir = Path(source_dir)\n        self.backup_dir = Path(backup_dir)\n        self.backup_dir.mkdir(parents=True, exist_ok=True)\n\n    def backup_file(self, relative_path):\n        \"\"\"Backup a single file with verification.\"\"\"\n        source_file = self.source_dir / relative_path\n        backup_file = self.backup_dir / relative_path\n\n        # Create backup directory structure\n        backup_file.parent.mkdir(parents=True, exist_ok=True)\n\n        # Copy with automatic backup of existing\n        success = copy_file_with_backup(\n            str(source_file),\n            str(backup_file),\n            backup_suffix=\".old\"\n        )\n\n        if success:\n            # Verify the copy\n            if verify_copy(str(source_file), str(backup_file), check_hash=True):\n                return True\n            else:\n                print(f\"Verification failed for {relative_path}\")\n                return False\n        else:\n            print(f\"Copy failed for {relative_path}\")\n            return False\n\n    def backup_directory(self, extensions=None):\n        \"\"\"Backup entire directory with optional file filtering.\"\"\"\n        success_count = 0\n        failure_count = 0\n\n        for file_path in self.source_dir.rglob('*'):\n            if file_path.is_file():\n                # Filter by extensions if specified\n                if extensions and file_path.suffix.lower() not in extensions:\n                    continue\n\n                relative_path = file_path.relative_to(self.source_dir)\n\n                if self.backup_file(relative_path):\n                    success_count += 1\n                    print(f\"\u2713 Backed up: {relative_path}\")\n                else:\n                    failure_count += 1\n                    print(f\"\u2717 Failed: {relative_path}\")\n\n        print(f\"\\nBackup complete: {success_count} successful, {failure_count} failed\")\n        return failure_count == 0\n\n# Usage\nbackup_mgr = BackupManager(\"/important/documents\", \"/backup/documents\")\nbackup_mgr.backup_directory(extensions=['.pdf', '.docx', '.xlsx'])\n</code></pre>"},{"location":"python/lib/copy_file.html#media-processing-pipeline","title":"Media Processing Pipeline","text":"<pre><code>import os\nfrom copyFile import copy_file\n\nclass MediaProcessor:\n    def __init__(self, input_dir, output_dir, temp_dir):\n        self.input_dir = input_dir\n        self.output_dir = output_dir\n        self.temp_dir = temp_dir\n\n        # Create directories\n        os.makedirs(output_dir, exist_ok=True)\n        os.makedirs(temp_dir, exist_ok=True)\n\n    def process_video(self, video_file):\n        \"\"\"Process video file with staging through temp directory.\"\"\"\n        filename = os.path.basename(video_file)\n        name, ext = os.path.splitext(filename)\n\n        # Stage 1: Copy to temp for processing\n        temp_file = os.path.join(self.temp_dir, filename)\n\n        print(f\"Staging {filename} for processing...\")\n        if not copy_file(\n            video_file, \n            temp_file,\n            buffer_size=2097152,  # 2MB buffer for video\n            progress_callback=self._show_copy_progress\n        ):\n            print(f\"Failed to stage {filename}\")\n            return False\n\n        # Stage 2: Process video (placeholder)\n        processed_file = os.path.join(self.temp_dir, f\"{name}_processed{ext}\")\n        if not self._process_video_placeholder(temp_file, processed_file):\n            print(f\"Failed to process {filename}\")\n            return False\n\n        # Stage 3: Copy to final destination\n        output_file = os.path.join(self.output_dir, f\"{name}_processed{ext}\")\n\n        print(f\"Finalizing {filename}...\")\n        if copy_file(\n            processed_file,\n            output_file,\n            buffer_size=2097152,\n            progress_callback=self._show_copy_progress\n        ):\n            # Cleanup temp files\n            os.remove(temp_file)\n            os.remove(processed_file)\n            print(f\"\u2713 Completed: {filename}\")\n            return True\n        else:\n            print(f\"Failed to finalize {filename}\")\n            return False\n\n    def _show_copy_progress(self, bytes_copied, total_size):\n        \"\"\"Simple progress display.\"\"\"\n        percent = (bytes_copied / total_size) * 100\n        if bytes_copied == total_size or percent % 10 &lt; 1:  # Update every 10%\n            print(f\"  Progress: {percent:.0f}%\")\n\n    def _process_video_placeholder(self, input_file, output_file):\n        \"\"\"Placeholder for actual video processing.\"\"\"\n        # In real implementation, this would call ffmpeg, etc.\n        return copy_file(input_file, output_file)\n\n# Usage\nprocessor = MediaProcessor(\"/input/videos\", \"/output/videos\", \"/tmp/processing\")\nprocessor.process_video(\"/input/videos/movie.mp4\")\n</code></pre>"},{"location":"python/lib/copy_file.html#distributed-file-synchronization","title":"Distributed File Synchronization","text":"<pre><code>import json\nimport hashlib\nfrom pathlib import Path\nfrom copyFile import copy_file, verify_copy\n\nclass FileSynchronizer:\n    def __init__(self, local_dir, remote_dir, manifest_file=\"sync_manifest.json\"):\n        self.local_dir = Path(local_dir)\n        self.remote_dir = Path(remote_dir)\n        self.manifest_file = self.local_dir / manifest_file\n        self.manifest = self._load_manifest()\n\n    def _load_manifest(self):\n        \"\"\"Load synchronization manifest.\"\"\"\n        if self.manifest_file.exists():\n            with open(self.manifest_file, 'r') as f:\n                return json.load(f)\n        return {}\n\n    def _save_manifest(self):\n        \"\"\"Save synchronization manifest.\"\"\"\n        with open(self.manifest_file, 'w') as f:\n            json.dump(self.manifest, f, indent=2)\n\n    def _get_file_info(self, file_path):\n        \"\"\"Get file information for sync tracking.\"\"\"\n        stat = file_path.stat()\n        return {\n            'size': stat.st_size,\n            'mtime': stat.st_mtime,\n            'hash': self._calculate_hash(file_path)\n        }\n\n    def _calculate_hash(self, file_path):\n        \"\"\"Calculate file hash for comparison.\"\"\"\n        hasher = hashlib.blake2b()\n        with open(file_path, 'rb') as f:\n            while chunk := f.read(8192):\n                hasher.update(chunk)\n        return hasher.hexdigest()\n\n    def sync_to_remote(self):\n        \"\"\"Synchronize local files to remote location.\"\"\"\n        synced_count = 0\n\n        for file_path in self.local_dir.rglob('*'):\n            if file_path.is_file() and file_path.name != self.manifest_file.name:\n                relative_path = str(file_path.relative_to(self.local_dir))\n                remote_path = self.remote_dir / relative_path\n\n                # Check if file needs syncing\n                current_info = self._get_file_info(file_path)\n\n                needs_sync = False\n                if relative_path not in self.manifest:\n                    needs_sync = True\n                    print(f\"New file: {relative_path}\")\n                elif self.manifest[relative_path] != current_info:\n                    needs_sync = True\n                    print(f\"Modified file: {relative_path}\")\n\n                if needs_sync:\n                    # Ensure remote directory exists\n                    remote_path.parent.mkdir(parents=True, exist_ok=True)\n\n                    # Copy file\n                    if copy_file(str(file_path), str(remote_path)):\n                        # Verify copy\n                        if verify_copy(str(file_path), str(remote_path), check_hash=True):\n                            self.manifest[relative_path] = current_info\n                            synced_count += 1\n                            print(f\"\u2713 Synced: {relative_path}\")\n                        else:\n                            print(f\"\u2717 Verification failed: {relative_path}\")\n                    else:\n                        print(f\"\u2717 Copy failed: {relative_path}\")\n\n        self._save_manifest()\n        print(f\"\\nSync complete: {synced_count} files updated\")\n        return synced_count\n\n# Usage\nsync = FileSynchronizer(\"/local/project\", \"/remote/backup\")\nsync.sync_to_remote()\n</code></pre>"},{"location":"python/lib/copy_file.html#error-handling-and-recovery","title":"Error Handling and Recovery","text":""},{"location":"python/lib/copy_file.html#comprehensive-error-handling","title":"Comprehensive Error Handling","text":"<pre><code>import os\nimport shutil\nfrom copyFile import copy_file, verify_copy\n\ndef robust_file_copy(source, destination, max_retries=3):\n    \"\"\"Copy file with retry logic and comprehensive error handling.\"\"\"\n\n    for attempt in range(max_retries):\n        try:\n            print(f\"Copy attempt {attempt + 1}/{max_retries}\")\n\n            # Attempt copy\n            success = copy_file(\n                source, \n                destination,\n                create_dirs=True,\n                preserve_file_date=True\n            )\n\n            if not success:\n                raise RuntimeError(\"Copy operation returned False\")\n\n            # Verify copy\n            if not verify_copy(source, destination, check_size=True):\n                raise RuntimeError(\"Copy verification failed\")\n\n            print(f\"\u2713 Successfully copied: {source} -&gt; {destination}\")\n            return True\n\n        except FileNotFoundError:\n            print(f\"\u2717 Source file not found: {source}\")\n            return False\n\n        except PermissionError as e:\n            print(f\"\u2717 Permission denied: {e}\")\n            if attempt &lt; max_retries - 1:\n                print(\"Waiting before retry...\")\n                time.sleep(2)\n            else:\n                return False\n\n        except OSError as e:\n            print(f\"\u2717 System error: {e}\")\n            if attempt &lt; max_retries - 1:\n                # Clean up partial copy\n                if os.path.exists(destination):\n                    try:\n                        os.remove(destination)\n                    except OSError:\n                        pass\n                print(\"Retrying...\")\n                time.sleep(1)\n            else:\n                return False\n\n        except Exception as e:\n            print(f\"\u2717 Unexpected error: {e}\")\n            return False\n\n    print(f\"\u2717 Failed to copy after {max_retries} attempts\")\n    return False\n\n# Usage with error handling\nif robust_file_copy(\"/source/important.db\", \"/backup/important.db\"):\n    print(\"Backup completed successfully\")\nelse:\n    print(\"Backup failed - manual intervention required\")\n</code></pre>"},{"location":"python/lib/copy_file.html#legacy-compatibility","title":"Legacy Compatibility","text":""},{"location":"python/lib/copy_file.html#backward-compatibility-function","title":"Backward Compatibility Function","text":"<pre><code># Legacy function for existing code\ndef copyFile(src, dst, buffer_size=10485760, perserveFileDate=True):\n    \"\"\"Legacy function for backward compatibility.\"\"\"\n    return copy_file(\n        src, \n        dst, \n        buffer_size=buffer_size, \n        preserve_file_date=perserveFileDate\n    )\n\n# Migration example\ndef migrate_legacy_code():\n    \"\"\"Example of migrating from legacy to new API.\"\"\"\n\n    # Old way\n    success = copyFile(\"/old/file.txt\", \"/new/file.txt\", 32768, True)\n\n    # New way (recommended)\n    success = copy_file(\n        \"/old/file.txt\", \n        \"/new/file.txt\",\n        buffer_size=32768,\n        preserve_file_date=True,\n        create_dirs=True,\n        overwrite=True\n    )\n\n    return success\n</code></pre> <p>copyFile.py provides enterprise-grade file copying with performance optimization, progress tracking, verification capabilities, and comprehensive error handling for reliable, high-performance file operations.</p>"},{"location":"python/lib/hash_for_file.html","title":"hash_for_file.py","text":"<p>Multi-algorithm file hashing utilities with streaming support, performance optimization, and comprehensive error handling for file integrity verification.</p>"},{"location":"python/lib/hash_for_file.html#overview","title":"Overview","text":"<p>hash_for_file.py provides fast, secure file hashing capabilities supporting multiple cryptographic algorithms. The module is designed for file integrity verification, deduplication, and content validation workflows with optimal performance for files of any size.</p>"},{"location":"python/lib/hash_for_file.html#features","title":"Features","text":"<ul> <li>Multiple Hash Algorithms - Blake2b, SHA256, SHA1, MD5 support</li> <li>Streaming Processing - Memory-efficient handling of large files</li> <li>Performance Optimized - Configurable buffer sizes for optimal I/O</li> <li>Error Handling - Comprehensive error management and reporting</li> <li>Legacy Compatibility - Backward compatibility with existing code</li> <li>Modern Defaults - Blake2b as secure, fast default algorithm</li> </ul>"},{"location":"python/lib/hash_for_file.html#supported-algorithms","title":"Supported Algorithms","text":"Algorithm Speed Security Use Case <code>blake2b</code> Very Fast High Recommended default - Best balance of speed and security <code>sha256</code> Medium High Standards compliance, regulatory requirements <code>sha1</code> Fast Medium Legacy compatibility (avoid for new projects) <code>md5</code> Very Fast Low Legacy systems only (not cryptographically secure)"},{"location":"python/lib/hash_for_file.html#usage","title":"Usage","text":""},{"location":"python/lib/hash_for_file.html#basic-usage","title":"Basic Usage","text":"<pre><code>from hash_for_file import hash_for_file\n\n# Using default Blake2b algorithm\nfile_hash = hash_for_file(\"/path/to/file.txt\")\nprint(f\"Blake2b hash: {file_hash}\")\n\n# Specify algorithm\nsha256_hash = hash_for_file(\"/path/to/file.txt\", \"sha256\")\nprint(f\"SHA256 hash: {sha256_hash}\")\n\n# Custom buffer size for performance tuning\nhash_value = hash_for_file(\"/path/to/large_file.bin\", \"blake2b\", 16384)\n</code></pre>"},{"location":"python/lib/hash_for_file.html#advanced-usage","title":"Advanced Usage","text":"<pre><code>import os\nfrom hash_for_file import hash_for_file\n\ndef verify_file_integrity(file_path, expected_hash, algorithm=\"blake2b\"):\n    \"\"\"Verify file integrity against expected hash.\"\"\"\n    try:\n        actual_hash = hash_for_file(file_path, algorithm)\n        return actual_hash == expected_hash\n    except RuntimeError as e:\n        print(f\"Hash verification failed: {e}\")\n        return False\n\ndef compare_files(file1, file2, algorithm=\"blake2b\"):\n    \"\"\"Compare two files using hash comparison.\"\"\"\n    hash1 = hash_for_file(file1, algorithm)\n    hash2 = hash_for_file(file2, algorithm)\n    return hash1 == hash2\n\ndef get_file_fingerprint(file_path):\n    \"\"\"Get comprehensive file fingerprint.\"\"\"\n    stat = os.stat(file_path)\n    return {\n        'blake2b': hash_for_file(file_path, 'blake2b'),\n        'sha256': hash_for_file(file_path, 'sha256'),\n        'size': stat.st_size,\n        'modified': stat.st_mtime\n    }\n</code></pre>"},{"location":"python/lib/hash_for_file.html#api-reference","title":"API Reference","text":""},{"location":"python/lib/hash_for_file.html#hash_for_filefile_path-algorithmblake2b-block_size8192","title":"hash_for_file(file_path, algorithm='blake2b', block_size=8192)","text":"<p>Calculate hash for a file using specified algorithm.</p> <p>Parameters: - <code>file_path</code> (str): Path to the file to hash - <code>algorithm</code> (str): Hash algorithm ('blake2b', 'sha256', 'sha1', 'md5') - <code>block_size</code> (int): Buffer size for file reading (default: 8192 bytes)</p> <p>Returns: - <code>str</code>: Hexadecimal hash string</p> <p>Raises: - <code>ValueError</code>: If algorithm is not supported - <code>RuntimeError</code>: If file cannot be read or processed</p> <p>Example: <pre><code># Basic usage with defaults\nhash_value = hash_for_file(\"document.pdf\")\n\n# High-security hashing\nsecure_hash = hash_for_file(\"sensitive.doc\", \"sha256\")\n\n# Performance optimized for large files\nlarge_file_hash = hash_for_file(\"video.mp4\", \"blake2b\", 65536)\n</code></pre></p>"},{"location":"python/lib/hash_for_file.html#hash_for_file_legacyfilename-block_size8192","title":"hash_for_file_legacy(fileName, block_size=8192)","text":"<p>Legacy SHA1 hash function for backward compatibility.</p> <p>Parameters: - <code>fileName</code> (str): Path to file (legacy parameter name) - <code>block_size</code> (int): Buffer size for reading</p> <p>Returns: - <code>str</code>: SHA1 hash as hexadecimal string</p> <p>Note: This function is provided for backward compatibility only. Use <code>hash_for_file()</code> with explicit algorithm for new code.</p>"},{"location":"python/lib/hash_for_file.html#performance-optimization","title":"Performance Optimization","text":""},{"location":"python/lib/hash_for_file.html#buffer-size-selection","title":"Buffer Size Selection","text":"<p>Choose buffer size based on file characteristics and system:</p> <pre><code># Small files (&lt; 1MB) - default buffer\nhash_for_file(\"config.txt\")  # Uses 8192 bytes\n\n# Medium files (1MB - 100MB) - larger buffer\nhash_for_file(\"document.pdf\", \"blake2b\", 32768)  # 32KB buffer\n\n# Large files (&gt; 100MB) - maximum buffer\nhash_for_file(\"video.mp4\", \"blake2b\", 1048576)  # 1MB buffer\n\n# SSD vs HDD optimization\nif is_ssd_storage(file_path):\n    buffer_size = 1048576  # 1MB for SSD\nelse:\n    buffer_size = 65536    # 64KB for HDD\n\nhash_value = hash_for_file(file_path, \"blake2b\", buffer_size)\n</code></pre>"},{"location":"python/lib/hash_for_file.html#algorithm-performance-comparison","title":"Algorithm Performance Comparison","text":"<pre><code>import time\nfrom hash_for_file import hash_for_file\n\ndef benchmark_algorithms(file_path):\n    \"\"\"Benchmark different hash algorithms.\"\"\"\n    algorithms = [\"blake2b\", \"sha256\", \"sha1\", \"md5\"]\n    results = {}\n\n    for algorithm in algorithms:\n        start_time = time.time()\n        hash_value = hash_for_file(file_path, algorithm)\n        end_time = time.time()\n\n        results[algorithm] = {\n            'hash': hash_value,\n            'time': end_time - start_time\n        }\n\n    return results\n\n# Example output:\n# {\n#     'blake2b': {'hash': 'a1b2c3...', 'time': 0.125},\n#     'sha256':  {'hash': 'd4e5f6...', 'time': 0.203},\n#     'sha1':    {'hash': 'g7h8i9...', 'time': 0.156},\n#     'md5':     {'hash': 'j0k1l2...', 'time': 0.089}\n# }\n</code></pre>"},{"location":"python/lib/hash_for_file.html#integration-examples","title":"Integration Examples","text":""},{"location":"python/lib/hash_for_file.html#file-deduplication","title":"File Deduplication","text":"<pre><code>import os\nfrom collections import defaultdict\nfrom hash_for_file import hash_for_file\n\ndef find_duplicate_files(directory):\n    \"\"\"Find duplicate files by hash comparison.\"\"\"\n    hash_to_files = defaultdict(list)\n\n    for root, dirs, files in os.walk(directory):\n        for filename in files:\n            file_path = os.path.join(root, filename)\n            try:\n                file_hash = hash_for_file(file_path, \"blake2b\")\n                hash_to_files[file_hash].append(file_path)\n            except RuntimeError as e:\n                print(f\"Error hashing {file_path}: {e}\")\n\n    # Return only groups with duplicates\n    duplicates = {k: v for k, v in hash_to_files.items() if len(v) &gt; 1}\n    return duplicates\n\n# Usage\nduplicates = find_duplicate_files(\"/home/user/documents\")\nfor hash_value, file_list in duplicates.items():\n    print(f\"Duplicate files (hash: {hash_value[:16]}...):\")\n    for file_path in file_list:\n        print(f\"  {file_path}\")\n</code></pre>"},{"location":"python/lib/hash_for_file.html#backup-verification","title":"Backup Verification","text":"<pre><code>from hash_for_file import hash_for_file\n\nclass BackupVerifier:\n    def __init__(self, algorithm=\"blake2b\"):\n        self.algorithm = algorithm\n        self.hash_database = {}\n\n    def create_baseline(self, directory):\n        \"\"\"Create hash database for backup verification.\"\"\"\n        for root, dirs, files in os.walk(directory):\n            for filename in files:\n                file_path = os.path.join(root, filename)\n                relative_path = os.path.relpath(file_path, directory)\n\n                try:\n                    file_hash = hash_for_file(file_path, self.algorithm)\n                    self.hash_database[relative_path] = file_hash\n                except RuntimeError as e:\n                    print(f\"Warning: Could not hash {file_path}: {e}\")\n\n    def verify_backup(self, backup_directory):\n        \"\"\"Verify backup against baseline hashes.\"\"\"\n        results = {\n            'verified': [],\n            'corrupted': [],\n            'missing': []\n        }\n\n        # Check each file in baseline\n        for relative_path, expected_hash in self.hash_database.items():\n            backup_file = os.path.join(backup_directory, relative_path)\n\n            if not os.path.exists(backup_file):\n                results['missing'].append(relative_path)\n                continue\n\n            try:\n                actual_hash = hash_for_file(backup_file, self.algorithm)\n                if actual_hash == expected_hash:\n                    results['verified'].append(relative_path)\n                else:\n                    results['corrupted'].append(relative_path)\n            except RuntimeError as e:\n                results['corrupted'].append(relative_path)\n\n        return results\n\n# Usage\nverifier = BackupVerifier(\"sha256\")\nverifier.create_baseline(\"/important/data\")\nresults = verifier.verify_backup(\"/backup/data\")\n\nprint(f\"Verified: {len(results['verified'])} files\")\nprint(f\"Corrupted: {len(results['corrupted'])} files\")\nprint(f\"Missing: {len(results['missing'])} files\")\n</code></pre>"},{"location":"python/lib/hash_for_file.html#content-based-file-organization","title":"Content-Based File Organization","text":"<pre><code>import shutil\nfrom pathlib import Path\nfrom hash_for_file import hash_for_file\n\ndef organize_by_content(source_dir, target_dir):\n    \"\"\"Organize files by content hash to eliminate duplicates.\"\"\"\n    source_path = Path(source_dir)\n    target_path = Path(target_dir)\n    target_path.mkdir(exist_ok=True)\n\n    processed_hashes = set()\n    stats = {'processed': 0, 'duplicates': 0, 'errors': 0}\n\n    for file_path in source_path.rglob('*'):\n        if not file_path.is_file():\n            continue\n\n        try:\n            file_hash = hash_for_file(str(file_path), \"blake2b\")\n            stats['processed'] += 1\n\n            if file_hash in processed_hashes:\n                stats['duplicates'] += 1\n                print(f\"Duplicate found: {file_path} (hash: {file_hash[:16]}...)\")\n                continue\n\n            # Create organized path: first 2 chars / next 2 chars / hash.ext\n            hash_dir = target_path / file_hash[:2] / file_hash[2:4]\n            hash_dir.mkdir(parents=True, exist_ok=True)\n\n            target_file = hash_dir / f\"{file_hash}{file_path.suffix}\"\n            shutil.copy2(file_path, target_file)\n\n            processed_hashes.add(file_hash)\n\n        except RuntimeError as e:\n            stats['errors'] += 1\n            print(f\"Error processing {file_path}: {e}\")\n\n    return stats\n\n# Usage\nstats = organize_by_content(\"/messy/photos\", \"/organized/photos\")\nprint(f\"Processed: {stats['processed']}, Duplicates: {stats['duplicates']}, Errors: {stats['errors']}\")\n</code></pre>"},{"location":"python/lib/hash_for_file.html#error-handling","title":"Error Handling","text":""},{"location":"python/lib/hash_for_file.html#common-exceptions","title":"Common Exceptions","text":"<pre><code>from hash_for_file import hash_for_file\n\ndef safe_hash_file(file_path, algorithm=\"blake2b\"):\n    \"\"\"Safely hash a file with comprehensive error handling.\"\"\"\n    try:\n        return hash_for_file(file_path, algorithm)\n\n    except ValueError as e:\n        print(f\"Invalid algorithm or parameters: {e}\")\n        return None\n\n    except RuntimeError as e:\n        if \"No such file\" in str(e):\n            print(f\"File not found: {file_path}\")\n        elif \"Permission denied\" in str(e):\n            print(f\"Permission denied: {file_path}\")\n        elif \"Is a directory\" in str(e):\n            print(f\"Path is a directory: {file_path}\")\n        else:\n            print(f\"Runtime error: {e}\")\n        return None\n\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\n        return None\n\n# Usage with error handling\nresult = safe_hash_file(\"/path/to/file.txt\")\nif result:\n    print(f\"Hash: {result}\")\nelse:\n    print(\"Hashing failed\")\n</code></pre>"},{"location":"python/lib/hash_for_file.html#validation-and-recovery","title":"Validation and Recovery","text":"<pre><code>def validate_and_retry_hash(file_path, max_retries=3):\n    \"\"\"Validate file and retry hashing if needed.\"\"\"\n    import os\n    import time\n\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(f\"File not found: {file_path}\")\n\n    if not os.path.isfile(file_path):\n        raise ValueError(f\"Path is not a file: {file_path}\")\n\n    for attempt in range(max_retries):\n        try:\n            return hash_for_file(file_path, \"blake2b\")\n\n        except RuntimeError as e:\n            if attempt == max_retries - 1:\n                raise e\n\n            print(f\"Retry {attempt + 1}/{max_retries} for {file_path}\")\n            time.sleep(1)  # Brief delay before retry\n\n    return None\n</code></pre>"},{"location":"python/lib/hash_for_file.html#performance-considerations","title":"Performance Considerations","text":""},{"location":"python/lib/hash_for_file.html#memory-usage","title":"Memory Usage","text":"<ul> <li>Constant Memory - Memory usage independent of file size</li> <li>Streaming Processing - Files processed in small chunks</li> <li>Buffer Optimization - Configurable buffer sizes for different scenarios</li> </ul>"},{"location":"python/lib/hash_for_file.html#io-optimization","title":"I/O Optimization","text":"<pre><code># Optimize for different storage types\ndef get_optimal_buffer_size(file_path):\n    \"\"\"Determine optimal buffer size based on file and storage characteristics.\"\"\"\n    import os\n\n    file_size = os.path.getsize(file_path)\n\n    # Small files\n    if file_size &lt; 1024 * 1024:  # &lt; 1MB\n        return 8192  # 8KB\n\n    # Medium files\n    elif file_size &lt; 100 * 1024 * 1024:  # &lt; 100MB\n        return 65536  # 64KB\n\n    # Large files\n    else:\n        return 1048576  # 1MB\n\n# Usage\noptimal_buffer = get_optimal_buffer_size(\"/path/to/file\")\nhash_value = hash_for_file(\"/path/to/file\", \"blake2b\", optimal_buffer)\n</code></pre>"},{"location":"python/lib/hash_for_file.html#concurrent-processing","title":"Concurrent Processing","text":"<pre><code>import concurrent.futures\nfrom hash_for_file import hash_for_file\n\ndef hash_files_concurrently(file_list, algorithm=\"blake2b\", max_workers=4):\n    \"\"\"Hash multiple files concurrently for better performance.\"\"\"\n    def hash_single_file(file_path):\n        try:\n            return file_path, hash_for_file(file_path, algorithm)\n        except RuntimeError as e:\n            return file_path, f\"ERROR: {e}\"\n\n    results = {}\n\n    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n        future_to_file = {\n            executor.submit(hash_single_file, file_path): file_path \n            for file_path in file_list\n        }\n\n        for future in concurrent.futures.as_completed(future_to_file):\n            file_path, result = future.result()\n            results[file_path] = result\n\n    return results\n\n# Usage\nfile_list = [\"/path/file1.txt\", \"/path/file2.txt\", \"/path/file3.txt\"]\nhashes = hash_files_concurrently(file_list)\n</code></pre>"},{"location":"python/lib/hash_for_file.html#migration-from-legacy-versions","title":"Migration from Legacy Versions","text":""},{"location":"python/lib/hash_for_file.html#updating-existing-code","title":"Updating Existing Code","text":"<pre><code># Old code using SHA1\nfrom hash_for_file import hash_for_file_legacy\nold_hash = hash_for_file_legacy(\"/path/to/file\")\n\n# New code with explicit algorithm\nfrom hash_for_file import hash_for_file\nnew_hash = hash_for_file(\"/path/to/file\", \"sha1\")  # Same result\nsecure_hash = hash_for_file(\"/path/to/file\", \"blake2b\")  # Better security\n</code></pre>"},{"location":"python/lib/hash_for_file.html#batch-migration-script","title":"Batch Migration Script","text":"<pre><code>def migrate_hash_database(old_db_file, new_db_file):\n    \"\"\"Migrate hash database from SHA1 to Blake2b.\"\"\"\n    import json\n\n    # Load old database\n    with open(old_db_file, 'r') as f:\n        old_db = json.load(f)\n\n    # Migrate to new hashes\n    new_db = {}\n    for file_path, old_sha1_hash in old_db.items():\n        if os.path.exists(file_path):\n            try:\n                new_hash = hash_for_file(file_path, \"blake2b\")\n                new_db[file_path] = {\n                    'blake2b': new_hash,\n                    'sha1_legacy': old_sha1_hash  # Keep for reference\n                }\n            except RuntimeError as e:\n                print(f\"Could not migrate {file_path}: {e}\")\n\n    # Save new database\n    with open(new_db_file, 'w') as f:\n        json.dump(new_db, f, indent=2)\n</code></pre> <p>hash_for_file.py provides secure, high-performance file hashing with multiple algorithm support, streaming processing, and comprehensive error handling for all file integrity verification needs.</p>"},{"location":"python/lib/query_yes_no.html","title":"query_yes_no.py","text":"<p>Enhanced interactive user prompts for yes/no questions and multiple choice selections with robust input handling and error management.</p>"},{"location":"python/lib/query_yes_no.html#overview","title":"Overview","text":"<p>query_yes_no.py provides reliable, user-friendly functions for interactive command-line prompts. It handles yes/no questions with configurable defaults and supports multiple choice selections with flexible input validation and error handling.</p>"},{"location":"python/lib/query_yes_no.html#features","title":"Features","text":"<ul> <li>Simple Yes/No Prompts - Classic binary choice prompts with defaults</li> <li>Multiple Choice Support - Extended functionality for complex selections</li> <li>Flexible Input Handling - Accepts various input formats and abbreviations</li> <li>Robust Error Management - Handles EOF, interruptions, and invalid input</li> <li>Configurable Defaults - Optional default values for automated workflows</li> <li>Case Sensitivity Options - Configurable case-sensitive or insensitive matching</li> </ul>"},{"location":"python/lib/query_yes_no.html#basic-usage","title":"Basic Usage","text":""},{"location":"python/lib/query_yes_no.html#yesno-prompts","title":"Yes/No Prompts","text":"<pre><code>from query_yes_no import query_yes_no\n\n# Simple yes/no question with default \"yes\"\nif query_yes_no(\"Do you want to continue?\"):\n    print(\"Continuing...\")\nelse:\n    print(\"Stopping...\")\n\n# Default \"no\"\nif query_yes_no(\"Delete all files?\", default=\"no\"):\n    print(\"Files deleted\")\nelse:\n    print(\"Files preserved\")\n\n# No default - user must provide answer\ntry:\n    result = query_yes_no(\"Proceed with installation?\", default=None)\n    if result:\n        install_software()\nexcept KeyboardInterrupt:\n    print(\"Installation cancelled\")\n</code></pre>"},{"location":"python/lib/query_yes_no.html#multiple-choice-prompts","title":"Multiple Choice Prompts","text":"<pre><code>from query_yes_no import query_choice\n\n# Simple choice selection\nchoices = [\"red\", \"green\", \"blue\"]\ncolor = query_choice(\"Choose a color:\", choices)\nprint(f\"You selected: {color}\")\n\n# With default selection\ncolor = query_choice(\"Choose a color:\", choices, default=\"blue\")\n\n# Case-sensitive choices\nprogramming_languages = [\"Python\", \"JavaScript\", \"Go\"]\nlanguage = query_choice(\n    \"Select language:\", \n    programming_languages, \n    case_sensitive=True\n)\n\n# Using index as default\naction = query_choice(\n    \"Select action:\", \n    [\"start\", \"stop\", \"restart\"], \n    default=0  # \"start\"\n)\n</code></pre>"},{"location":"python/lib/query_yes_no.html#api-reference","title":"API Reference","text":""},{"location":"python/lib/query_yes_no.html#query_yes_noquestion-defaultyes","title":"query_yes_no(question, default=\"yes\")","text":"<p>Ask a yes/no question with configurable default.</p> <p>Parameters: - <code>question</code> (str): Question text to display to user - <code>default</code> (str, optional): Default answer (\"yes\", \"no\", or None)</p> <p>Returns: - <code>bool</code>: True for yes, False for no</p> <p>Raises: - <code>ValueError</code>: If default is not \"yes\", \"no\", or None - <code>KeyboardInterrupt</code>: If user cancels with Ctrl+C</p> <p>Accepted Inputs: - Yes: \"yes\", \"y\", \"ye\", \"YES\", \"Y\", \"Yes\" - No: \"no\", \"n\", \"NO\", \"N\", \"No\" - Empty: Uses default if provided</p> <p>Example: <pre><code># Basic usage\nproceed = query_yes_no(\"Continue with operation?\")\n\n# With explicit default\ndangerous = query_yes_no(\"Delete everything?\", default=\"no\")\n\n# Require explicit answer\nconfirmed = query_yes_no(\"Are you absolutely sure?\", default=None)\n</code></pre></p>"},{"location":"python/lib/query_yes_no.html#query_choicequestion-choices-defaultnone-case_sensitivefalse","title":"query_choice(question, choices, default=None, case_sensitive=False)","text":"<p>Ask a multiple choice question with flexible selection options.</p> <p>Parameters: - <code>question</code> (str): Question text to display - <code>choices</code> (list): List of available choices - <code>default</code> (str or int, optional): Default choice (string value or index) - <code>case_sensitive</code> (bool): Whether choices are case-sensitive</p> <p>Returns: - <code>str</code>: Selected choice as string</p> <p>Raises: - <code>ValueError</code>: If choices list is empty or default is invalid - <code>KeyboardInterrupt</code>: If user cancels with Ctrl+C</p> <p>Example: <pre><code># Basic multiple choice\noptions = [\"create\", \"update\", \"delete\"]\naction = query_choice(\"Select action:\", options)\n\n# With string default\nenv = query_choice(\"Environment:\", [\"dev\", \"staging\", \"prod\"], default=\"dev\")\n\n# With index default\npriority = query_choice(\"Priority:\", [\"low\", \"medium\", \"high\"], default=1)\n\n# Case-sensitive matching\nframework = query_choice(\n    \"Framework:\", \n    [\"Flask\", \"Django\", \"FastAPI\"], \n    case_sensitive=True\n)\n</code></pre></p>"},{"location":"python/lib/query_yes_no.html#advanced-examples","title":"Advanced Examples","text":""},{"location":"python/lib/query_yes_no.html#configuration-wizard","title":"Configuration Wizard","text":"<pre><code>from query_yes_no import query_yes_no, query_choice\n\ndef setup_wizard():\n    \"\"\"Interactive setup wizard using prompts.\"\"\"\n    config = {}\n\n    print(\"=== Application Setup Wizard ===\")\n\n    # Database configuration\n    if query_yes_no(\"Configure database connection?\"):\n        db_types = [\"sqlite\", \"postgresql\", \"mysql\"]\n        config['database'] = query_choice(\"Database type:\", db_types)\n\n        if config['database'] != \"sqlite\":\n            config['db_host'] = input(\"Database host: \")\n            config['db_port'] = input(\"Database port: \")\n\n    # API configuration\n    if query_yes_no(\"Enable API server?\", default=\"yes\"):\n        config['api_enabled'] = True\n\n        port_options = [\"8000\", \"8080\", \"3000\"]\n        config['api_port'] = query_choice(\"API port:\", port_options, default=\"8000\")\n\n        if query_yes_no(\"Enable authentication?\", default=\"no\"):\n            auth_methods = [\"jwt\", \"session\", \"api_key\"]\n            config['auth_method'] = query_choice(\"Auth method:\", auth_methods)\n\n    # Environment selection\n    environments = [\"development\", \"staging\", \"production\"]\n    config['environment'] = query_choice(\n        \"Target environment:\", \n        environments, \n        default=\"development\"\n    )\n\n    # Confirmation\n    print(\"\\nConfiguration Summary:\")\n    for key, value in config.items():\n        print(f\"  {key}: {value}\")\n\n    if query_yes_no(\"\\nSave this configuration?\"):\n        save_config(config)\n        print(\"Configuration saved!\")\n    else:\n        print(\"Configuration discarded.\")\n\n    return config\n\ndef save_config(config):\n    \"\"\"Save configuration to file.\"\"\"\n    import json\n    with open(\"config.json\", \"w\") as f:\n        json.dump(config, f, indent=2)\n</code></pre>"},{"location":"python/lib/query_yes_no.html#interactive-file-operations","title":"Interactive File Operations","text":"<pre><code>import os\nimport shutil\nfrom query_yes_no import query_yes_no, query_choice\n\ndef interactive_file_manager(directory):\n    \"\"\"Interactive file management with user prompts.\"\"\"\n    if not os.path.exists(directory):\n        if query_yes_no(f\"Directory {directory} doesn't exist. Create it?\"):\n            os.makedirs(directory)\n        else:\n            return\n\n    while True:\n        # List files\n        files = os.listdir(directory)\n        if not files:\n            print(\"Directory is empty\")\n            if not query_yes_no(\"Continue anyway?\"):\n                break\n        else:\n            print(f\"\\nFiles in {directory}:\")\n            for i, filename in enumerate(files, 1):\n                print(f\"  {i}. {filename}\")\n\n        # Action selection\n        actions = [\"add file\", \"delete file\", \"rename file\", \"exit\"]\n        action = query_choice(\"\\nSelect action:\", actions, default=\"exit\")\n\n        if action == \"exit\":\n            break\n        elif action == \"add file\":\n            filename = input(\"Enter filename: \")\n            filepath = os.path.join(directory, filename)\n            with open(filepath, 'w') as f:\n                f.write(\"# New file created by interactive manager\\n\")\n            print(f\"Created: {filename}\")\n\n        elif action == \"delete file\" and files:\n            target = query_choice(\"Select file to delete:\", files)\n            if query_yes_no(f\"Really delete {target}?\", default=\"no\"):\n                os.remove(os.path.join(directory, target))\n                print(f\"Deleted: {target}\")\n\n        elif action == \"rename file\" and files:\n            old_name = query_choice(\"Select file to rename:\", files)\n            new_name = input(\"Enter new name: \")\n            old_path = os.path.join(directory, old_name)\n            new_path = os.path.join(directory, new_name)\n            shutil.move(old_path, new_path)\n            print(f\"Renamed: {old_name} -&gt; {new_name}\")\n\n# Usage\ninteractive_file_manager(\"/tmp/test_dir\")\n</code></pre>"},{"location":"python/lib/query_yes_no.html#deployment-confirmation","title":"Deployment Confirmation","text":"<pre><code>def deployment_workflow():\n    \"\"\"Safe deployment with multiple confirmation steps.\"\"\"\n\n    # Environment selection\n    environments = [\"staging\", \"production\"]\n    target_env = query_choice(\"Deploy to which environment?\", environments)\n\n    if target_env == \"production\":\n        print(\"\u26a0\ufe0f  WARNING: You are deploying to PRODUCTION!\")\n        if not query_yes_no(\"Are you absolutely sure?\", default=\"no\"):\n            print(\"Deployment cancelled\")\n            return False\n\n        # Additional production checks\n        checks = [\n            \"All tests are passing\",\n            \"Code review is complete\", \n            \"Database migrations are ready\",\n            \"Monitoring is configured\"\n        ]\n\n        print(\"\\nPre-deployment checklist:\")\n        for check in checks:\n            if not query_yes_no(f\"\u2713 {check}?\", default=\"no\"):\n                print(f\"\u274c Failed: {check}\")\n                print(\"Please complete all checks before deploying\")\n                return False\n\n        # Final confirmation\n        if not query_yes_no(\"\\n\ud83d\ude80 Deploy to production now?\", default=\"no\"):\n            print(\"Deployment cancelled\")\n            return False\n\n    # Deployment options\n    deploy_options = [\"full\", \"rolling\", \"canary\"]\n    strategy = query_choice(\"Deployment strategy:\", deploy_options, default=\"rolling\")\n\n    print(f\"\\nDeploying to {target_env} using {strategy} strategy...\")\n    return True\n</code></pre>"},{"location":"python/lib/query_yes_no.html#error-handling","title":"Error Handling","text":""},{"location":"python/lib/query_yes_no.html#graceful-interruption-handling","title":"Graceful Interruption Handling","text":"<pre><code>def safe_interactive_session():\n    \"\"\"Example of handling user interruptions gracefully.\"\"\"\n    try:\n        while True:\n            if not query_yes_no(\"Continue session?\"):\n                print(\"Session ended by user choice\")\n                break\n\n            # Simulate some work\n            action = query_choice(\"What to do?\", [\"work\", \"rest\", \"quit\"])\n\n            if action == \"quit\":\n                break\n            elif action == \"work\":\n                print(\"Working...\")\n            else:\n                print(\"Resting...\")\n\n    except KeyboardInterrupt:\n        print(\"\\n\\nSession interrupted by user (Ctrl+C)\")\n        if query_yes_no(\"Save progress before exiting?\", default=\"yes\"):\n            print(\"Progress saved\")\n        print(\"Goodbye!\")\n\n    except EOFError:\n        print(\"\\nInput stream closed unexpectedly\")\n        print(\"Exiting...\")\n</code></pre>"},{"location":"python/lib/query_yes_no.html#input-validation-and-recovery","title":"Input Validation and Recovery","text":"<pre><code>def robust_configuration():\n    \"\"\"Configuration with validation and error recovery.\"\"\"\n    max_retries = 3\n\n    for attempt in range(max_retries):\n        try:\n            # Get user choices\n            level = query_choice(\n                \"Log level:\", \n                [\"debug\", \"info\", \"warning\", \"error\"],\n                default=\"info\"\n            )\n\n            if query_yes_no(\"Enable verbose output?\"):\n                verbose = True\n            else:\n                verbose = False\n\n            # Validation\n            if level == \"debug\" and not verbose:\n                print(\"Warning: Debug level usually requires verbose output\")\n                if query_yes_no(\"Enable verbose for debug mode?\"):\n                    verbose = True\n\n            return {'log_level': level, 'verbose': verbose}\n\n        except (KeyboardInterrupt, EOFError):\n            if attempt &lt; max_retries - 1:\n                print(f\"\\nRetry {attempt + 1}/{max_retries}\")\n                if query_yes_no(\"Try again?\", default=\"yes\"):\n                    continue\n            print(\"Configuration cancelled\")\n            return None\n\n        except Exception as e:\n            print(f\"Unexpected error: {e}\")\n            if attempt &lt; max_retries - 1:\n                if query_yes_no(\"Retry configuration?\"):\n                    continue\n            return None\n\n    return None\n</code></pre>"},{"location":"python/lib/query_yes_no.html#integration-patterns","title":"Integration Patterns","text":""},{"location":"python/lib/query_yes_no.html#cli-tool-integration","title":"CLI Tool Integration","text":"<pre><code>import argparse\nfrom query_yes_no import query_yes_no, query_choice\n\ndef create_cli_with_interactive_mode():\n    \"\"\"CLI tool with optional interactive mode.\"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--interactive\", \"-i\", action=\"store_true\")\n    parser.add_argument(\"--action\", choices=[\"start\", \"stop\", \"restart\"])\n    parser.add_argument(\"--force\", action=\"store_true\")\n\n    args = parser.parse_args()\n\n    if args.interactive:\n        # Interactive mode\n        action = query_choice(\"Select action:\", [\"start\", \"stop\", \"restart\"])\n        force = query_yes_no(\"Force operation?\", default=\"no\")\n    else:\n        # Command-line mode\n        action = args.action\n        force = args.force\n\n        # Prompt for dangerous operations if not forced\n        if action == \"stop\" and not force:\n            force = query_yes_no(\"Really stop the service?\", default=\"no\")\n\n    if action and (force or action != \"stop\"):\n        execute_action(action, force)\n    else:\n        print(\"Operation cancelled\")\n\ndef execute_action(action, force):\n    print(f\"Executing: {action} (force: {force})\")\n</code></pre>"},{"location":"python/lib/query_yes_no.html#testing-support","title":"Testing Support","text":"<pre><code>import io\nimport sys\nfrom contextlib import redirect_stdin\nfrom query_yes_no import query_yes_no, query_choice\n\ndef test_interactive_functions():\n    \"\"\"Example of testing interactive functions with mocked input.\"\"\"\n\n    # Test yes/no with \"yes\" input\n    test_input = io.StringIO(\"yes\\n\")\n    with redirect_stdin(test_input):\n        result = query_yes_no(\"Test question?\")\n        assert result == True\n\n    # Test multiple choice\n    test_input = io.StringIO(\"option2\\n\")\n    with redirect_stdin(test_input):\n        result = query_choice(\"Choose:\", [\"option1\", \"option2\", \"option3\"])\n        assert result == \"option2\"\n\n    # Test with default\n    test_input = io.StringIO(\"\\n\")  # Empty input, should use default\n    with redirect_stdin(test_input):\n        result = query_yes_no(\"Test with default?\", default=\"yes\")\n        assert result == True\n\n    print(\"All tests passed!\")\n\n# For automated testing environments\ndef mock_user_input(responses):\n    \"\"\"Context manager to mock user responses for testing.\"\"\"\n    class MockInput:\n        def __init__(self, responses):\n            self.responses = iter(responses)\n\n        def __call__(self, prompt=\"\"):\n            try:\n                response = next(self.responses)\n                print(f\"{prompt}{response}\")  # Show what was \"typed\"\n                return response\n            except StopIteration:\n                raise EOFError(\"No more mock responses\")\n\n    import builtins\n    original_input = builtins.input\n    builtins.input = MockInput(responses)\n\n    try:\n        yield\n    finally:\n        builtins.input = original_input\n\n# Usage in tests\ndef test_configuration_wizard():\n    responses = [\"yes\", \"postgresql\", \"localhost\", \"5432\", \"no\"]\n\n    with mock_user_input(responses):\n        config = setup_wizard()\n        assert config['database'] == 'postgresql'\n</code></pre>"},{"location":"python/lib/query_yes_no.html#best-practices","title":"Best Practices","text":""},{"location":"python/lib/query_yes_no.html#user-experience","title":"User Experience","text":"<ol> <li>Clear Questions - Use specific, unambiguous question text</li> <li>Sensible Defaults - Provide safe defaults for common operations</li> <li>Confirmation for Destructive Actions - Always confirm dangerous operations</li> <li>Progress Indication - Show progress in multi-step processes</li> </ol>"},{"location":"python/lib/query_yes_no.html#error-handling_1","title":"Error Handling","text":"<ol> <li>Graceful Interruption - Handle Ctrl+C appropriately</li> <li>Input Validation - Validate responses and provide helpful error messages</li> <li>Retry Logic - Allow users to retry on errors</li> <li>Fallback Options - Provide alternatives when primary options fail</li> </ol>"},{"location":"python/lib/query_yes_no.html#code-organization","title":"Code Organization","text":"<ol> <li>Separation of Concerns - Keep UI logic separate from business logic</li> <li>Testability - Design for easy testing with mocked input</li> <li>Consistency - Use consistent prompting patterns across application</li> <li>Documentation - Document expected user interactions</li> </ol> <p>query_yes_no.py provides robust, user-friendly interactive prompts with comprehensive error handling and flexible configuration options for command-line applications.</p>"},{"location":"python/media/convert_psd_to_exr.html","title":"convert_psd_to_exr.py","text":"<p>Convert Photoshop PSD files to OpenEXR format while preserving layer structure and names, with secure subprocess handling and comprehensive error management.</p>"},{"location":"python/media/convert_psd_to_exr.html#overview","title":"Overview","text":"<p>convert_psd_to_exr.py is a professional tool for converting Adobe Photoshop PSD files to OpenEXR format, maintaining layer integrity and supporting both individual layer extraction and multi-part EXR creation. The script uses ImageMagick and OpenEXR tools for high-quality conversion suitable for VFX and compositing workflows.</p>"},{"location":"python/media/convert_psd_to_exr.html#features","title":"Features","text":"<ul> <li>Layer Preservation - Maintains original layer names and structure</li> <li>Multiple Output Modes - Individual EXR files per layer or single multi-part EXR</li> <li>Batch Processing - Convert entire directories of PSD files</li> <li>EXR Compression - Support for all OpenEXR compression algorithms</li> <li>Security Hardened - No shell injection vulnerabilities</li> <li>Performance Timing - Integrated timing for conversion monitoring</li> <li>Error Handling - Robust error handling with detailed reporting</li> </ul>"},{"location":"python/media/convert_psd_to_exr.html#requirements","title":"Requirements","text":""},{"location":"python/media/convert_psd_to_exr.html#external-dependencies","title":"External Dependencies","text":"<ul> <li>ImageMagick with OpenEXR and HDRi support</li> <li>Homepage: https://www.imagemagick.org/</li> <li>HDRi Guide: https://www.imagemagick.org/script/high-dynamic-range.php</li> <li>OpenEXR binaries (exrmultipart, exrmaketiled)</li> <li>Homepage: http://www.openexr.org/</li> </ul>"},{"location":"python/media/convert_psd_to_exr.html#installation","title":"Installation","text":"<pre><code># macOS with Homebrew\nbrew install imagemagick --with-openexr\nbrew install openexr\n\n# Ubuntu/Debian\nsudo apt-get install imagemagick libmagick++-dev openexr libopenexr-dev\n\n# CentOS/RHEL\nsudo yum install ImageMagick-devel OpenEXR-devel\n</code></pre>"},{"location":"python/media/convert_psd_to_exr.html#usage","title":"Usage","text":""},{"location":"python/media/convert_psd_to_exr.html#basic-usage","title":"Basic Usage","text":"<pre><code># Convert single PSD file\npython3 convert_psd_to_exr.py input.psd\n\n# Convert all PSD files in directory\npython3 convert_psd_to_exr.py /path/to/psd/directory\n\n# Create multi-layer EXR instead of individual files\npython3 convert_psd_to_exr.py input.psd --multilayer\n</code></pre>"},{"location":"python/media/convert_psd_to_exr.html#advanced-usage","title":"Advanced Usage","text":"<pre><code># Specify EXR compression\npython3 convert_psd_to_exr.py input.psd --compression zip\n\n# Batch convert with multi-layer output\npython3 convert_psd_to_exr.py /path/to/psds \\\n    --multilayer \\\n    --compression b44a\n</code></pre>"},{"location":"python/media/convert_psd_to_exr.html#command-line-options","title":"Command-Line Options","text":"Option Short Description Default <code>input</code> - Input PSD file or directory containing PSD files Required <code>--compression</code> <code>-c</code> EXR compression type <code>B44A</code> <code>--multilayer</code> <code>-m</code> Output multilayered EXR instead of one EXR per layer False"},{"location":"python/media/convert_psd_to_exr.html#exr-compression-options","title":"EXR Compression Options","text":"Compression Description Use Case <code>none</code> No compression Fastest access, largest files <code>rle</code> Run-length encoding Simple compression <code>zip</code> Zip compression Good compression ratio <code>piz</code> PIZ compression Good for noisy images <code>pxr24</code> Pixar 24-bit Lossy, smaller files <code>b44</code> B44 compression Good for final images <code>b44a</code> B44A compression Best general purpose (default) <code>dwaa</code> DWAA compression Advanced compression <code>dwab</code> DWAB compression Advanced compression"},{"location":"python/media/convert_psd_to_exr.html#output-modes","title":"Output Modes","text":""},{"location":"python/media/convert_psd_to_exr.html#individual-layer-mode-default","title":"Individual Layer Mode (Default)","text":"<p>Creates separate EXR files for each layer: <pre><code>input.psd \u2192 input_layer1.exr\n          \u2192 input_layer2.exr\n          \u2192 input_layer3.exr\n</code></pre></p>"},{"location":"python/media/convert_psd_to_exr.html#multi-layer-mode-multilayer","title":"Multi-Layer Mode (--multilayer)","text":"<p>Creates single EXR with all layers: <pre><code>input.psd \u2192 input.exr (contains all layers)\n</code></pre></p>"},{"location":"python/media/convert_psd_to_exr.html#layer-processing","title":"Layer Processing","text":""},{"location":"python/media/convert_psd_to_exr.html#layer-detection","title":"Layer Detection","text":"<p>The script automatically detects layers by: 1. Running <code>identify -verbose</code> on the PSD file 2. Parsing layer information from ImageMagick output 3. Extracting layer names and indices 4. Handling empty or flattened layers gracefully</p>"},{"location":"python/media/convert_psd_to_exr.html#layer-export-process","title":"Layer Export Process","text":"<ol> <li>Extract Layer - Uses ImageMagick convert to extract individual layers</li> <li>Apply Compression - Uses exrmaketiled to apply EXR compression</li> <li>Clean Temporary Files - Removes intermediate files automatically</li> <li>Combine (if multi-layer) - Uses exrmultipart to create single file</li> </ol>"},{"location":"python/media/convert_psd_to_exr.html#rgba-layer-handling","title":"RGBA Layer Handling","text":"<ul> <li>RGBA layer is automatically placed as the topmost layer in multi-part EXR</li> <li>Ensures proper compositing order for downstream applications</li> <li>Compatibility with industry-standard EXR workflows</li> </ul>"},{"location":"python/media/convert_psd_to_exr.html#examples","title":"Examples","text":""},{"location":"python/media/convert_psd_to_exr.html#example-1-single-file-conversion","title":"Example 1: Single File Conversion","text":"<pre><code>python3 convert_psd_to_exr.py ~/Desktop/comp_v001.psd\n</code></pre> <p>Output: <pre><code>Processing: /Users/alex/Desktop/comp_v001.psd\nProcessing layer 1: background\nProcessing layer 2: foreground\nProcessing layer 3: rgba\nPSD To EXR Conversion Running Time: 45.30 seconds\n</code></pre></p> <p>Creates: - <code>comp_v001_background.exr</code> - <code>comp_v001_foreground.exr</code> - <code>comp_v001_rgba.exr</code></p>"},{"location":"python/media/convert_psd_to_exr.html#example-2-multi-layer-exr","title":"Example 2: Multi-Layer EXR","text":"<pre><code>python3 convert_psd_to_exr.py ~/Desktop/comp_v001.psd --multilayer\n</code></pre> <p>Creates single file: <code>comp_v001.exr</code> containing all layers</p>"},{"location":"python/media/convert_psd_to_exr.html#example-3-batch-processing","title":"Example 3: Batch Processing","text":"<pre><code>python3 convert_psd_to_exr.py ~/Projects/Renders/PSDs --compression zip\n</code></pre> <p>Converts all PSD files in the directory with ZIP compression.</p>"},{"location":"python/media/convert_psd_to_exr.html#example-4-vfx-pipeline-integration","title":"Example 4: VFX Pipeline Integration","text":"<pre><code>#!/bin/bash\n# VFX conversion pipeline\n\nINPUT_DIR=\"/mnt/projects/shot001/comp\"\nOUTPUT_DIR=\"/mnt/projects/shot001/elements\"\n\necho \"Converting PSD comps to EXR...\"\ncd \"$OUTPUT_DIR\"\n\npython3 convert_psd_to_exr.py \"$INPUT_DIR\" \\\n    --compression b44a \\\n    --multilayer\n\necho \"Conversion complete. Files ready for Nuke.\"\n</code></pre>"},{"location":"python/media/convert_psd_to_exr.html#error-handling","title":"Error Handling","text":""},{"location":"python/media/convert_psd_to_exr.html#common-issues-and-solutions","title":"Common Issues and Solutions","text":"<p>Issue: \"identify: command not found\" <pre><code># Install ImageMagick\nbrew install imagemagick  # macOS\nsudo apt-get install imagemagick  # Ubuntu\n</code></pre></p> <p>Issue: \"exrmultipart: command not found\" <pre><code># Install OpenEXR tools\nbrew install openexr  # macOS\nsudo apt-get install openexr  # Ubuntu\n</code></pre></p> <p>Issue: \"No layers found in file\" <pre><code>Solution: PSD file may be flattened or corrupted\n- Check file in Photoshop\n- Ensure layers are properly named\n- Try re-saving PSD with maximum compatibility\n</code></pre></p> <p>Issue: Conversion fails on specific layers <pre><code>Solution: Check for unsupported layer types\n- Some layer effects may not convert properly\n- Rasterize complex layers before conversion\n- Check layer names for special characters\n</code></pre></p>"},{"location":"python/media/convert_psd_to_exr.html#security-features","title":"Security Features","text":"<ul> <li>No Shell Injection - All subprocess calls use list arguments</li> <li>Input Validation - Validates file paths and arguments</li> <li>Safe File Operations - Proper handling of temporary files</li> <li>Error Isolation - Errors in one file don't stop batch processing</li> </ul>"},{"location":"python/media/convert_psd_to_exr.html#performance-optimization","title":"Performance Optimization","text":""},{"location":"python/media/convert_psd_to_exr.html#large-file-handling","title":"Large File Handling","text":"<ul> <li>Streaming Processing - Processes layers individually to manage memory</li> <li>Temporary File Management - Automatic cleanup of intermediate files</li> <li>Compression Optimization - Intelligent compression selection</li> <li>Batch Efficiency - Optimized for processing multiple files</li> </ul>"},{"location":"python/media/convert_psd_to_exr.html#memory-considerations","title":"Memory Considerations","text":"<ul> <li>Each layer is processed independently</li> <li>Temporary files are cleaned immediately after use</li> <li>Memory usage scales with individual layer size, not total PSD size</li> </ul>"},{"location":"python/media/convert_psd_to_exr.html#integration","title":"Integration","text":""},{"location":"python/media/convert_psd_to_exr.html#nuke-pipeline","title":"Nuke Pipeline","text":"<pre><code># Nuke script to import multi-layer EXR\nimport nuke\n\ndef import_multilayer_exr(filepath):\n    \"\"\"Import multi-layer EXR into Nuke.\"\"\"\n    read_node = nuke.createNode(\"Read\")\n    read_node['file'].setValue(filepath)\n\n    # Set up layer channels\n    read_node['premultiplied'].setValue(True)\n    read_node['auto_alpha'].setValue(True)\n\n    return read_node\n\n# Usage\nexr_file = \"/path/to/converted/comp_v001.exr\"\nread_node = import_multilayer_exr(exr_file)\n</code></pre>"},{"location":"python/media/convert_psd_to_exr.html#after-effects-integration","title":"After Effects Integration","text":"<pre><code>// After Effects script to import EXR sequence\nvar comp = app.project.activeItem;\nvar folder = Folder.selectDialog(\"Select EXR folder\");\n\nif (folder) {\n    var files = folder.getFiles(\"*.exr\");\n    for (var i = 0; i &lt; files.length; i++) {\n        var importOptions = new ImportOptions(files[i]);\n        var footage = app.project.importFile(importOptions);\n        comp.layers.add(footage);\n    }\n}\n</code></pre>"},{"location":"python/media/convert_psd_to_exr.html#maya-integration","title":"Maya Integration","text":"<pre><code># Maya script to import EXR files\nimport maya.cmds as cmds\n\ndef import_exr_layers(directory):\n    \"\"\"Import EXR files as file textures in Maya.\"\"\"\n    import os\n\n    exr_files = [f for f in os.listdir(directory) if f.endswith('.exr')]\n\n    for exr_file in exr_files:\n        filepath = os.path.join(directory, exr_file)\n\n        # Create file texture node\n        file_node = cmds.shadingNode('file', asTexture=True)\n        cmds.setAttr(f\"{file_node}.fileTextureName\", filepath, type=\"string\")\n        cmds.setAttr(f\"{file_node}.colorSpace\", \"Raw\", type=\"string\")\n\n        print(f\"Imported: {exr_file}\")\n\n# Usage\nimport_exr_layers(\"/path/to/converted/exrs\")\n</code></pre>"},{"location":"python/media/convert_psd_to_exr.html#workflow-best-practices","title":"Workflow Best Practices","text":""},{"location":"python/media/convert_psd_to_exr.html#psd-preparation","title":"PSD Preparation","text":"<ol> <li>Layer Organization - Use descriptive layer names</li> <li>Flattening - Avoid unnecessary layer effects</li> <li>Naming Convention - Use consistent, pipeline-friendly names</li> <li>File Size - Consider splitting very large PSDs</li> </ol>"},{"location":"python/media/convert_psd_to_exr.html#conversion-strategy","title":"Conversion Strategy","text":"<ol> <li>Test First - Convert single file before batch processing</li> <li>Compression Choice - Select appropriate compression for use case</li> <li>Quality Control - Verify converted files in target application</li> <li>Archive Originals - Keep original PSD files for future edits</li> </ol>"},{"location":"python/media/convert_psd_to_exr.html#pipeline-integration","title":"Pipeline Integration","text":"<ol> <li>Automation - Include in render pipeline scripts</li> <li>Validation - Check converted files automatically</li> <li>Metadata - Preserve creation and modification dates</li> <li>Version Control - Track PSD and EXR versions together</li> </ol>"},{"location":"python/media/convert_psd_to_exr.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"python/media/convert_psd_to_exr.html#imagemagick-issues","title":"ImageMagick Issues","text":"<pre><code># Check ImageMagick installation\nidentify -version\n\n# Check OpenEXR support\nidentify -list format | grep EXR\n\n# Test basic conversion\nconvert input.psd[0] test.exr\n</code></pre>"},{"location":"python/media/convert_psd_to_exr.html#openexr-tools-issues","title":"OpenEXR Tools Issues","text":"<pre><code># Check OpenEXR tools\nwhich exrmaketiled\nwhich exrmultipart\n\n# Test EXR tools\nexrheader test.exr\n</code></pre>"},{"location":"python/media/convert_psd_to_exr.html#file-permission-issues","title":"File Permission Issues","text":"<pre><code># Fix permissions\nchmod 755 /path/to/script\nchmod 644 /path/to/psd/files\n</code></pre> <p>convert_psd_to_exr.py provides professional PSD to EXR conversion with layer preservation, security hardening, and comprehensive error handling for VFX and compositing workflows.</p>"},{"location":"python/system/compare_folders.html","title":"compareFolders.py","text":"<p>Advanced directory comparison and synchronization analysis tool with comprehensive filtering, recursive scanning, and detailed reporting capabilities.</p>"},{"location":"python/system/compare_folders.html#overview","title":"Overview","text":"<p>compareFolders.py performs in-depth analysis of two directory structures to identify missing files, size differences, and synchronization issues. The tool is designed for backup validation, mirror maintenance, and large-scale directory synchronization workflows.</p>"},{"location":"python/system/compare_folders.html#features","title":"Features","text":"<ul> <li>Recursive Directory Scanning - Deep analysis of entire directory trees</li> <li>Missing File Detection - Identifies files present in one directory but not the other</li> <li>Size Comparison - Detects files with different sizes between directories</li> <li>Advanced Filtering - File extension, size, and date filtering options</li> <li>Progress Tracking - Real-time progress updates for large datasets</li> <li>Multiple Output Formats - Console, file, and structured reporting</li> <li>Performance Optimization - Efficient handling of large directory structures</li> </ul>"},{"location":"python/system/compare_folders.html#usage","title":"Usage","text":""},{"location":"python/system/compare_folders.html#basic-usage","title":"Basic Usage","text":"<pre><code># Compare two directories\npython3 compareFolders.py /source/dir /destination/dir\n\n# Recursive comparison with progress\npython3 compareFolders.py /source/dir /destination/dir --recursive --verbose\n\n# Generate detailed report file\npython3 compareFolders.py /source/dir /destination/dir \\\n    --output-file comparison_report.txt\n</code></pre>"},{"location":"python/system/compare_folders.html#advanced-usage","title":"Advanced Usage","text":"<pre><code># Filter by file extension\npython3 compareFolders.py /source/dir /destination/dir \\\n    --filter-extension .mov \\\n    --recursive\n\n# Size-based filtering\npython3 compareFolders.py /source/dir /destination/dir \\\n    --min-size 1048576 \\\n    --max-size 10737418240\n\n# Generate copy script for missing files\npython3 compareFolders.py /source/dir /destination/dir \\\n    --generate-script \\\n    --recursive\n</code></pre>"},{"location":"python/system/compare_folders.html#command-line-options","title":"Command-Line Options","text":"Option Short Description Default <code>source_dir</code> - Source directory path Required <code>dest_dir</code> - Destination directory path Required <code>--recursive</code> <code>-r</code> Scan directories recursively False <code>--filter-extension</code> <code>-f</code> Filter by file extension (e.g., .mov, .jpg) None <code>--min-size</code> - Minimum file size in bytes None <code>--max-size</code> - Maximum file size in bytes None <code>--output-file</code> <code>-o</code> Output file for detailed report None <code>--generate-script</code> - Generate copy script for missing files False <code>--show-sizes</code> - Show file sizes in output False <code>--verbose</code> <code>-v</code> Show detailed progress information False"},{"location":"python/system/compare_folders.html#comparison-analysis","title":"Comparison Analysis","text":""},{"location":"python/system/compare_folders.html#file-detection","title":"File Detection","text":"<p>The script identifies three categories of files:</p> <ol> <li>Missing in Destination - Files present in source but not destination</li> <li>Missing in Source - Files present in destination but not source  </li> <li>Size Mismatches - Files present in both but with different sizes</li> </ol>"},{"location":"python/system/compare_folders.html#comparison-logic","title":"Comparison Logic","text":"<ul> <li>Filename Matching - Compares files by relative path from root</li> <li>Size Comparison - Byte-perfect size matching</li> <li>Case Sensitivity - Respects filesystem case sensitivity rules</li> <li>Symbolic Links - Handles symlinks according to target filesystem</li> </ul>"},{"location":"python/system/compare_folders.html#output-formats","title":"Output Formats","text":""},{"location":"python/system/compare_folders.html#console-output","title":"Console Output","text":"<pre><code>Comparing directories:\n  Source:      /backup/photos\n  Destination: /archive/photos\n\nScanning directories...\nFound 1,250 files in source directory\nFound 1,180 files in destination directory\n\nCOMPARISON RESULTS:\n==================\n\nMissing in destination (70 files):\n  vacation2023/IMG_001.jpg (2.5 MB)\n  vacation2023/IMG_002.jpg (2.8 MB)\n  work/presentation.pptx (15.2 MB)\n  ...\n\nMissing in source (0 files):\n  (No files missing in source)\n\nSize mismatches (0 files):\n  (No size mismatches found)\n\nSUMMARY:\n========\nTotal files compared: 1,180\nFiles missing in destination: 70\nFiles missing in source: 0\nSize mismatches: 0\n</code></pre>"},{"location":"python/system/compare_folders.html#file-report","title":"File Report","text":"<p>When using <code>--output-file</code>, creates detailed reports with: - Complete file lists with full paths - File sizes and timestamps - Summary statistics - Recommended actions</p>"},{"location":"python/system/compare_folders.html#filtering-options","title":"Filtering Options","text":""},{"location":"python/system/compare_folders.html#file-extension-filtering","title":"File Extension Filtering","text":"<pre><code># Compare only video files\npython3 compareFolders.py /source /dest --filter-extension .mov\n\n# Compare only image files  \npython3 compareFolders.py /source /dest --filter-extension .jpg\n</code></pre>"},{"location":"python/system/compare_folders.html#size-based-filtering","title":"Size-Based Filtering","text":"<pre><code># Files larger than 100MB\npython3 compareFolders.py /source /dest --min-size 104857600\n\n# Files between 1MB and 1GB\npython3 compareFolders.py /source /dest \\\n    --min-size 1048576 \\\n    --max-size 1073741824\n</code></pre>"},{"location":"python/system/compare_folders.html#script-generation","title":"Script Generation","text":""},{"location":"python/system/compare_folders.html#copy-script-creation","title":"Copy Script Creation","text":"<p>The <code>--generate-script</code> option creates executable scripts to synchronize directories:</p> <pre><code>python3 compareFolders.py /source /dest --generate-script\n</code></pre> <p>Creates <code>sync_missing_files.py</code>: <pre><code>#!/usr/bin/env python3\n\"\"\"Auto-generated script to copy missing files.\"\"\"\nimport shutil\nimport os\n\ndef copy_missing_files():\n    # Copy missing files from source to destination\n    shutil.copy2(\"/source/file1.jpg\", \"/dest/file1.jpg\")\n    shutil.copy2(\"/source/file2.mov\", \"/dest/file2.mov\")\n    # ... more copy operations\n\nif __name__ == \"__main__\":\n    copy_missing_files()\n</code></pre></p>"},{"location":"python/system/compare_folders.html#examples","title":"Examples","text":""},{"location":"python/system/compare_folders.html#example-1-backup-validation","title":"Example 1: Backup Validation","text":"<pre><code># Verify backup completeness\npython3 compareFolders.py /home/user/documents /backup/documents \\\n    --recursive \\\n    --verbose \\\n    --output-file backup_validation.txt\n</code></pre>"},{"location":"python/system/compare_folders.html#example-2-media-archive-sync","title":"Example 2: Media Archive Sync","text":"<pre><code># Check video archive synchronization\npython3 compareFolders.py /production/footage /archive/footage \\\n    --filter-extension .mov \\\n    --recursive \\\n    --show-sizes \\\n    --generate-script\n</code></pre>"},{"location":"python/system/compare_folders.html#example-3-large-file-migration","title":"Example 3: Large File Migration","text":"<pre><code># Find large files that need migration\npython3 compareFolders.py /old_storage /new_storage \\\n    --min-size 1073741824 \\\n    --recursive \\\n    --verbose\n</code></pre>"},{"location":"python/system/compare_folders.html#example-4-incremental-backup-check","title":"Example 4: Incremental Backup Check","text":"<pre><code>#!/bin/bash\n# Daily backup verification script\n\nSOURCE=\"/home/user/projects\"\nBACKUP=\"/mnt/backup/projects\"\nREPORT=\"/var/log/backup_check_$(date +%Y%m%d).txt\"\n\necho \"Checking backup: $(date)\" &gt; \"$REPORT\"\n\npython3 compareFolders.py \"$SOURCE\" \"$BACKUP\" \\\n    --recursive \\\n    --output-file \"$REPORT\" \\\n    --verbose\n\nif [ $? -eq 0 ]; then\n    echo \"Backup check completed successfully\"\nelse\n    echo \"Backup check failed - see $REPORT\"\n    exit 1\nfi\n</code></pre>"},{"location":"python/system/compare_folders.html#performance-considerations","title":"Performance Considerations","text":""},{"location":"python/system/compare_folders.html#large-datasets","title":"Large Datasets","text":"<ul> <li>Memory Efficient - Processes files incrementally</li> <li>Progress Tracking - Real-time updates for long operations</li> <li>Interrupt Handling - Graceful handling of cancellation</li> <li>Resume Capability - Can restart interrupted comparisons</li> </ul>"},{"location":"python/system/compare_folders.html#network-filesystems","title":"Network Filesystems","text":"<ul> <li>Optimized I/O - Minimizes network filesystem calls</li> <li>Batch Operations - Groups filesystem operations efficiently</li> <li>Timeout Handling - Robust handling of slow network connections</li> <li>Cache Utilization - Leverages filesystem metadata caching</li> </ul>"},{"location":"python/system/compare_folders.html#integration","title":"Integration","text":""},{"location":"python/system/compare_folders.html#backup-scripts","title":"Backup Scripts","text":"<pre><code>import subprocess\nimport sys\nfrom pathlib import Path\n\ndef validate_backup(source, destination):\n    \"\"\"Validate backup completeness using compareFolders.\"\"\"\n    cmd = [\n        sys.executable, \"compareFolders.py\",\n        str(source), str(destination),\n        \"--recursive\", \"--verbose\"\n    ]\n\n    result = subprocess.run(cmd, capture_output=True, text=True)\n\n    if result.returncode == 0:\n        print(\"Backup validation successful\")\n        return True\n    else:\n        print(f\"Backup validation failed: {result.stderr}\")\n        return False\n\n# Usage\nif validate_backup(\"/home/user/docs\", \"/backup/docs\"):\n    print(\"Backup is complete and valid\")\nelse:\n    print(\"Backup needs attention\")\n</code></pre>"},{"location":"python/system/compare_folders.html#synchronization-workflow","title":"Synchronization Workflow","text":"<pre><code>#!/bin/bash\n# Complete synchronization workflow\n\nSOURCE_DIR=\"/production/assets\"\nDEST_DIR=\"/archive/assets\"\nREPORT_DIR=\"/var/log/sync\"\n\nmkdir -p \"$REPORT_DIR\"\nDATE=$(date +%Y%m%d_%H%M%S)\n\necho \"Starting synchronization analysis...\"\n\n# Generate comparison report\npython3 compareFolders.py \"$SOURCE_DIR\" \"$DEST_DIR\" \\\n    --recursive \\\n    --output-file \"$REPORT_DIR/comparison_$DATE.txt\" \\\n    --generate-script \\\n    --verbose\n\n# Review and execute sync script\nif [ -f sync_missing_files.py ]; then\n    echo \"Found missing files. Review sync script before execution:\"\n    echo \"python3 sync_missing_files.py\"\nelse\n    echo \"Directories are in sync\"\nfi\n</code></pre>"},{"location":"python/system/compare_folders.html#cicd-integration","title":"CI/CD Integration","text":"<pre><code># GitHub Actions workflow\nname: Backup Validation\non:\n  schedule:\n    - cron: '0 2 * * *'  # Daily at 2 AM\n\njobs:\n  validate-backup:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: Mount backup drive\n      run: sudo mount /dev/backup /mnt/backup\n\n    - name: Validate backup\n      run: |\n        python3 compareFolders.py /data /mnt/backup/data \\\n          --recursive \\\n          --output-file backup_report.txt\n\n    - name: Upload report\n      uses: actions/upload-artifact@v2\n      with:\n        name: backup-report\n        path: backup_report.txt\n</code></pre>"},{"location":"python/system/compare_folders.html#error-handling","title":"Error Handling","text":""},{"location":"python/system/compare_folders.html#common-issues","title":"Common Issues","text":"<p>Issue: Permission denied errors <pre><code># Fix file permissions\nchmod -R +r /source/directory\nchmod -R +r /destination/directory\n</code></pre></p> <p>Issue: \"Directory not found\" errors <pre><code># Verify paths exist and are accessible\nls -la /source/directory\nls -la /destination/directory\n</code></pre></p> <p>Issue: Out of memory with very large directories <pre><code># Use filtering to reduce memory usage\npython3 compareFolders.py /source /dest \\\n    --filter-extension .jpg \\\n    --recursive\n</code></pre></p>"},{"location":"python/system/compare_folders.html#debugging","title":"Debugging","text":"<p>Use verbose mode for detailed operation information:</p> <pre><code>python3 compareFolders.py /source /dest --verbose --recursive\n</code></pre> <p>This shows: - Directory scanning progress - File discovery statistics - Comparison operations - Any errors or warnings</p>"},{"location":"python/system/compare_folders.html#use-cases","title":"Use Cases","text":""},{"location":"python/system/compare_folders.html#data-migration","title":"Data Migration","text":"<ul> <li>Server Migration - Verify complete data transfer</li> <li>Storage Upgrade - Ensure all files copied correctly</li> <li>Cloud Migration - Validate cloud sync completeness</li> </ul>"},{"location":"python/system/compare_folders.html#backup-management","title":"Backup Management","text":"<ul> <li>Backup Verification - Regular backup completeness checks</li> <li>Incremental Validation - Verify incremental backup integrity</li> <li>Archive Maintenance - Ensure archive completeness</li> </ul>"},{"location":"python/system/compare_folders.html#synchronization","title":"Synchronization","text":"<ul> <li>Mirror Maintenance - Keep multiple copies synchronized</li> <li>Team Collaboration - Verify shared folder synchronization</li> <li>Distributed Storage - Maintain consistency across locations</li> </ul> <p>compareFolders.py provides comprehensive directory comparison with advanced filtering, performance optimization, and integration capabilities for backup validation and synchronization workflows.</p>"},{"location":"python/system/compare_sizes.html","title":"compareSizes.py","text":"<p>Compare file sizes or checksums between two directories for files with matching names, identifying corrupted or incomplete file copies with advanced verification options.</p>"},{"location":"python/system/compare_sizes.html#overview","title":"Overview","text":"<p>compareSizes.py is a powerful file integrity verification tool that compares files between two directories using either file sizes or cryptographic checksums. It's designed to identify corrupted files, incomplete transfers, and data integrity issues in backup and synchronization workflows.</p>"},{"location":"python/system/compare_sizes.html#features","title":"Features","text":"<ul> <li>Dual Verification Modes - File size comparison or cryptographic checksum validation</li> <li>Multiple Hash Algorithms - Blake2b, SHA256, MD5, and SHA1 support</li> <li>Progress Tracking - Real-time progress bars for large operations</li> <li>Automatic Script Generation - Creates copy scripts to fix mismatches</li> <li>Comprehensive Reporting - Detailed mismatch reports with statistics</li> <li>Performance Optimized - Efficient handling of large file sets</li> <li>Security Hardened - Uses modern, secure hash algorithms by default</li> </ul>"},{"location":"python/system/compare_sizes.html#usage","title":"Usage","text":""},{"location":"python/system/compare_sizes.html#basic-usage","title":"Basic Usage","text":"<pre><code># Basic size comparison\npython3 compareSizes.py /source/dir /dest/dir\n\n# Compare only specific file types\npython3 compareSizes.py /source/dir /dest/dir --filter .mov\n\n# Use checksum comparison (more accurate but slower)\npython3 compareSizes.py /source/dir /dest/dir --checksum\n</code></pre>"},{"location":"python/system/compare_sizes.html#advanced-usage","title":"Advanced Usage","text":"<pre><code># Use different hash algorithm\npython3 compareSizes.py /source/dir /dest/dir \\\n    --checksum \\\n    --hash-algorithm sha256\n\n# Generate script to fix mismatches\npython3 compareSizes.py /source/dir /dest/dir \\\n    --generate-script\n\n# Save detailed report and show verbose output\npython3 compareSizes.py /source/dir /dest/dir \\\n    --output report.txt \\\n    --verbose\n</code></pre>"},{"location":"python/system/compare_sizes.html#command-line-options","title":"Command-Line Options","text":"Option Short Description Default <code>source_dir</code> - Source directory (copied from) Required <code>dest_dir</code> - Destination directory (copied to) Required <code>--filter</code> <code>-f</code> File extension filter (e.g., .mov, .txt, .jpg) None <code>--checksum</code> - Use checksum comparison instead of file size False <code>--hash-algorithm</code> - Hash algorithm for checksum comparison <code>blake2b</code> <code>--generate-script</code> - Generate Python script to copy mismatched files False <code>--output</code> <code>-o</code> Output file for detailed mismatch report None <code>--verbose</code> <code>-v</code> Show detailed output including file paths False"},{"location":"python/system/compare_sizes.html#comparison-modes","title":"Comparison Modes","text":""},{"location":"python/system/compare_sizes.html#size-comparison-default","title":"Size Comparison (Default)","text":"<p>Fast comparison using file sizes only: - Speed - Very fast, no file content reading required - Accuracy - Good for detecting truncated or incomplete files - Use Case - Initial validation, large dataset screening</p>"},{"location":"python/system/compare_sizes.html#checksum-comparison-checksum","title":"Checksum Comparison (--checksum)","text":"<p>Cryptographic comparison using file content hashes: - Speed - Slower, requires reading entire file contents - Accuracy - Detects any content differences, even same-size corruption - Use Case - Critical data validation, final verification</p>"},{"location":"python/system/compare_sizes.html#hash-algorithms","title":"Hash Algorithms","text":""},{"location":"python/system/compare_sizes.html#available-algorithms","title":"Available Algorithms","text":"Algorithm Speed Security Use Case <code>blake2b</code> Fast High General purpose (default) <code>sha256</code> Medium High Standards compliance <code>md5</code> Very Fast Low Legacy compatibility only <code>sha1</code> Fast Medium Legacy systems"},{"location":"python/system/compare_sizes.html#algorithm-selection","title":"Algorithm Selection","text":"<pre><code># High security validation\npython3 compareSizes.py /source /dest --checksum --hash-algorithm sha256\n\n# Fast validation for large datasets\npython3 compareSizes.py /source /dest --checksum --hash-algorithm blake2b\n\n# Legacy system compatibility\npython3 compareSizes.py /source /dest --checksum --hash-algorithm md5\n</code></pre>"},{"location":"python/system/compare_sizes.html#output-formats","title":"Output Formats","text":""},{"location":"python/system/compare_sizes.html#console-output","title":"Console Output","text":"<pre><code>Comparing directories:\n  Source:      /backup/media\n  Destination: /archive/media\n  Filter:      .mov\n\nScanning: /backup/media\nFound 150 files in source directory\n\nScanning: /archive/media\nFound 148 files in destination directory\n\nFound 148 files with matching names\nUsing file size comparison\n\n\u26a0 Found 3 mismatches:\n\nFile: movie_001.mov\n  Source size:      2,847,392,816 bytes\n  Destination size: 2,847,392,000 bytes\n\nFile: movie_002.mov\n  Source size:      1,954,725,632 bytes\n  Destination size: 1,954,720,000 bytes\n\nFile: movie_003.mov\n  Source size:      3,247,891,456 bytes\n  Destination size: 3,247,891,456 bytes\n\n========================================\nSUMMARY:\n  Files compared: 148\n  Mismatches:     3\n  Success rate:   97.9%\n</code></pre>"},{"location":"python/system/compare_sizes.html#checksum-output","title":"Checksum Output","text":"<pre><code>WARNING: Checksum comparison can be very slow for large files!\nConsider testing with a small subset first.\n\nComparing directories:\n  Source:      /important/docs\n  Destination: /backup/docs\n\nUsing blake2b checksum comparison (this may take a while...)\nComparing files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1250/1250 [02:15&lt;00:00,  9.23it/s]\n\n\u26a0 Found 2 mismatches:\n\nFile: document.pdf\n  Source checksum:      a1b2c3d4e5f6...\n  Destination checksum: f6e5d4c3b2a1...\n\nFile: spreadsheet.xlsx\n  Source checksum:      123456789abc...\n  Destination checksum: cba987654321...\n</code></pre>"},{"location":"python/system/compare_sizes.html#script-generation","title":"Script Generation","text":""},{"location":"python/system/compare_sizes.html#automatic-fix-scripts","title":"Automatic Fix Scripts","text":"<p>The <code>--generate-script</code> option creates executable Python scripts to fix mismatches:</p> <pre><code>python3 compareSizes.py /source /dest --generate-script\n</code></pre> <p>Creates <code>fix_mismatches.py</code>: <pre><code>#!/usr/bin/env python3\n\"\"\"Auto-generated script to fix file mismatches.\"\"\"\nimport shutil\nimport os\n\ndef copy_file_with_backup(src, dst):\n    \"\"\"Copy file with backup of existing destination.\"\"\"\n    if os.path.exists(dst):\n        backup_path = dst + '.backup'\n        shutil.copy2(dst, backup_path)\n        print(f\"Backed up {dst} to {backup_path}\")\n\n    shutil.copy2(src, dst)\n    print(f\"Copied {src} to {dst}\")\n\ndef main():\n    print(\"Fixing 3 mismatched files...\")\n\n    # movie_001.mov\n    copy_file_with_backup(r\"/source/movie_001.mov\", r\"/dest/movie_001.mov\")\n\n    # movie_002.mov\n    copy_file_with_backup(r\"/source/movie_002.mov\", r\"/dest/movie_002.mov\")\n\n    print(\"All files copied successfully!\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre></p>"},{"location":"python/system/compare_sizes.html#examples","title":"Examples","text":""},{"location":"python/system/compare_sizes.html#example-1-media-archive-validation","title":"Example 1: Media Archive Validation","text":"<pre><code># Validate video archive integrity\npython3 compareSizes.py /production/footage /archive/footage \\\n    --filter .mov \\\n    --verbose \\\n    --output archive_validation.txt\n</code></pre>"},{"location":"python/system/compare_sizes.html#example-2-critical-data-verification","title":"Example 2: Critical Data Verification","text":"<pre><code># High-security checksum validation\npython3 compareSizes.py /sensitive/data /backup/data \\\n    --checksum \\\n    --hash-algorithm sha256 \\\n    --generate-script\n</code></pre>"},{"location":"python/system/compare_sizes.html#example-3-incremental-backup-check","title":"Example 3: Incremental Backup Check","text":"<pre><code>#!/bin/bash\n# Daily backup integrity check\n\nSOURCE=\"/home/user/documents\"\nBACKUP=\"/mnt/backup/documents\" \nREPORT=\"/var/log/backup_integrity_$(date +%Y%m%d).txt\"\n\necho \"Checking backup integrity: $(date)\" | tee \"$REPORT\"\n\npython3 compareSizes.py \"$SOURCE\" \"$BACKUP\" \\\n    --output \"$REPORT\" \\\n    --verbose\n\nif [ $? -eq 0 ]; then\n    echo \"Backup integrity check passed\" | tee -a \"$REPORT\"\nelse\n    echo \"Backup integrity issues found\" | tee -a \"$REPORT\"\n    # Send alert email\n    mail -s \"Backup Integrity Alert\" admin@company.com &lt; \"$REPORT\"\nfi\n</code></pre>"},{"location":"python/system/compare_sizes.html#example-4-large-dataset-screening","title":"Example 4: Large Dataset Screening","text":"<pre><code># Fast screening of large video archive\npython3 compareSizes.py /terabyte/archive /mirror/archive \\\n    --filter .mov \\\n    --verbose\n\n# Follow up with checksum validation for mismatches only\nif [ $? -ne 0 ]; then\n    echo \"Size mismatches found. Running checksum validation...\"\n    python3 compareSizes.py /terabyte/archive /mirror/archive \\\n        --filter .mov \\\n        --checksum \\\n        --hash-algorithm blake2b\nfi\n</code></pre>"},{"location":"python/system/compare_sizes.html#performance-optimization","title":"Performance Optimization","text":""},{"location":"python/system/compare_sizes.html#large-file-handling","title":"Large File Handling","text":"<ul> <li>Progress Bars - Visual feedback for long operations using tqdm</li> <li>Streaming Hashes - Memory-efficient hash calculation</li> <li>Interrupt Handling - Graceful cancellation with Ctrl+C</li> <li>Resume Capability - Can restart interrupted operations</li> </ul>"},{"location":"python/system/compare_sizes.html#memory-management","title":"Memory Management","text":"<pre><code># Internal optimization features:\n# - Files processed one at a time\n# - Hash calculations use streaming approach\n# - Memory usage independent of file size\n# - Efficient directory scanning\n</code></pre>"},{"location":"python/system/compare_sizes.html#network-filesystems","title":"Network Filesystems","text":"<ul> <li>Batch Operations - Reduces network round trips</li> <li>Metadata Caching - Leverages filesystem caching</li> <li>Error Recovery - Handles network timeouts gracefully</li> </ul>"},{"location":"python/system/compare_sizes.html#integration","title":"Integration","text":""},{"location":"python/system/compare_sizes.html#backup-validation-workflow","title":"Backup Validation Workflow","text":"<pre><code>import subprocess\nimport sys\n\ndef validate_backup_integrity(source, destination, use_checksum=False):\n    \"\"\"Validate backup using compareSizes script.\"\"\"\n    cmd = [\n        sys.executable, \"compareSizes.py\",\n        source, destination\n    ]\n\n    if use_checksum:\n        cmd.extend([\"--checksum\", \"--hash-algorithm\", \"blake2b\"])\n\n    cmd.extend([\"--verbose\"])\n\n    result = subprocess.run(cmd, capture_output=True, text=True)\n\n    return {\n        'success': result.returncode == 0,\n        'output': result.stdout,\n        'errors': result.stderr\n    }\n\n# Usage\nresult = validate_backup_integrity(\"/data\", \"/backup\", use_checksum=True)\nif result['success']:\n    print(\"Backup validation passed\")\nelse:\n    print(f\"Backup validation failed: {result['errors']}\")\n</code></pre>"},{"location":"python/system/compare_sizes.html#cicd-pipeline-integration","title":"CI/CD Pipeline Integration","text":"<pre><code># GitHub Actions example\nname: Data Integrity Check\non:\n  schedule:\n    - cron: '0 3 * * *'  # Daily at 3 AM\n\njobs:\n  integrity-check:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: Mount storage\n      run: |\n        sudo mount /dev/storage1 /mnt/primary\n        sudo mount /dev/storage2 /mnt/backup\n\n    - name: Size comparison check\n      run: |\n        python3 compareSizes.py /mnt/primary /mnt/backup \\\n          --output size_check.txt \\\n          --verbose\n\n    - name: Checksum verification (if size mismatches found)\n      if: failure()\n      run: |\n        python3 compareSizes.py /mnt/primary /mnt/backup \\\n          --checksum \\\n          --hash-algorithm sha256 \\\n          --output checksum_check.txt \\\n          --generate-script\n\n    - name: Upload reports\n      uses: actions/upload-artifact@v2\n      with:\n        name: integrity-reports\n        path: \"*.txt\"\n</code></pre>"},{"location":"python/system/compare_sizes.html#production-monitoring","title":"Production Monitoring","text":"<pre><code>#!/bin/bash\n# Production data integrity monitoring\n\nENVIRONMENTS=(\"staging\" \"production\" \"backup\")\nREPORT_DIR=\"/var/log/integrity_checks\"\nDATE=$(date +%Y%m%d_%H%M%S)\n\nmkdir -p \"$REPORT_DIR\"\n\nfor env in \"${ENVIRONMENTS[@]}\"; do\n    echo \"Checking $env environment...\"\n\n    SOURCE=\"/data/$env\"\n    MIRROR=\"/mirrors/$env\"\n    REPORT=\"$REPORT_DIR/${env}_integrity_$DATE.txt\"\n\n    # Fast size check first\n    if python3 compareSizes.py \"$SOURCE\" \"$MIRROR\" \\\n        --output \"$REPORT\" \\\n        --verbose; then\n        echo \"$env: PASS - No integrity issues\"\n    else\n        echo \"$env: FAIL - Integrity issues detected\"\n\n        # Detailed checksum analysis\n        python3 compareSizes.py \"$SOURCE\" \"$MIRROR\" \\\n            --checksum \\\n            --hash-algorithm blake2b \\\n            --output \"${REPORT%.txt}_detailed.txt\" \\\n            --generate-script\n\n        # Alert operations team\n        echo \"Integrity issues in $env environment\" | \\\n            mail -s \"Data Integrity Alert: $env\" ops-team@company.com \\\n            -A \"$REPORT\"\n    fi\ndone\n</code></pre>"},{"location":"python/system/compare_sizes.html#error-handling","title":"Error Handling","text":""},{"location":"python/system/compare_sizes.html#common-issues","title":"Common Issues","text":"<p>Issue: \"No matching filenames found\" <pre><code>Solution: Check that both directories contain files with the same names\n- Verify directory paths are correct\n- Check if files have been renamed\n- Use --verbose to see discovered files\n</code></pre></p> <p>Issue: Very slow checksum comparison <pre><code>Solution: Optimize hash algorithm choice\npython3 compareSizes.py /source /dest --checksum --hash-algorithm blake2b\n</code></pre></p> <p>Issue: Out of memory with large files <pre><code>Solution: The script uses streaming hash calculation, but if issues persist:\n- Check available system memory\n- Process smaller subsets using --filter\n- Monitor system resources during operation\n</code></pre></p>"},{"location":"python/system/compare_sizes.html#debugging","title":"Debugging","text":"<p>Use verbose mode for detailed operation information:</p> <pre><code>python3 compareSizes.py /source /dest --verbose --checksum\n</code></pre> <p>This shows: - Directory scanning progress - File matching statistics - Hash calculation progress - Detailed mismatch information</p>"},{"location":"python/system/compare_sizes.html#best-practices","title":"Best Practices","text":""},{"location":"python/system/compare_sizes.html#validation-strategy","title":"Validation Strategy","text":"<ol> <li>Tiered Approach - Start with size comparison, then checksum critical files</li> <li>Regular Checks - Schedule periodic integrity validation</li> <li>Documentation - Keep logs of validation results</li> <li>Automation - Integrate into backup and sync workflows</li> </ol>"},{"location":"python/system/compare_sizes.html#algorithm-selection_1","title":"Algorithm Selection","text":"<ol> <li>Blake2b - Best general-purpose choice (fast + secure)</li> <li>SHA256 - Use for compliance or interoperability requirements</li> <li>MD5 - Only for legacy system compatibility</li> <li>SHA1 - Avoid for new implementations (security concerns)</li> </ol>"},{"location":"python/system/compare_sizes.html#performance-tuning","title":"Performance Tuning","text":"<ol> <li>Filter Usage - Use file filters to reduce dataset size</li> <li>Progress Monitoring - Use verbose mode for long operations</li> <li>Resource Planning - Account for CPU/I/O intensive operations</li> <li>Network Considerations - Plan for bandwidth usage with checksums</li> </ol> <p>compareSizes.py provides comprehensive file integrity verification with multiple validation modes, modern hash algorithms, and automated fixing capabilities for data validation workflows.</p>"},{"location":"python/system/duplicate_folder_structure.html","title":"duplicate_folder_structure.py","text":"<p>Modern Python tool for duplicating directory structures without copying files. Creates an exact replica of folder hierarchies while preserving the complete directory tree structure.</p>"},{"location":"python/system/duplicate_folder_structure.html#overview","title":"Overview","text":"<p>duplicate_folder_structure.py creates a complete copy of a directory tree structure without copying any files. This is useful for creating template directory structures, preparing backup locations, or setting up parallel folder hierarchies for different purposes.</p> <p>I created both a Python and Shell version since they serve slightly different use cases:</p> <ul> <li>Python version (duplicate_folder_structure.py): For integration into Python workflows, with advanced features like progress tracking and flexible configuration</li> <li>Shell version (duplicate_folder_structure.sh): For quick command-line use and shell scripting integration</li> </ul>"},{"location":"python/system/duplicate_folder_structure.html#features","title":"Features","text":"<ul> <li>Structure-Only Duplication - Copies directory hierarchy without any files</li> <li>Flexible Naming - Automatic destination generation with suffix/prefix options  </li> <li>Safety Features - Dry-run mode, path validation, and confirmation prompts</li> <li>Progress Tracking - Real-time progress display for large directory trees</li> <li>Error Handling - Comprehensive error reporting and recovery</li> <li>Cross-Platform - Works on macOS, Linux, and Windows</li> <li>Performance Optimized - Efficient processing of large directory structures</li> </ul>"},{"location":"python/system/duplicate_folder_structure.html#usage","title":"Usage","text":""},{"location":"python/system/duplicate_folder_structure.html#basic-usage","title":"Basic Usage","text":"<pre><code># Duplicate structure to specific destination\npython3 duplicate_folder_structure.py /source/project /backup/structure\n\n# Generate destination with suffix\npython3 duplicate_folder_structure.py /project --suffix \"_backup\"\n\n# Generate destination with prefix  \npython3 duplicate_folder_structure.py /data --prefix \"structure_\"\n\n# Dry-run to preview what would be created\npython3 duplicate_folder_structure.py /source /dest --dry-run\n</code></pre>"},{"location":"python/system/duplicate_folder_structure.html#advanced-usage","title":"Advanced Usage","text":"<pre><code># Verbose output with detailed progress\npython3 duplicate_folder_structure.py /large/project /backup --verbose\n\n# Skip confirmation prompts\npython3 duplicate_folder_structure.py /source /dest --force\n\n# Combine options for automated workflows\npython3 duplicate_folder_structure.py /project \\\n    --suffix \"_template\" \\\n    --verbose \\\n    --force\n</code></pre>"},{"location":"python/system/duplicate_folder_structure.html#command-line-options","title":"Command-Line Options","text":"Option Short Description Default <code>source</code> - Source directory to duplicate structure from Required <code>destination</code> - Destination directory (optional with --suffix/--prefix) None <code>--suffix</code> - Add suffix to source directory name for destination None <code>--prefix</code> - Add prefix to source directory name for destination None <code>--dry-run</code> - Show what would be done without making changes False <code>--verbose</code> <code>-v</code> Show detailed output and progress False <code>--force</code> - Skip confirmation prompts False"},{"location":"python/system/duplicate_folder_structure.html#examples","title":"Examples","text":""},{"location":"python/system/duplicate_folder_structure.html#example-1-project-template-creation","title":"Example 1: Project Template Creation","text":"<pre><code># Create a template structure for new projects\npython3 duplicate_folder_structure.py /master/project_template /new/client_project --verbose\n\n# Result: All directories from project_template are created in client_project\n# Files are not copied, leaving clean directory structure\n</code></pre>"},{"location":"python/system/duplicate_folder_structure.html#example-2-backup-structure-preparation","title":"Example 2: Backup Structure Preparation","text":"<pre><code># Prepare backup directory structure\npython3 duplicate_folder_structure.py /important/data --suffix \"_backup_structure\"\n\n# Creates: /important/data_backup_structure/\n# With all subdirectories from /important/data/ but no files\n</code></pre>"},{"location":"python/system/duplicate_folder_structure.html#example-3-parallel-environment-setup","title":"Example 3: Parallel Environment Setup","text":"<pre><code># Set up development, staging, and production structures\npython3 duplicate_folder_structure.py /app/production --prefix \"dev_\" --force\npython3 duplicate_folder_structure.py /app/production --prefix \"staging_\" --force\n\n# Creates parallel directory structures for different environments\n</code></pre>"},{"location":"python/system/duplicate_folder_structure.html#example-4-large-directory-tree-processing","title":"Example 4: Large Directory Tree Processing","text":"<pre><code># Process large directory with progress tracking\npython3 duplicate_folder_structure.py /massive/dataset /backup/structure \\\n    --verbose \\\n    --dry-run\n\n# Review output, then execute:\npython3 duplicate_folder_structure.py /massive/dataset /backup/structure --verbose\n</code></pre>"},{"location":"python/system/duplicate_folder_structure.html#advanced-features","title":"Advanced Features","text":""},{"location":"python/system/duplicate_folder_structure.html#automatic-path-generation","title":"Automatic Path Generation","text":"<p>The tool can automatically generate destination paths using patterns:</p> <pre><code># Suffix generation\npython3 duplicate_folder_structure.py /project --suffix \"_folders\"\n# Creates: /project_folders/\n\n# Prefix generation  \npython3 duplicate_folder_structure.py /data --prefix \"structure_\"\n# Creates: /structure_data/\n\n# Default generation (if no suffix/prefix specified with explicit destination)\npython3 duplicate_folder_structure.py /source\n# Would create: /source_structure/ (but requires confirmation)\n</code></pre>"},{"location":"python/system/duplicate_folder_structure.html#path-validation-and-safety","title":"Path Validation and Safety","text":"<p>The tool includes comprehensive safety checks:</p> <pre><code># Prevents dangerous operations\nduplicate_folder_structure.py / /backup           # Error: Critical path\nduplicate_folder_structure.py /source /source     # Error: Same path  \nduplicate_folder_structure.py /parent /parent/sub # Error: Destination inside source\n</code></pre>"},{"location":"python/system/duplicate_folder_structure.html#progress-tracking-for-large-operations","title":"Progress Tracking for Large Operations","text":"<p>For directories with many subdirectories, the tool provides progress feedback:</p> <pre><code>Found 1,247 directories to duplicate\n\nCreating directory structure in: /backup/structure\n==================================================\nCreated: /backup/structure/subdir1\nCreated: /backup/structure/subdir1/nested\nCreated: /backup/structure/subdir2\n...\n\n==================================================\nOPERATION SUMMARY:\nDirectories created: 1,247\nDirectories already existing: 0\nNo errors encountered\nSource: /source/project\nDestination: /backup/structure\nOperation completed in 2.34 seconds\n</code></pre>"},{"location":"python/system/duplicate_folder_structure.html#integration-examples","title":"Integration Examples","text":""},{"location":"python/system/duplicate_folder_structure.html#python-script-integration","title":"Python Script Integration","text":"<pre><code>import subprocess\nimport sys\nfrom pathlib import Path\n\nclass StructureDuplicator:\n    def __init__(self, script_path=\"duplicate_folder_structure.py\"):\n        self.script_path = script_path\n\n    def duplicate_structure(self, source, destination, dry_run=False, verbose=False):\n        \"\"\"Duplicate directory structure programmatically.\"\"\"\n        cmd = [sys.executable, self.script_path, str(source), str(destination)]\n\n        if dry_run:\n            cmd.append(\"--dry-run\")\n        if verbose:\n            cmd.append(\"--verbose\")\n\n        # Always use --force for programmatic calls\n        cmd.append(\"--force\")\n\n        result = subprocess.run(cmd, capture_output=True, text=True)\n\n        return {\n            'success': result.returncode == 0,\n            'output': result.stdout,\n            'errors': result.stderr\n        }\n\n    def create_template_structure(self, template_dir, new_project_dir):\n        \"\"\"Create new project from template structure.\"\"\"\n        print(f\"Creating project structure from template: {template_dir}\")\n\n        # First, dry-run to check\n        result = self.duplicate_structure(template_dir, new_project_dir, dry_run=True)\n\n        if result['success']:\n            print(\"Template structure validated. Creating directories...\")\n            # Execute the duplication\n            result = self.duplicate_structure(template_dir, new_project_dir, verbose=True)\n\n            if result['success']:\n                print(f\"\u2713 Project structure created: {new_project_dir}\")\n                return True\n            else:\n                print(f\"\u2717 Failed to create structure: {result['errors']}\")\n                return False\n        else:\n            print(f\"\u2717 Template validation failed: {result['errors']}\")\n            return False\n\n# Usage\nduplicator = StructureDuplicator()\nduplicator.create_template_structure(\"/templates/web_app\", \"/projects/new_client\")\n</code></pre>"},{"location":"python/system/duplicate_folder_structure.html#automated-workflow-integration","title":"Automated Workflow Integration","text":"<pre><code>#!/bin/bash\n# Project setup automation script\n\nPROJECT_TEMPLATE=\"/templates/standard_project\"\nCLIENT_NAME=\"$1\"\nPROJECT_BASE=\"/projects\"\n\nif [[ -z \"$CLIENT_NAME\" ]]; then\n    echo \"Usage: $0 &lt;client_name&gt;\"\n    exit 1\nfi\n\nNEW_PROJECT=\"${PROJECT_BASE}/${CLIENT_NAME}\"\n\necho \"Setting up new project for: $CLIENT_NAME\"\n\n# Create directory structure\npython3 duplicate_folder_structure.py \"$PROJECT_TEMPLATE\" \"$NEW_PROJECT\" --verbose --force\n\nif [[ $? -eq 0 ]]; then\n    echo \"\u2713 Directory structure created\"\n\n    # Additional setup steps\n    echo \"Setting up configuration files...\"\n    cp \"$PROJECT_TEMPLATE/config.template\" \"$NEW_PROJECT/config.ini\"\n\n    # Set permissions\n    chmod -R 755 \"$NEW_PROJECT\"\n\n    echo \"\u2713 Project setup complete: $NEW_PROJECT\"\nelse\n    echo \"\u2717 Failed to create project structure\"\n    exit 1\nfi\n</code></pre>"},{"location":"python/system/duplicate_folder_structure.html#backup-preparation-workflow","title":"Backup Preparation Workflow","text":"<pre><code>#!/usr/bin/env python3\n\"\"\"\nBackup structure preparation script\nCreates empty directory structures for organized backups\n\"\"\"\n\nimport argparse\nimport sys\nfrom pathlib import Path\nimport subprocess\nfrom datetime import datetime\n\ndef prepare_backup_structures(source_dirs, backup_base):\n    \"\"\"Prepare backup directory structures for multiple source directories.\"\"\"\n\n    backup_base = Path(backup_base)\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n    success_count = 0\n    failure_count = 0\n\n    for source in source_dirs:\n        source_path = Path(source)\n        if not source_path.exists():\n            print(f\"\u2717 Source does not exist: {source}\")\n            failure_count += 1\n            continue\n\n        # Create timestamped backup structure\n        backup_dest = backup_base / f\"{source_path.name}_{timestamp}\"\n\n        print(f\"Preparing backup structure: {source_path.name}\")\n\n        # Use duplicate_folder_structure.py\n        cmd = [\n            sys.executable, \"duplicate_folder_structure.py\",\n            str(source_path), str(backup_dest),\n            \"--verbose\", \"--force\"\n        ]\n\n        result = subprocess.run(cmd, capture_output=True, text=True)\n\n        if result.returncode == 0:\n            print(f\"\u2713 Structure prepared: {backup_dest}\")\n            success_count += 1\n        else:\n            print(f\"\u2717 Failed: {source_path.name}\")\n            print(f\"  Error: {result.stderr}\")\n            failure_count += 1\n\n    print(f\"\\nSummary: {success_count} successful, {failure_count} failed\")\n    return failure_count == 0\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"Prepare backup directory structures\")\n    parser.add_argument(\"sources\", nargs=\"+\", help=\"Source directories\")\n    parser.add_argument(\"--backup-base\", required=True, help=\"Base backup directory\")\n\n    args = parser.parse_args()\n\n    if prepare_backup_structures(args.sources, args.backup_base):\n        print(\"All backup structures prepared successfully\")\n        sys.exit(0)\n    else:\n        print(\"Some operations failed\")\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()\n\n# Usage:\n# python3 backup_prep.py /home/user /var/www /opt/apps --backup-base /backup/structures\n</code></pre>"},{"location":"python/system/duplicate_folder_structure.html#error-handling-and-recovery","title":"Error Handling and Recovery","text":""},{"location":"python/system/duplicate_folder_structure.html#comprehensive-error-handling","title":"Comprehensive Error Handling","text":"<p>The tool includes robust error handling for common scenarios:</p> <pre><code># Invalid source directory\npython3 duplicate_folder_structure.py /nonexistent /dest\n# Error: Source directory does not exist: /nonexistent\n\n# Source is not a directory\npython3 duplicate_folder_structure.py /etc/passwd /dest  \n# Error: Source is not a directory: /etc/passwd\n\n# Destination inside source (prevents infinite recursion)\npython3 duplicate_folder_structure.py /parent /parent/child\n# Error: Destination cannot be inside source directory\n\n# Permission issues\npython3 duplicate_folder_structure.py /restricted /dest\n# Error: Permission denied accessing: /restricted/private\n</code></pre>"},{"location":"python/system/duplicate_folder_structure.html#recovery-and-cleanup","title":"Recovery and Cleanup","text":"<pre><code># Example recovery script for partial failures\nimport shutil\nfrom pathlib import Path\n\ndef cleanup_partial_structure(failed_destination):\n    \"\"\"Clean up partially created structure after failure.\"\"\"\n    dest_path = Path(failed_destination)\n\n    if dest_path.exists() and dest_path.is_dir():\n        # Check if directory is empty or only contains empty subdirectories\n        if is_empty_structure(dest_path):\n            print(f\"Cleaning up partial structure: {dest_path}\")\n            shutil.rmtree(dest_path)\n            return True\n\n    return False\n\ndef is_empty_structure(directory):\n    \"\"\"Check if directory structure contains only empty directories.\"\"\"\n    for item in directory.rglob('*'):\n        if item.is_file():\n            return False  # Found a file\n    return True\n\n# Usage after failed operation\ncleanup_partial_structure(\"/failed/backup/structure\")\n</code></pre>"},{"location":"python/system/duplicate_folder_structure.html#performance-considerations","title":"Performance Considerations","text":""},{"location":"python/system/duplicate_folder_structure.html#optimization-for-large-directory-trees","title":"Optimization for Large Directory Trees","text":"<pre><code># For very large directory structures, use verbose mode to track progress\npython3 duplicate_folder_structure.py /massive/dataset /backup \\\n    --verbose \\\n    2&gt;&amp;1 | tee duplication.log\n\n# Monitor system resources during operation\n# The tool is memory-efficient and processes directories incrementally\n</code></pre>"},{"location":"python/system/duplicate_folder_structure.html#benchmarking-and-performance","title":"Benchmarking and Performance","text":"<pre><code>#!/usr/bin/env python3\n\"\"\"Benchmark duplicate_folder_structure.py performance\"\"\"\n\nimport time\nimport subprocess\nimport sys\nfrom pathlib import Path\n\ndef benchmark_duplication(source, destination_base, iterations=3):\n    \"\"\"Benchmark directory structure duplication.\"\"\"\n\n    times = []\n\n    for i in range(iterations):\n        dest = f\"{destination_base}_test_{i}\"\n\n        # Clean up any existing destination\n        if Path(dest).exists():\n            shutil.rmtree(dest)\n\n        start_time = time.time()\n\n        result = subprocess.run([\n            sys.executable, \"duplicate_folder_structure.py\",\n            source, dest, \"--force\"\n        ], capture_output=True)\n\n        end_time = time.time()\n\n        if result.returncode == 0:\n            duration = end_time - start_time\n            times.append(duration)\n            print(f\"Iteration {i+1}: {duration:.2f} seconds\")\n        else:\n            print(f\"Iteration {i+1}: FAILED\")\n\n    if times:\n        avg_time = sum(times) / len(times)\n        print(f\"Average time: {avg_time:.2f} seconds\")\n        return avg_time\n\n    return None\n\n# Usage\nbenchmark_duplication(\"/large/source\", \"/tmp/benchmark\")\n</code></pre>"},{"location":"python/system/duplicate_folder_structure.html#best-practices","title":"Best Practices","text":""},{"location":"python/system/duplicate_folder_structure.html#directory-structure-planning","title":"Directory Structure Planning","text":"<ol> <li>Test First - Always use <code>--dry-run</code> to preview operations</li> <li>Use Descriptive Names - Choose clear suffix/prefix patterns  </li> <li>Validate Paths - Ensure source paths are correct before execution</li> <li>Check Permissions - Verify write access to destination areas</li> </ol>"},{"location":"python/system/duplicate_folder_structure.html#automation-integration","title":"Automation Integration","text":"<ol> <li>Use --force Flag - For automated scripts to skip prompts</li> <li>Capture Output - Log operations for audit trails</li> <li>Error Handling - Check return codes and handle failures</li> <li>Progress Monitoring - Use verbose mode for long operations</li> </ol>"},{"location":"python/system/duplicate_folder_structure.html#safety-procedures","title":"Safety Procedures","text":"<ol> <li>Backup Important Paths - Don't duplicate over critical directories</li> <li>Test on Copies - Test with non-critical data first</li> <li>Monitor Disk Space - Ensure adequate space for new structures</li> <li>Document Operations - Keep records of structure duplications</li> </ol> <p>duplicate_folder_structure.py provides efficient, safe directory structure duplication with comprehensive features for template creation, backup preparation, and parallel environment setup workflows.</p>"},{"location":"python/system/fix_symlinks.html","title":"fix_symlinks.py","text":"<p>Intelligent symlink repair and validation tool with comprehensive analysis, automatic fixing, and safety features for maintaining symlink integrity across filesystems.</p>"},{"location":"python/system/fix_symlinks.html#overview","title":"Overview","text":"<p>fix_symlinks.py is a robust tool for managing symbolic links in complex directory structures. It identifies broken symlinks, analyzes link patterns, and provides both automated and manual repair options with comprehensive safety features and detailed reporting.</p>"},{"location":"python/system/fix_symlinks.html#features","title":"Features","text":"<ul> <li>Comprehensive Analysis - Scans directory trees for all symlink types</li> <li>Broken Link Detection - Identifies symlinks with missing targets</li> <li>Intelligent Repair - Attempts to locate moved targets automatically</li> <li>Safety Features - Dry-run mode and backup creation</li> <li>Detailed Reporting - Comprehensive analysis and repair reports</li> <li>Performance Optimized - Efficient handling of large directory structures</li> <li>Cross-Platform - Works on Unix-like systems with symlink support</li> </ul>"},{"location":"python/system/fix_symlinks.html#usage","title":"Usage","text":""},{"location":"python/system/fix_symlinks.html#basic-usage","title":"Basic Usage","text":"<pre><code># Scan for broken symlinks\npython3 fix_symlinks.py /path/to/scan\n\n# Fix broken symlinks with dry-run first\npython3 fix_symlinks.py /path/to/scan --dry-run\npython3 fix_symlinks.py /path/to/scan --fix\n\n# Recursive scan with verbose output\npython3 fix_symlinks.py /path/to/scan --recursive --verbose\n</code></pre>"},{"location":"python/system/fix_symlinks.html#advanced-usage","title":"Advanced Usage","text":"<pre><code># Create backups before fixing\npython3 fix_symlinks.py /path/to/scan \\\n    --fix \\\n    --backup \\\n    --recursive\n\n# Generate repair script for manual review\npython3 fix_symlinks.py /path/to/scan \\\n    --generate-script \\\n    --output-file repair_script.py\n\n# Detailed analysis with report\npython3 fix_symlinks.py /path/to/scan \\\n    --recursive \\\n    --report-file symlink_analysis.txt \\\n    --verbose\n</code></pre>"},{"location":"python/system/fix_symlinks.html#command-line-options","title":"Command-Line Options","text":"Option Short Description Default <code>path</code> - Directory path to scan for symlinks Required <code>--recursive</code> <code>-r</code> Scan directories recursively False <code>--fix</code> - Attempt to fix broken symlinks False <code>--dry-run</code> - Show what would be done without making changes False <code>--backup</code> - Create backups before modifying symlinks False <code>--generate-script</code> - Generate Python script for manual fixes False <code>--output-file</code> <code>-o</code> Output file for generated script <code>fix_symlinks_generated.py</code> <code>--report-file</code> - File for detailed analysis report None <code>--verbose</code> <code>-v</code> Show detailed output False"},{"location":"python/system/fix_symlinks.html#symlink-analysis","title":"Symlink Analysis","text":""},{"location":"python/system/fix_symlinks.html#detection-categories","title":"Detection Categories","text":"<p>The tool categorizes symlinks into several types:</p> <ol> <li>Valid Symlinks - Links pointing to existing targets</li> <li>Broken Symlinks - Links with missing targets</li> <li>Circular Links - Links creating circular references</li> <li>Relative Links - Links using relative paths</li> <li>Absolute Links - Links using absolute paths</li> </ol>"},{"location":"python/system/fix_symlinks.html#analysis-output","title":"Analysis Output","text":"<pre><code>Symlink Analysis Report\n=======================\n\nScanning: /home/user/projects\nMode: Recursive scan\n\nSUMMARY:\n--------\nTotal symlinks found: 45\nValid symlinks: 38\nBroken symlinks: 7\nCircular references: 0\nRelative path links: 32\nAbsolute path links: 13\n\nBROKEN SYMLINKS:\n----------------\n1. /home/user/projects/lib/old_library.so\n   Target: /usr/local/lib/library_v1.so (missing)\n   Suggested fix: Update to /usr/local/lib/library_v2.so\n\n2. /home/user/projects/docs/manual.pdf\n   Target: ../resources/docs/manual.pdf (missing)\n   Suggested fix: Create target or update link\n\n3. /home/user/projects/bin/tool\n   Target: /opt/tools/legacy/tool (missing)\n   Suggested fix: Update to /opt/tools/current/tool\n</code></pre>"},{"location":"python/system/fix_symlinks.html#repair-strategies","title":"Repair Strategies","text":""},{"location":"python/system/fix_symlinks.html#automatic-repair","title":"Automatic Repair","text":"<p>The tool attempts several repair strategies:</p> <ol> <li>Target Search - Look for moved files in nearby directories</li> <li>Version Updates - Find newer versions of missing files</li> <li>Path Correction - Fix common path issues</li> <li>Relative Path Conversion - Convert broken absolute paths to relative</li> </ol>"},{"location":"python/system/fix_symlinks.html#manual-repair-options","title":"Manual Repair Options","text":"<ul> <li>Script Generation - Creates executable repair scripts</li> <li>Interactive Mode - Prompts for user decisions</li> <li>Backup Creation - Preserves original symlinks before changes</li> </ul>"},{"location":"python/system/fix_symlinks.html#examples","title":"Examples","text":""},{"location":"python/system/fix_symlinks.html#example-1-development-environment-cleanup","title":"Example 1: Development Environment Cleanup","text":"<pre><code># Scan development project for broken symlinks\npython3 fix_symlinks.py ~/projects/myapp \\\n    --recursive \\\n    --dry-run \\\n    --verbose\n\n# Fix after reviewing dry-run output\npython3 fix_symlinks.py ~/projects/myapp \\\n    --recursive \\\n    --fix \\\n    --backup\n</code></pre>"},{"location":"python/system/fix_symlinks.html#example-2-system-maintenance","title":"Example 2: System Maintenance","text":"<pre><code># Check system directories for broken links\nsudo python3 fix_symlinks.py /usr/local \\\n    --recursive \\\n    --report-file /var/log/symlink_audit.txt\n\n# Generate repair script for review\nsudo python3 fix_symlinks.py /usr/local \\\n    --recursive \\\n    --generate-script \\\n    --output-file /root/symlink_repairs.py\n</code></pre>"},{"location":"python/system/fix_symlinks.html#example-3-media-library-maintenance","title":"Example 3: Media Library Maintenance","text":"<pre><code>#!/bin/bash\n# Media library symlink maintenance script\n\nMEDIA_DIR=\"/mnt/media\"\nLOG_DIR=\"/var/log/media_maintenance\"\nDATE=$(date +%Y%m%d)\n\nmkdir -p \"$LOG_DIR\"\n\necho \"Starting symlink maintenance: $(date)\"\n\n# Scan for issues\npython3 fix_symlinks.py \"$MEDIA_DIR\" \\\n    --recursive \\\n    --report-file \"$LOG_DIR/symlink_analysis_$DATE.txt\" \\\n    --verbose\n\n# Dry run to see what would be fixed\npython3 fix_symlinks.py \"$MEDIA_DIR\" \\\n    --recursive \\\n    --dry-run &gt; \"$LOG_DIR/repair_preview_$DATE.txt\"\n\n# Generate repair script for manual review\npython3 fix_symlinks.py \"$MEDIA_DIR\" \\\n    --recursive \\\n    --generate-script \\\n    --output-file \"$LOG_DIR/repair_script_$DATE.py\"\n\necho \"Maintenance complete. Review files in $LOG_DIR\"\n</code></pre>"},{"location":"python/system/fix_symlinks.html#example-4-docker-volume-cleanup","title":"Example 4: Docker Volume Cleanup","text":"<pre><code># Clean up symlinks in Docker volumes\nfor volume in $(docker volume ls -q); do\n    volume_path=\"/var/lib/docker/volumes/$volume/_data\"\n    echo \"Checking volume: $volume\"\n\n    python3 fix_symlinks.py \"$volume_path\" \\\n        --recursive \\\n        --dry-run \\\n        --verbose\ndone\n</code></pre>"},{"location":"python/system/fix_symlinks.html#safety-features","title":"Safety Features","text":""},{"location":"python/system/fix_symlinks.html#dry-run-mode","title":"Dry-Run Mode","text":"<p>Preview operations without making changes: <pre><code>python3 fix_symlinks.py /path --fix --dry-run\n</code></pre></p> <p>Output: <pre><code>DRY RUN - No changes will be made\n=====================================\n\nWould fix broken symlink:\n  Link: /path/to/broken_link\n  Current target: /missing/file\n  New target: /found/file\n  Action: Update symlink target\n\nWould remove broken symlink:\n  Link: /path/to/unfixable_link\n  Target: /completely/missing/target\n  Action: Remove broken symlink\n</code></pre></p>"},{"location":"python/system/fix_symlinks.html#backup-creation","title":"Backup Creation","text":"<p>Automatic backup before modifications: <pre><code>python3 fix_symlinks.py /path --fix --backup\n</code></pre></p> <p>Creates: - <code>broken_link.backup</code> - Copy of original symlink - <code>symlink_backup_YYYYMMDD_HHMMSS/</code> - Timestamped backup directory</p>"},{"location":"python/system/fix_symlinks.html#generated-repair-scripts","title":"Generated Repair Scripts","text":""},{"location":"python/system/fix_symlinks.html#script-structure","title":"Script Structure","text":"<p>Generated scripts provide fine-grained control:</p> <pre><code>#!/usr/bin/env python3\n\"\"\"Auto-generated symlink repair script.\"\"\"\nimport os\nimport shutil\nfrom pathlib import Path\n\ndef backup_symlink(link_path, backup_dir):\n    \"\"\"Create backup of symlink before modification.\"\"\"\n    backup_path = backup_dir / Path(link_path).name\n    shutil.copy2(link_path, backup_path, follow_symlinks=False)\n    return backup_path\n\ndef fix_symlink_1():\n    \"\"\"Fix: /home/user/lib/library.so\"\"\"\n    link_path = \"/home/user/lib/library.so\"\n    old_target = \"/usr/lib/old/library.so\"\n    new_target = \"/usr/lib/current/library.so\"\n\n    print(f\"Fixing: {link_path}\")\n    print(f\"  Old target: {old_target}\")\n    print(f\"  New target: {new_target}\")\n\n    # Create backup\n    backup_path = backup_symlink(link_path, Path(\"/tmp/symlink_backups\"))\n    print(f\"  Backup created: {backup_path}\")\n\n    # Remove old link and create new one\n    os.unlink(link_path)\n    os.symlink(new_target, link_path)\n    print(f\"  \u2713 Fixed\")\n\ndef main():\n    \"\"\"Run all repairs.\"\"\"\n    print(\"Symlink Repair Script\")\n    print(\"====================\")\n\n    # Create backup directory\n    backup_dir = Path(\"/tmp/symlink_backups\")\n    backup_dir.mkdir(exist_ok=True)\n\n    # Run repairs\n    fix_symlink_1()\n    # Additional repairs...\n\n    print(\"\\nAll repairs completed!\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"python/system/fix_symlinks.html#advanced-features","title":"Advanced Features","text":""},{"location":"python/system/fix_symlinks.html#intelligent-target-detection","title":"Intelligent Target Detection","text":"<p>The tool uses several strategies to find moved targets:</p> <ol> <li>Filename Search - Look for files with same name in nearby directories</li> <li>Pattern Matching - Match files based on naming patterns</li> <li>Version Detection - Find newer versions of versioned files</li> <li>Content Analysis - Compare file metadata when available</li> </ol>"},{"location":"python/system/fix_symlinks.html#circular-reference-detection","title":"Circular Reference Detection","text":"<p>Identifies and reports circular symlink chains: <pre><code>CIRCULAR REFERENCE DETECTED:\n/path/a -&gt; /path/b -&gt; /path/c -&gt; /path/a\n\nResolution required: Break the circle by updating one link\n</code></pre></p>"},{"location":"python/system/fix_symlinks.html#cross-filesystem-handling","title":"Cross-Filesystem Handling","text":"<ul> <li>Detects symlinks crossing filesystem boundaries</li> <li>Provides warnings for potential mount point issues</li> <li>Suggests relative path alternatives where appropriate</li> </ul>"},{"location":"python/system/fix_symlinks.html#integration","title":"Integration","text":""},{"location":"python/system/fix_symlinks.html#system-administration","title":"System Administration","text":"<pre><code>import subprocess\nimport sys\n\nclass SymlinkMaintenance:\n    def __init__(self, base_paths):\n        self.base_paths = base_paths\n        self.results = {}\n\n    def scan_all_paths(self):\n        \"\"\"Scan all configured paths for symlink issues.\"\"\"\n        for path in self.base_paths:\n            print(f\"Scanning {path}...\")\n\n            result = subprocess.run([\n                sys.executable, \"fix_symlinks.py\",\n                path, \"--recursive\", \"--dry-run\"\n            ], capture_output=True, text=True)\n\n            self.results[path] = {\n                'success': result.returncode == 0,\n                'output': result.stdout,\n                'issues_found': 'Broken symlinks: 0' not in result.stdout\n            }\n\n    def generate_report(self):\n        \"\"\"Generate maintenance report.\"\"\"\n        issues_found = False\n\n        for path, result in self.results.items():\n            if result['issues_found']:\n                print(f\"Issues found in {path}\")\n                issues_found = True\n\n        return issues_found\n\n# Usage\nmaintenance = SymlinkMaintenance([\n    \"/home\", \"/usr/local\", \"/opt\"\n])\nmaintenance.scan_all_paths()\n\nif maintenance.generate_report():\n    print(\"Symlink maintenance required\")\nelse:\n    print(\"All symlinks are healthy\")\n</code></pre>"},{"location":"python/system/fix_symlinks.html#cicd-integration","title":"CI/CD Integration","text":"<pre><code># GitHub Actions workflow\nname: Symlink Health Check\non:\n  schedule:\n    - cron: '0 4 * * 1'  # Weekly on Monday at 4 AM\n\njobs:\n  symlink-check:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: Check project symlinks\n      run: |\n        python3 fix_symlinks.py . \\\n          --recursive \\\n          --dry-run \\\n          --report-file symlink_report.txt\n\n    - name: Upload symlink report\n      uses: actions/upload-artifact@v2\n      with:\n        name: symlink-health-report\n        path: symlink_report.txt\n\n    - name: Fail if broken symlinks found\n      run: |\n        if grep -q \"Broken symlinks: [1-9]\" symlink_report.txt; then\n          echo \"Broken symlinks detected!\"\n          exit 1\n        fi\n</code></pre>"},{"location":"python/system/fix_symlinks.html#backup-workflows","title":"Backup Workflows","text":"<pre><code>#!/bin/bash\n# Pre-backup symlink validation\n\nBACKUP_SOURCE=\"/data\"\nBACKUP_LOG=\"/var/log/backup_prep.log\"\n\necho \"Pre-backup symlink validation: $(date)\" &gt;&gt; \"$BACKUP_LOG\"\n\n# Check for broken symlinks before backup\nif python3 fix_symlinks.py \"$BACKUP_SOURCE\" \\\n    --recursive \\\n    --dry-run &gt;&gt; \"$BACKUP_LOG\" 2&gt;&amp;1; then\n    echo \"Symlink validation passed\" &gt;&gt; \"$BACKUP_LOG\"\nelse\n    echo \"Symlink issues detected - fixing before backup\" &gt;&gt; \"$BACKUP_LOG\"\n\n    # Generate and review repair script\n    python3 fix_symlinks.py \"$BACKUP_SOURCE\" \\\n        --recursive \\\n        --generate-script \\\n        --output-file \"/tmp/pre_backup_fixes.py\"\n\n    echo \"Review /tmp/pre_backup_fixes.py before proceeding\"\n    exit 1\nfi\n\n# Proceed with backup\necho \"Starting backup process...\" &gt;&gt; \"$BACKUP_LOG\"\n</code></pre>"},{"location":"python/system/fix_symlinks.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"python/system/fix_symlinks.html#common-issues","title":"Common Issues","text":"<p>Issue: Permission denied when scanning system directories <pre><code># Run with appropriate privileges\nsudo python3 fix_symlinks.py /usr/local --recursive\n</code></pre></p> <p>Issue: Cannot find moved targets <pre><code># Use verbose mode to see search paths\npython3 fix_symlinks.py /path --verbose --dry-run\n</code></pre></p> <p>Issue: Too many symlinks to process manually <pre><code># Generate script for batch processing\npython3 fix_symlinks.py /path \\\n    --recursive \\\n    --generate-script \\\n    --output-file batch_fixes.py\n</code></pre></p>"},{"location":"python/system/fix_symlinks.html#debugging","title":"Debugging","text":"<p>Use verbose mode for detailed operation information: <pre><code>python3 fix_symlinks.py /path --verbose --recursive --dry-run\n</code></pre></p> <p>This shows: - Symlink discovery process - Target validation attempts - Repair strategy selection - Detailed error information</p>"},{"location":"python/system/fix_symlinks.html#best-practices","title":"Best Practices","text":""},{"location":"python/system/fix_symlinks.html#regular-maintenance","title":"Regular Maintenance","text":"<ol> <li>Scheduled Scans - Regular symlink health checks</li> <li>Pre-Backup Validation - Check symlinks before backups</li> <li>Post-Migration Cleanup - Fix symlinks after system changes</li> <li>Documentation - Keep records of symlink patterns and purposes</li> </ol>"},{"location":"python/system/fix_symlinks.html#safety-procedures","title":"Safety Procedures","text":"<ol> <li>Always Dry-Run First - Preview changes before applying</li> <li>Create Backups - Preserve original symlinks</li> <li>Test Repairs - Verify fixed symlinks work correctly</li> <li>Gradual Deployment - Fix critical symlinks first</li> </ol>"},{"location":"python/system/fix_symlinks.html#performance-optimization","title":"Performance Optimization","text":"<ol> <li>Targeted Scans - Focus on specific directories when possible</li> <li>Exclude System Areas - Skip areas not requiring maintenance</li> <li>Batch Operations - Group similar repairs together</li> <li>Resource Monitoring - Monitor I/O during large scans</li> </ol> <p>fix_symlinks.py provides comprehensive symlink maintenance with intelligent repair capabilities, safety features, and integration options for system administration and development workflows.</p>"},{"location":"python/system/keep_larger_version.html","title":"keepLargerVersion.py","text":"<p>Automated duplicate file management with intelligent size-based selection, comprehensive CLI interface, and safe operation modes for file deduplication workflows.</p>"},{"location":"python/system/keep_larger_version.html#overview","title":"Overview","text":"<p>keepLargerVersion.py intelligently manages duplicate files by automatically keeping the larger version and removing smaller duplicates. The tool is designed for scenarios where file size indicates completeness or quality, such as media files, documents, or backup archives.</p>"},{"location":"python/system/keep_larger_version.html#features","title":"Features","text":"<ul> <li>Intelligent Duplicate Detection - Identifies files with identical names in directory trees</li> <li>Size-Based Selection - Automatically keeps the larger version of duplicate files</li> <li>Safety Features - Dry-run mode and comprehensive confirmation prompts</li> <li>Flexible Filtering - File extension and size filtering options</li> <li>Detailed Reporting - Comprehensive analysis and operation reports</li> <li>Backup Support - Optional backup creation before file removal</li> <li>Performance Optimized - Efficient handling of large directory structures</li> </ul>"},{"location":"python/system/keep_larger_version.html#usage","title":"Usage","text":""},{"location":"python/system/keep_larger_version.html#basic-usage","title":"Basic Usage","text":"<pre><code># Find and remove duplicate files (dry-run first)\npython3 keepLargerVersion.py /path/to/scan --dry-run\n\n# Execute the operation after reviewing dry-run\npython3 keepLargerVersion.py /path/to/scan --execute\n\n# Recursive scan with verbose output\npython3 keepLargerVersion.py /path/to/scan --recursive --verbose\n</code></pre>"},{"location":"python/system/keep_larger_version.html#advanced-usage","title":"Advanced Usage","text":"<pre><code># Filter by file extension\npython3 keepLargerVersion.py /path/to/scan \\\n    --filter-extension .jpg \\\n    --recursive \\\n    --execute\n\n# Create backups before removal\npython3 keepLargerVersion.py /path/to/scan \\\n    --execute \\\n    --create-backup \\\n    --backup-dir /safe/backup/location\n\n# Size-based filtering\npython3 keepLargerVersion.py /path/to/scan \\\n    --min-size 1048576 \\\n    --max-size 104857600 \\\n    --recursive\n</code></pre>"},{"location":"python/system/keep_larger_version.html#command-line-options","title":"Command-Line Options","text":"Option Short Description Default <code>directory</code> - Directory to scan for duplicates Required <code>--recursive</code> <code>-r</code> Scan subdirectories recursively False <code>--execute</code> <code>-e</code> Execute file removal (required for actual removal) False <code>--dry-run</code> - Show what would be done without making changes True (default) <code>--filter-extension</code> <code>-f</code> Filter by file extension (e.g., .jpg, .mp4) None <code>--min-size</code> - Minimum file size in bytes None <code>--max-size</code> - Maximum file size in bytes None <code>--create-backup</code> - Create backup before removing files False <code>--backup-dir</code> - Directory for backup files <code>./backup_YYYYMMDD_HHMMSS</code> <code>--verbose</code> <code>-v</code> Show detailed output False"},{"location":"python/system/keep_larger_version.html#duplicate-detection-logic","title":"Duplicate Detection Logic","text":""},{"location":"python/system/keep_larger_version.html#file-matching","title":"File Matching","text":"<p>The tool identifies duplicates based on:</p> <ol> <li>Filename Matching - Files with identical names (case-sensitive)</li> <li>Extension Consideration - Considers files with same base name but different extensions as separate</li> <li>Path Independence - Matches files regardless of directory location</li> <li>Size Comparison - Compares file sizes to determine which to keep</li> </ol>"},{"location":"python/system/keep_larger_version.html#selection-strategy","title":"Selection Strategy","text":"<p>When duplicates are found:</p> <ol> <li>Size Comparison - Larger file is always kept</li> <li>Equal Sizes - First found file is kept (with warning)</li> <li>Zero-Byte Files - Special handling for empty files</li> <li>Access Permissions - Checks file permissions before removal</li> </ol>"},{"location":"python/system/keep_larger_version.html#safety-features","title":"Safety Features","text":""},{"location":"python/system/keep_larger_version.html#dry-run-mode-default","title":"Dry-Run Mode (Default)","text":"<p>By default, the tool runs in dry-run mode showing what would be done:</p> <pre><code>python3 keepLargerVersion.py /photos\n</code></pre> <p>Output: <pre><code>Duplicate File Analysis\n=======================\n\nScanning: /photos\nMode: Dry-run (no files will be removed)\n\nDUPLICATES FOUND:\n-----------------\n\nvacation.jpg (2 versions found):\n  KEEP:   /photos/2023/vacation.jpg (2.5 MB)\n  REMOVE: /photos/backup/vacation.jpg (1.8 MB)\n  Savings: 1.8 MB\n\ndocument.pdf (3 versions found):\n  KEEP:   /photos/docs/document.pdf (850 KB)\n  REMOVE: /photos/old/document.pdf (820 KB)\n  REMOVE: /photos/temp/document.pdf (800 KB)\n  Savings: 1.6 MB\n\nSUMMARY:\n--------\nTotal duplicates found: 2 sets\nFiles that would be removed: 3\nTotal space that would be saved: 3.4 MB\n\nRun with --execute to perform the removal.\n</code></pre></p>"},{"location":"python/system/keep_larger_version.html#backup-creation","title":"Backup Creation","text":"<p>Optional backup before file removal:</p> <pre><code>python3 keepLargerVersion.py /photos --execute --create-backup\n</code></pre> <p>Creates timestamped backup directory with copies of files before removal.</p>"},{"location":"python/system/keep_larger_version.html#examples","title":"Examples","text":""},{"location":"python/system/keep_larger_version.html#example-1-photo-collection-cleanup","title":"Example 1: Photo Collection Cleanup","text":"<pre><code># Clean up photo collection with duplicates\npython3 keepLargerVersion.py ~/Pictures \\\n    --filter-extension .jpg \\\n    --recursive \\\n    --dry-run \\\n    --verbose\n\n# After reviewing results, execute\npython3 keepLargerVersion.py ~/Pictures \\\n    --filter-extension .jpg \\\n    --recursive \\\n    --execute \\\n    --create-backup\n</code></pre>"},{"location":"python/system/keep_larger_version.html#example-2-document-archive-management","title":"Example 2: Document Archive Management","text":"<pre><code># Clean up document archives\npython3 keepLargerVersion.py /archive/documents \\\n    --filter-extension .pdf \\\n    --min-size 10240 \\\n    --recursive \\\n    --execute\n</code></pre>"},{"location":"python/system/keep_larger_version.html#example-3-media-library-optimization","title":"Example 3: Media Library Optimization","text":"<pre><code>#!/bin/bash\n# Complete media library optimization script\n\nMEDIA_DIR=\"/mnt/media\"\nBACKUP_DIR=\"/backup/media_cleanup_$(date +%Y%m%d)\"\nLOG_FILE=\"/var/log/media_cleanup.log\"\n\necho \"Starting media library cleanup: $(date)\" | tee \"$LOG_FILE\"\n\n# Process different media types\nfor extension in .mp4 .avi .mkv .mov; do\n    echo \"Processing $extension files...\" | tee -a \"$LOG_FILE\"\n\n    python3 keepLargerVersion.py \"$MEDIA_DIR\" \\\n        --filter-extension \"$extension\" \\\n        --recursive \\\n        --execute \\\n        --create-backup \\\n        --backup-dir \"$BACKUP_DIR\" \\\n        --verbose &gt;&gt; \"$LOG_FILE\" 2&gt;&amp;1\n\n    if [ $? -eq 0 ]; then\n        echo \"\u2713 $extension files processed successfully\" | tee -a \"$LOG_FILE\"\n    else\n        echo \"\u2717 Error processing $extension files\" | tee -a \"$LOG_FILE\"\n    fi\ndone\n\necho \"Media cleanup completed: $(date)\" | tee -a \"$LOG_FILE\"\n</code></pre>"},{"location":"python/system/keep_larger_version.html#example-4-automated-backup-cleanup","title":"Example 4: Automated Backup Cleanup","text":"<pre><code># Weekly backup cleanup automation\npython3 keepLargerVersion.py /backup/weekly \\\n    --recursive \\\n    --min-size 1024 \\\n    --execute \\\n    --verbose \\\n    &gt; /var/log/backup_cleanup_$(date +%Y%m%d).log\n</code></pre>"},{"location":"python/system/keep_larger_version.html#advanced-features","title":"Advanced Features","text":""},{"location":"python/system/keep_larger_version.html#size-based-filtering","title":"Size-Based Filtering","text":"<pre><code># Only process files between 1MB and 100MB\npython3 keepLargerVersion.py /data \\\n    --min-size 1048576 \\\n    --max-size 104857600 \\\n    --recursive\n\n# Only process large files (&gt; 100MB)\npython3 keepLargerVersion.py /videos \\\n    --min-size 104857600 \\\n    --filter-extension .mp4\n</code></pre>"},{"location":"python/system/keep_larger_version.html#multiple-extension-processing","title":"Multiple Extension Processing","text":"<pre><code>#!/bin/bash\n# Process multiple file types in sequence\n\nEXTENSIONS=(\".jpg\" \".png\" \".mp4\" \".avi\" \".pdf\" \".docx\")\nTARGET_DIR=\"/cleanup/target\"\n\nfor ext in \"${EXTENSIONS[@]}\"; do\n    echo \"Processing $ext files...\"\n\n    python3 keepLargerVersion.py \"$TARGET_DIR\" \\\n        --filter-extension \"$ext\" \\\n        --recursive \\\n        --execute \\\n        --verbose\n\n    echo \"Completed $ext files\"\n    echo \"---\"\ndone\n</code></pre>"},{"location":"python/system/keep_larger_version.html#detailed-reporting","title":"Detailed Reporting","text":""},{"location":"python/system/keep_larger_version.html#verbose-output-analysis","title":"Verbose Output Analysis","text":"<p>With <code>--verbose</code> flag, get detailed analysis:</p> <pre><code>Duplicate File Analysis\n=======================\n\nScanning: /test/duplicates\nMode: Execute (files will be removed)\nFilter: .jpg files only\nMinimum size: 1 MB\n\nSCAN RESULTS:\n------------\nTotal files scanned: 1,247\nFiltered files: 856 .jpg files\nFiles meeting size criteria: 734\n\nDUPLICATE ANALYSIS:\n------------------\n\nSet 1: vacation_sunset.jpg\n  Files found: 3\n  \u251c\u2500 /test/duplicates/2023/vacation_sunset.jpg (3.2 MB) \u2190 KEEP (largest)\n  \u251c\u2500 /test/duplicates/backup/vacation_sunset.jpg (3.1 MB) \u2192 REMOVE\n  \u2514\u2500 /test/duplicates/temp/vacation_sunset.jpg (2.8 MB) \u2192 REMOVE\n  Space saved: 5.9 MB\n\nSet 2: family_portrait.jpg\n  Files found: 2\n  \u251c\u2500 /test/duplicates/photos/family_portrait.jpg (4.1 MB) \u2190 KEEP (largest)\n  \u2514\u2500 /test/duplicates/old/family_portrait.jpg (4.0 MB) \u2192 REMOVE\n  Space saved: 4.0 MB\n\nOPERATION SUMMARY:\n-----------------\nDuplicate sets found: 2\nTotal files to remove: 3\nTotal space to save: 9.9 MB\nEstimated time: &lt; 1 second\n\nSAFETY CHECKS:\n-------------\n\u2713 All target files are writable\n\u2713 Backup directory has sufficient space\n\u2713 No system files detected\n\u2713 All operations are reversible\n\nProceeding with removal...\n\u2713 Removed: /test/duplicates/backup/vacation_sunset.jpg\n\u2713 Removed: /test/duplicates/temp/vacation_sunset.jpg  \n\u2713 Removed: /test/duplicates/old/family_portrait.jpg\n\nFINAL REPORT:\n------------\nFiles removed: 3\nSpace freed: 9.9 MB\nBackup created: /backup/keepLargerVersion_20240706_143022/\nOperation completed successfully in 0.8 seconds\n</code></pre>"},{"location":"python/system/keep_larger_version.html#integration-patterns","title":"Integration Patterns","text":""},{"location":"python/system/keep_larger_version.html#python-script-integration","title":"Python Script Integration","text":"<pre><code>import subprocess\nimport sys\nfrom pathlib import Path\n\nclass DuplicateManager:\n    def __init__(self, base_directory):\n        self.base_directory = Path(base_directory)\n        self.script_path = \"keepLargerVersion.py\"\n\n    def analyze_duplicates(self, file_extension=None, recursive=True):\n        \"\"\"Analyze duplicates without removing files.\"\"\"\n        cmd = [\n            sys.executable, self.script_path,\n            str(self.base_directory),\n            \"--dry-run\", \"--verbose\"\n        ]\n\n        if recursive:\n            cmd.append(\"--recursive\")\n\n        if file_extension:\n            cmd.extend([\"--filter-extension\", file_extension])\n\n        result = subprocess.run(cmd, capture_output=True, text=True)\n        return {\n            'success': result.returncode == 0,\n            'output': result.stdout,\n            'errors': result.stderr\n        }\n\n    def remove_duplicates(self, file_extension=None, create_backup=True):\n        \"\"\"Remove duplicates after analysis.\"\"\"\n        cmd = [\n            sys.executable, self.script_path,\n            str(self.base_directory),\n            \"--execute\", \"--recursive\"\n        ]\n\n        if file_extension:\n            cmd.extend([\"--filter-extension\", file_extension])\n\n        if create_backup:\n            cmd.append(\"--create-backup\")\n\n        result = subprocess.run(cmd, capture_output=True, text=True)\n        return result.returncode == 0\n\n# Usage\nmanager = DuplicateManager(\"/media/photos\")\n\n# Analyze first\nanalysis = manager.analyze_duplicates(\".jpg\")\nif analysis['success']:\n    print(\"Analysis completed. Found duplicates to remove.\")\n\n    # Execute removal\n    if manager.remove_duplicates(\".jpg\", create_backup=True):\n        print(\"Duplicates removed successfully\")\n    else:\n        print(\"Failed to remove duplicates\")\n</code></pre>"},{"location":"python/system/keep_larger_version.html#monitoring-and-alerting","title":"Monitoring and Alerting","text":"<pre><code>import smtplib\nfrom email.mime.text import MIMEText\nimport subprocess\n\ndef automated_cleanup_with_alerts(directory, email_recipient):\n    \"\"\"Automated cleanup with email alerts.\"\"\"\n\n    # Run analysis\n    result = subprocess.run([\n        \"python3\", \"keepLargerVersion.py\",\n        directory, \"--recursive\", \"--dry-run\"\n    ], capture_output=True, text=True)\n\n    if \"duplicates found\" in result.stdout:\n        # Send notification\n        msg = MIMEText(f\"Duplicate cleanup needed in {directory}\\n\\n{result.stdout}\")\n        msg['Subject'] = f'Duplicate Files Found: {directory}'\n        msg['From'] = 'system@company.com'\n        msg['To'] = email_recipient\n\n        # Send email (configure SMTP as needed)\n        smtp = smtplib.SMTP('localhost')\n        smtp.send_message(msg)\n        smtp.quit()\n\n        return True\n    else:\n        print(\"No duplicates found\")\n        return False\n\n# Schedule this function to run periodically\nautomated_cleanup_with_alerts(\"/important/data\", \"admin@company.com\")\n</code></pre>"},{"location":"python/system/keep_larger_version.html#error-handling-and-recovery","title":"Error Handling and Recovery","text":""},{"location":"python/system/keep_larger_version.html#comprehensive-error-handling","title":"Comprehensive Error Handling","text":"<pre><code>def safe_duplicate_removal(directory, **options):\n    \"\"\"Safely remove duplicates with comprehensive error handling.\"\"\"\n\n    try:\n        # Validate directory\n        if not os.path.exists(directory):\n            raise ValueError(f\"Directory does not exist: {directory}\")\n\n        if not os.access(directory, os.R_OK):\n            raise PermissionError(f\"Cannot read directory: {directory}\")\n\n        # Run dry-run first\n        print(\"Running analysis...\")\n        dry_run_cmd = [\n            \"python3\", \"keepLargerVersion.py\",\n            directory, \"--dry-run\", \"--verbose\"\n        ]\n\n        result = subprocess.run(dry_run_cmd, capture_output=True, text=True)\n\n        if result.returncode != 0:\n            raise RuntimeError(f\"Analysis failed: {result.stderr}\")\n\n        # Parse results\n        if \"No duplicates found\" in result.stdout:\n            print(\"No duplicates found\")\n            return True\n\n        # Confirm with user\n        print(result.stdout)\n        if not input(\"Proceed with removal? (y/N): \").lower().startswith('y'):\n            print(\"Operation cancelled by user\")\n            return False\n\n        # Execute removal\n        execute_cmd = [\n            \"python3\", \"keepLargerVersion.py\",\n            directory, \"--execute\", \"--create-backup\", \"--verbose\"\n        ]\n\n        result = subprocess.run(execute_cmd, capture_output=True, text=True)\n\n        if result.returncode == 0:\n            print(\"\u2713 Duplicates removed successfully\")\n            print(result.stdout)\n            return True\n        else:\n            print(\"\u2717 Removal failed\")\n            print(result.stderr)\n            return False\n\n    except Exception as e:\n        print(f\"Error during duplicate removal: {e}\")\n        return False\n\n# Usage with error handling\nif safe_duplicate_removal(\"/media/photos\", recursive=True):\n    print(\"Cleanup completed successfully\")\nelse:\n    print(\"Cleanup failed - manual intervention required\")\n</code></pre>"},{"location":"python/system/keep_larger_version.html#best-practices","title":"Best Practices","text":""},{"location":"python/system/keep_larger_version.html#safe-operation-workflow","title":"Safe Operation Workflow","text":"<ol> <li>Always Dry-Run First - Review what will be removed</li> <li>Create Backups - Use <code>--create-backup</code> for important files</li> <li>Filter Appropriately - Use extension and size filters to target specific files</li> <li>Verify Results - Check that intended files were removed</li> <li>Monitor Disk Space - Ensure sufficient space for backups</li> </ol>"},{"location":"python/system/keep_larger_version.html#performance-optimization","title":"Performance Optimization","text":"<ol> <li>Use Filters - Reduce processing time with appropriate filters</li> <li>Size Thresholds - Skip very small files if not relevant</li> <li>Incremental Processing - Process one extension type at a time</li> <li>Resource Monitoring - Monitor system resources during operation</li> </ol>"},{"location":"python/system/keep_larger_version.html#data-safety","title":"Data Safety","text":"<ol> <li>Test on Copies - Test the tool on copies of important data first</li> <li>Backup Strategy - Have independent backups before cleanup</li> <li>Verification - Verify that kept files are actually larger and intact</li> <li>Rollback Plan - Know how to restore from backups if needed</li> </ol> <p>keepLargerVersion.py provides intelligent duplicate file management with comprehensive safety features, detailed reporting, and flexible filtering options for automated file deduplication workflows.</p>"},{"location":"python/system/switch_paths.html","title":"switch_paths.py","text":"<p>Bulk path replacement tool with JSON configuration support, flexible pattern matching, and comprehensive safety features for project migration and path management.</p>"},{"location":"python/system/switch_paths.html#overview","title":"Overview","text":"<p>switch_paths.py performs intelligent bulk find-and-replace operations on file paths within text files. It's designed for project migration scenarios where file paths need to be updated across multiple configuration files, scripts, or documentation.</p>"},{"location":"python/system/switch_paths.html#features","title":"Features","text":"<ul> <li>JSON Configuration - Store complex replacement patterns in configuration files</li> <li>Flexible Pattern Matching - Support for exact matches, regex patterns, and wildcards</li> <li>Safety Features - Dry-run mode, backup creation, and rollback capabilities</li> <li>File Filtering - Process specific file types or exclude certain files</li> <li>Recursive Processing - Handle entire directory trees</li> <li>Detailed Reporting - Comprehensive logs of all changes made</li> </ul>"},{"location":"python/system/switch_paths.html#usage","title":"Usage","text":""},{"location":"python/system/switch_paths.html#basic-usage","title":"Basic Usage","text":"<pre><code># Simple path replacement\npython3 switch_paths.py /project/files \\\n    --old-path \"/old/base/path\" \\\n    --new-path \"/new/base/path\"\n\n# Dry-run to preview changes\npython3 switch_paths.py /project/files \\\n    --old-path \"/old/path\" \\\n    --new-path \"/new/path\" \\\n    --dry-run\n\n# Use JSON configuration file\npython3 switch_paths.py /project/files \\\n    --config-file path_mappings.json\n</code></pre>"},{"location":"python/system/switch_paths.html#advanced-usage","title":"Advanced Usage","text":"<pre><code># Filter by file extension\npython3 switch_paths.py /project \\\n    --old-path \"/old/path\" \\\n    --new-path \"/new/path\" \\\n    --file-extensions .py .sh .conf \\\n    --recursive\n\n# Create backups before modification\npython3 switch_paths.py /project \\\n    --config-file mappings.json \\\n    --create-backup \\\n    --backup-suffix .backup\n\n# Exclude specific files or patterns\npython3 switch_paths.py /project \\\n    --old-path \"/old/path\" \\\n    --new-path \"/new/path\" \\\n    --exclude-patterns \"*.log\" \"temp/*\" \\\n    --recursive\n</code></pre>"},{"location":"python/system/switch_paths.html#command-line-options","title":"Command-Line Options","text":"Option Short Description Default <code>directory</code> - Directory to process Required <code>--old-path</code> - Path to replace (if not using config file) None <code>--new-path</code> - Replacement path (if not using config file) None <code>--config-file</code> <code>-c</code> JSON configuration file with path mappings None <code>--recursive</code> <code>-r</code> Process subdirectories recursively False <code>--file-extensions</code> <code>-e</code> File extensions to process All text files <code>--exclude-patterns</code> - Patterns to exclude from processing None <code>--dry-run</code> <code>-d</code> Show what would be changed without modifying files False <code>--create-backup</code> <code>-b</code> Create backup files before modification False <code>--backup-suffix</code> - Suffix for backup files <code>.bak</code> <code>--verbose</code> <code>-v</code> Show detailed output False"},{"location":"python/system/switch_paths.html#configuration-file-format","title":"Configuration File Format","text":""},{"location":"python/system/switch_paths.html#json-configuration-structure","title":"JSON Configuration Structure","text":"<pre><code>{\n  \"description\": \"Project migration path mappings\",\n  \"replacements\": [\n    {\n      \"name\": \"Update base directory\",\n      \"old_path\": \"/old/project/base\",\n      \"new_path\": \"/new/project/location\",\n      \"pattern_type\": \"exact\"\n    },\n    {\n      \"name\": \"Update config paths\",\n      \"old_path\": \"/etc/oldapp/\",\n      \"new_path\": \"/etc/newapp/\",\n      \"pattern_type\": \"prefix\"\n    },\n    {\n      \"name\": \"Update log file paths\",\n      \"old_path\": \"(/var/log/)(\\\\w+)(\\\\.log)\",\n      \"new_path\": \"/new/logs/$2.log\", \n      \"pattern_type\": \"regex\"\n    }\n  ],\n  \"file_filters\": {\n    \"include_extensions\": [\".py\", \".sh\", \".conf\", \".yaml\", \".json\"],\n    \"exclude_patterns\": [\"*.pyc\", \"*.log\", \".git/*\"]\n  },\n  \"options\": {\n    \"create_backup\": true,\n    \"backup_suffix\": \".pre_migration\",\n    \"case_sensitive\": true\n  }\n}\n</code></pre>"},{"location":"python/system/switch_paths.html#pattern-types","title":"Pattern Types","text":""},{"location":"python/system/switch_paths.html#exact-match","title":"Exact Match","text":"<pre><code>{\n  \"old_path\": \"/exact/path/to/replace\",\n  \"new_path\": \"/new/exact/path\",\n  \"pattern_type\": \"exact\"\n}\n</code></pre>"},{"location":"python/system/switch_paths.html#prefix-match","title":"Prefix Match","text":"<pre><code>{\n  \"old_path\": \"/old/prefix/\",\n  \"new_path\": \"/new/prefix/\",\n  \"pattern_type\": \"prefix\"\n}\n</code></pre>"},{"location":"python/system/switch_paths.html#regex-pattern","title":"Regex Pattern","text":"<pre><code>{\n  \"old_path\": \"/logs/(\\\\w+)/(\\\\d+)/(.+\\\\.log)\",\n  \"new_path\": \"/new_logs/$1/$2/$3\",\n  \"pattern_type\": \"regex\"\n}\n</code></pre>"},{"location":"python/system/switch_paths.html#examples","title":"Examples","text":""},{"location":"python/system/switch_paths.html#example-1-simple-project-migration","title":"Example 1: Simple Project Migration","text":"<pre><code># Migrate project from /old/location to /new/location\npython3 switch_paths.py /project/source \\\n    --old-path \"/old/location\" \\\n    --new-path \"/new/location\" \\\n    --recursive \\\n    --file-extensions .py .sh .conf \\\n    --create-backup \\\n    --verbose\n</code></pre>"},{"location":"python/system/switch_paths.html#example-2-complex-migration-with-configuration","title":"Example 2: Complex Migration with Configuration","text":"<p>Create <code>migration_config.json</code>: <pre><code>{\n  \"description\": \"Development to Production Migration\", \n  \"replacements\": [\n    {\n      \"name\": \"Update database paths\",\n      \"old_path\": \"/dev/database/\",\n      \"new_path\": \"/prod/database/\",\n      \"pattern_type\": \"prefix\"\n    },\n    {\n      \"name\": \"Update log directories\", \n      \"old_path\": \"/tmp/logs/\",\n      \"new_path\": \"/var/log/app/\",\n      \"pattern_type\": \"prefix\"\n    },\n    {\n      \"name\": \"Update config files\",\n      \"old_path\": \"/home/dev/config/\",\n      \"new_path\": \"/etc/app/\",\n      \"pattern_type\": \"prefix\"\n    }\n  ],\n  \"file_filters\": {\n    \"include_extensions\": [\".py\", \".sh\", \".conf\", \".yaml\"],\n    \"exclude_patterns\": [\"*.pyc\", \"*.log\", \"__pycache__/*\"]\n  },\n  \"options\": {\n    \"create_backup\": true,\n    \"backup_suffix\": \".dev_backup\"\n  }\n}\n</code></pre></p> <p>Execute migration: <pre><code>python3 switch_paths.py /app/source \\\n    --config-file migration_config.json \\\n    --recursive \\\n    --dry-run  # Preview first\n\n# After reviewing, execute\npython3 switch_paths.py /app/source \\\n    --config-file migration_config.json \\\n    --recursive\n</code></pre></p>"},{"location":"python/system/switch_paths.html#example-3-docker-container-path-updates","title":"Example 3: Docker Container Path Updates","text":"<pre><code>{\n  \"description\": \"Update Docker volume paths\",\n  \"replacements\": [\n    {\n      \"name\": \"Update volume mounts\",\n      \"old_path\": \"(/host/data/)(\\\\w+)\",\n      \"new_path\": \"/container/data/$2\",\n      \"pattern_type\": \"regex\"\n    },\n    {\n      \"name\": \"Update config mounts\", \n      \"old_path\": \"/host/config/\",\n      \"new_path\": \"/etc/app/\",\n      \"pattern_type\": \"prefix\"\n    }\n  ],\n  \"file_filters\": {\n    \"include_extensions\": [\".yml\", \".yaml\", \".json\"],\n    \"exclude_patterns\": [\".git/*\"]\n  }\n}\n</code></pre>"},{"location":"python/system/switch_paths.html#example-4-windows-to-linux-path-migration","title":"Example 4: Windows to Linux Path Migration","text":"<pre><code>{\n  \"description\": \"Windows to Linux path migration\",\n  \"replacements\": [\n    {\n      \"name\": \"Convert Windows drive paths\",\n      \"old_path\": \"C:\\\\\\\\\",\n      \"new_path\": \"/mnt/c/\",\n      \"pattern_type\": \"exact\"\n    },\n    {\n      \"name\": \"Convert backslashes to forward slashes\",\n      \"old_path\": \"\\\\\\\\\",\n      \"new_path\": \"/\",\n      \"pattern_type\": \"exact\"\n    },\n    {\n      \"name\": \"Update program files path\",\n      \"old_path\": \"C:/Program Files/\",\n      \"new_path\": \"/usr/local/\",\n      \"pattern_type\": \"prefix\"\n    }\n  ],\n  \"options\": {\n    \"case_sensitive\": false\n  }\n}\n</code></pre>"},{"location":"python/system/switch_paths.html#advanced-features","title":"Advanced Features","text":""},{"location":"python/system/switch_paths.html#regex-pattern-replacement","title":"Regex Pattern Replacement","text":"<p>Support for complex pattern matching with capture groups:</p> <pre><code>{\n  \"name\": \"Update versioned paths\",\n  \"old_path\": \"/app/version(\\\\d+)\\\\.(\\\\d+)/data/\",\n  \"new_path\": \"/new_app/v$1.$2/storage/\",\n  \"pattern_type\": \"regex\"\n}\n</code></pre>"},{"location":"python/system/switch_paths.html#conditional-replacements","title":"Conditional Replacements","text":"<p>Apply different replacements based on file context:</p> <pre><code>{\n  \"replacements\": [\n    {\n      \"name\": \"Python imports\", \n      \"old_path\": \"from old_module\",\n      \"new_path\": \"from new_module\",\n      \"pattern_type\": \"exact\",\n      \"file_types\": [\".py\"]\n    },\n    {\n      \"name\": \"Shell script paths\",\n      \"old_path\": \"/old/bin/\",\n      \"new_path\": \"/new/bin/\",\n      \"pattern_type\": \"prefix\", \n      \"file_types\": [\".sh\", \".bash\"]\n    }\n  ]\n}\n</code></pre>"},{"location":"python/system/switch_paths.html#batch-processing-script","title":"Batch Processing Script","text":"<pre><code>#!/bin/bash\n# Batch process multiple projects\n\nPROJECTS=(\n    \"/project1\"\n    \"/project2\" \n    \"/project3\"\n)\n\nCONFIG_FILE=\"standard_migration.json\"\nLOG_DIR=\"/var/log/path_migrations\"\n\nmkdir -p \"$LOG_DIR\"\n\nfor project in \"${PROJECTS[@]}\"; do\n    project_name=$(basename \"$project\")\n    log_file=\"$LOG_DIR/${project_name}_$(date +%Y%m%d_%H%M%S).log\"\n\n    echo \"Processing $project...\" | tee \"$log_file\"\n\n    # Dry run first\n    python3 switch_paths.py \"$project\" \\\n        --config-file \"$CONFIG_FILE\" \\\n        --recursive \\\n        --dry-run \\\n        --verbose &gt;&gt; \"$log_file\" 2&gt;&amp;1\n\n    if [ $? -eq 0 ]; then\n        echo \"Dry run successful, executing migration...\" | tee -a \"$log_file\"\n\n        # Execute migration\n        python3 switch_paths.py \"$project\" \\\n            --config-file \"$CONFIG_FILE\" \\\n            --recursive \\\n            --create-backup \\\n            --verbose &gt;&gt; \"$log_file\" 2&gt;&amp;1\n\n        if [ $? -eq 0 ]; then\n            echo \"\u2713 $project migrated successfully\" | tee -a \"$log_file\"\n        else\n            echo \"\u2717 $project migration failed\" | tee -a \"$log_file\"\n        fi\n    else\n        echo \"\u2717 $project dry run failed\" | tee -a \"$log_file\"\n    fi\n\n    echo \"---\" | tee -a \"$log_file\"\ndone\n</code></pre>"},{"location":"python/system/switch_paths.html#safety-and-recovery-features","title":"Safety and Recovery Features","text":""},{"location":"python/system/switch_paths.html#backup-and-rollback","title":"Backup and Rollback","text":"<pre><code># Create timestamped backups\npython3 switch_paths.py /project \\\n    --config-file migration.json \\\n    --create-backup \\\n    --backup-suffix \".backup_$(date +%Y%m%d_%H%M%S)\"\n\n# Rollback script\n#!/bin/bash\n# Rollback changes by restoring backups\n\nfind /project -name \"*.backup_*\" | while read backup_file; do\n    original_file=\"${backup_file%.backup_*}\"\n    if [ -f \"$backup_file\" ]; then\n        echo \"Restoring: $original_file\"\n        cp \"$backup_file\" \"$original_file\"\n    fi\ndone\n</code></pre>"},{"location":"python/system/switch_paths.html#validation-and-verification","title":"Validation and Verification","text":"<pre><code>import json\nimport subprocess\n\ndef validate_migration(directory, config_file):\n    \"\"\"Validate migration results.\"\"\"\n\n    # Load configuration\n    with open(config_file, 'r') as f:\n        config = json.load(f)\n\n    validation_results = []\n\n    for replacement in config['replacements']:\n        old_path = replacement['old_path']\n\n        # Search for remaining old paths\n        cmd = ['grep', '-r', old_path, directory]\n        result = subprocess.run(cmd, capture_output=True, text=True)\n\n        if result.stdout:\n            validation_results.append({\n                'replacement': replacement['name'],\n                'remaining_occurrences': result.stdout.strip().split('\\n')\n            })\n\n    return validation_results\n\n# Usage\nresults = validate_migration('/project', 'migration.json')\nif results:\n    print(\"Migration incomplete. Remaining old paths found:\")\n    for result in results:\n        print(f\"- {result['replacement']}: {len(result['remaining_occurrences'])} occurrences\")\nelse:\n    print(\"Migration validation passed - no old paths found\")\n</code></pre>"},{"location":"python/system/switch_paths.html#integration-patterns","title":"Integration Patterns","text":""},{"location":"python/system/switch_paths.html#cicd-pipeline-integration","title":"CI/CD Pipeline Integration","text":"<pre><code># GitHub Actions workflow\nname: Project Migration\non: \n  workflow_dispatch:\n    inputs:\n      config_file:\n        description: 'Migration configuration file'\n        required: true\n        default: 'migration_config.json'\n\njobs:\n  migrate-paths:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: Validate configuration\n      run: |\n        python3 -c \"import json; json.load(open('${{ github.event.inputs.config_file }}'))\"\n\n    - name: Dry run migration\n      run: |\n        python3 switch_paths.py . \\\n          --config-file \"${{ github.event.inputs.config_file }}\" \\\n          --recursive \\\n          --dry-run \\\n          --verbose &gt; migration_preview.txt\n\n    - name: Upload preview\n      uses: actions/upload-artifact@v2\n      with:\n        name: migration-preview\n        path: migration_preview.txt\n\n    - name: Execute migration\n      if: github.event.inputs.execute == 'true'\n      run: |\n        python3 switch_paths.py . \\\n          --config-file \"${{ github.event.inputs.config_file }}\" \\\n          --recursive \\\n          --create-backup \\\n          --verbose\n</code></pre>"},{"location":"python/system/switch_paths.html#docker-container-migration","title":"Docker Container Migration","text":"<pre><code># Dockerfile for migration container\nFROM python:3.11-slim\n\nCOPY switch_paths.py /usr/local/bin/\nCOPY migration_configs/ /configs/\n\nWORKDIR /workspace\n\nENTRYPOINT [\"python3\", \"/usr/local/bin/switch_paths.py\"]\n</code></pre> <p>Usage: <pre><code># Run migration in container\ndocker run --rm -v /host/project:/workspace migration-tool \\\n    /workspace \\\n    --config-file /configs/production_migration.json \\\n    --recursive \\\n    --create-backup\n</code></pre></p>"},{"location":"python/system/switch_paths.html#error-handling-and-troubleshooting","title":"Error Handling and Troubleshooting","text":""},{"location":"python/system/switch_paths.html#common-issues-and-solutions","title":"Common Issues and Solutions","text":"<p>Issue: \"Permission denied\" errors <pre><code># Fix file permissions before migration\nfind /project -type f -exec chmod 644 {} \\;\nfind /project -type d -exec chmod 755 {} \\;\n</code></pre></p> <p>Issue: Binary files being processed <pre><code># Add file type detection to config\n{\n  \"file_filters\": {\n    \"exclude_patterns\": [\"*.exe\", \"*.dll\", \"*.so\", \"*.dylib\", \"*.pyc\"]\n  }\n}\n</code></pre></p> <p>Issue: Regex patterns not matching <pre><code># Test regex patterns separately\npython3 -c \"\nimport re\npattern = r'/logs/(\\w+)/(\\d+)/(.+\\.log)'\ntest_string = '/logs/app/2024/error.log'\nmatch = re.search(pattern, test_string)\nif match:\n    print('Match found:', match.groups())\nelse:\n    print('No match')\n\"\n</code></pre></p>"},{"location":"python/system/switch_paths.html#debugging-and-logging","title":"Debugging and Logging","text":"<pre><code>import logging\n\n# Configure detailed logging\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format='%(asctime)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('switch_paths_debug.log'),\n        logging.StreamHandler()\n    ]\n)\n\n# Add logging to switch_paths.py for debugging\ndef debug_replacement(file_path, old_pattern, new_pattern, matches):\n    \"\"\"Log detailed replacement information.\"\"\"\n    logging.debug(f\"File: {file_path}\")\n    logging.debug(f\"Pattern: {old_pattern} -&gt; {new_pattern}\")\n    logging.debug(f\"Matches found: {len(matches)}\")\n    for i, match in enumerate(matches):\n        logging.debug(f\"  Match {i+1}: {match}\")\n</code></pre>"},{"location":"python/system/switch_paths.html#best-practices","title":"Best Practices","text":""},{"location":"python/system/switch_paths.html#migration-planning","title":"Migration Planning","text":"<ol> <li>Test on Copies - Always test migrations on copies of important data</li> <li>Incremental Approach - Process one replacement type at a time</li> <li>Validation Scripts - Create scripts to validate migration results</li> <li>Rollback Planning - Ensure ability to rollback changes</li> </ol>"},{"location":"python/system/switch_paths.html#configuration-management","title":"Configuration Management","text":"<ol> <li>Version Control - Keep migration configs in version control</li> <li>Environment-Specific - Create separate configs for different environments</li> <li>Documentation - Document the purpose of each replacement</li> <li>Validation - Validate JSON configuration files before use</li> </ol>"},{"location":"python/system/switch_paths.html#safety-procedures","title":"Safety Procedures","text":"<ol> <li>Always Dry-Run First - Review changes before execution</li> <li>Create Backups - Use backup features for important files</li> <li>Monitor Progress - Use verbose mode for long operations</li> <li>Verify Results - Check that replacements worked as expected</li> </ol> <p>switch_paths.py provides comprehensive bulk path replacement capabilities with JSON configuration support, safety features, and flexible pattern matching for project migration and path management workflows.</p>"}]}